{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "ba-synapse01-lhf7sbrgc3jru"
		},
		"ControlDB_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'ControlDB'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=ba-sql01-lhf7sbrgc3jru.database.windows.net;Initial Catalog=controlDB"
		},
		"ba-synapse01-lhf7sbrgc3jru-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'ba-synapse01-lhf7sbrgc3jru-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:ba-synapse01-lhf7sbrgc3jru.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"AIMLCustomModels_properties_typeProperties_serviceEndpoint": {
			"type": "string",
			"defaultValue": "https://baaimlstorage01o2katdvwv.blob.core.windows.net/"
		},
		"AtlasREST_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://ba-purview01-6spfx5oytiivq.purview.azure.com"
		},
		"AtlasREST_properties_typeProperties_servicePrincipalId": {
			"type": "string",
			"defaultValue": "5f2dc546-5728-4896-8055-a4853c8cc26b"
		},
		"AtlasREST_properties_typeProperties_tenant": {
			"type": "string",
			"defaultValue": "45a126ff-7fc0-4528-ac6b-eefad687db2d"
		},
		"AtlasREST_properties_typeProperties_aadResourceId": {
			"type": "string",
			"defaultValue": "https://purview.azure.net"
		},
		"Bronze_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://badatalake01lhf7sbrgc3jr.dfs.core.windows.net/"
		},
		"DeltaZone_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://badatalake01lhf7sbrgc3jr.dfs.core.windows.net/"
		},
		"DropZone_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://badatalake01lhf7sbrgc3jr.dfs.core.windows.net/"
		},
		"REST_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "@{linkedService().BaseURL}"
		},
		"REST_properties_typeProperties_servicePrincipalId": {
			"type": "string",
			"defaultValue": "@{linkedService().ServicePrincipalID}"
		},
		"REST_properties_typeProperties_tenant": {
			"type": "string",
			"defaultValue": "@{linkedService().TenantID}"
		},
		"REST_properties_typeProperties_aadResourceId": {
			"type": "string",
			"defaultValue": "@{linkedService().AADResource}"
		},
		"ba-synapse01-lhf7sbrgc3jru-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://badatalake01lhf7sbrgc3jr.dfs.core.windows.net/"
		},
		"keyvault01_properties_typeProperties_baseUrl": {
			"type": "string",
			"defaultValue": "https://ba-kv01-lhf7sbrgc3jru.vault.azure.net/"
		},
		"Azure Daily_properties_Master ELT REST API_parameters_SourceSystemName": {
			"type": "string",
			"defaultValue": "Azure"
		},
		"Azure Daily_properties_Master ELT REST API_parameters_StreamName": {
			"type": "string",
			"defaultValue": "%"
		},
		"Azure Daily_properties_Master ELT REST API_parameters_MaxIngestInstance": {
			"type": "string",
			"defaultValue": "100"
		},
		"Azure Daily_properties_Master ELT REST API_parameters_BaseURL": {
			"type": "string",
			"defaultValue": "https://management.azure.com"
		},
		"Azure Daily_properties_Master ELT REST API_parameters_ServicePrincipalID": {
			"type": "string",
			"defaultValue": "5e07b142-92b4-4671-83c0-e824bc93da6c"
		},
		"Azure Daily_properties_Master ELT REST API_parameters_TenantID": {
			"type": "string",
			"defaultValue": "45a126ff-7fc0-4528-ac6b-eefad687db2d"
		},
		"Azure Daily_properties_Master ELT REST API_parameters_AADResource": {
			"type": "string",
			"defaultValue": "https://management.azure.com"
		},
		"Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_resourceList_logicapp_endpoint": {
			"type": "string",
			"defaultValue": "https://prod-04.australiaeast.logic.azure.com:443/workflows/ee295f1388fb4359b67720244b66cbe3/triggers/manual/paths/invoke?api-version=2016-10-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=SlzOGTURSi2tPQycv6MeL5XrA7lsO882OG1emTGjQ7Y"
		},
		"Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_subscriptionId": {
			"type": "string",
			"defaultValue": "735994b1-b3b0-46d5-96bc-c9b30ddb4265"
		},
		"Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_resourceType": {
			"type": "string",
			"defaultValue": "Microsoft.Synapse/workspaces/sqlPools"
		},
		"Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_apiVersion": {
			"type": "string",
			"defaultValue": "2021-04-01"
		},
		"Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_action": {
			"type": "string",
			"defaultValue": "pause"
		},
		"Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_sku": {
			"type": "string",
			"defaultValue": "DW100c"
		},
		"Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_sqlPool_logicapp_endpoint": {
			"type": "string",
			"defaultValue": "https://prod-09.australiaeast.logic.azure.com:443/workflows/af3838b72592416e873d9f32cfc40eb4/triggers/manual/paths/invoke?api-version=2016-10-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=yvG-d--0V35lUDOOuc6cNzGDjqtcHzVc8KBl3DOPql4"
		},
		"Purview Daily_properties_Master ELT REST API_parameters_SourceSystemName": {
			"type": "string",
			"defaultValue": "Purview"
		},
		"Purview Daily_properties_Master ELT REST API_parameters_StreamName": {
			"type": "string",
			"defaultValue": "%"
		},
		"Purview Daily_properties_Master ELT REST API_parameters_MaxIngestInstance": {
			"type": "string",
			"defaultValue": "50"
		},
		"Purview Daily_properties_Master ELT REST API_parameters_BaseURL": {
			"type": "string",
			"defaultValue": "https://ba-purview01-6spfx5oytiivq.purview.azure.com"
		},
		"Purview Daily_properties_Master ELT REST API_parameters_ServicePrincipalID": {
			"type": "string",
			"defaultValue": "5e07b142-92b4-4671-83c0-e824bc93da6c"
		},
		"Purview Daily_properties_Master ELT REST API_parameters_TenantID": {
			"type": "string",
			"defaultValue": "45a126ff-7fc0-4528-ac6b-eefad687db2d"
		},
		"Purview Daily_properties_Master ELT REST API_parameters_AADResource": {
			"type": "string",
			"defaultValue": "https://purview.azure.net"
		},
		"Real Estate Statement Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceFileDropFileSystem": {
			"type": "string",
			"defaultValue": "doci"
		},
		"Real Estate Statement Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceFileDropFolder": {
			"type": "string",
			"defaultValue": "@triggerBody().folderPath"
		},
		"Real Estate Statement Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceFileDropFile": {
			"type": "string",
			"defaultValue": "@triggerBody().fileName"
		},
		"Real Estate Statement Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceSystemName": {
			"type": "string",
			"defaultValue": "AIML-OCR"
		},
		"Real Estate Statement Event_properties_Ingest_AIML_CustomInferenceFile_parameters_StreamName": {
			"type": "string",
			"defaultValue": "restatements"
		},
		"Real Estate Statement Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SparkPool": {
			"type": "string",
			"defaultValue": "smallMO"
		},
		"Real Estate Statement Event_properties_typeProperties_scope": {
			"type": "string",
			"defaultValue": "/subscriptions/735994b1-b3b0-46d5-96bc-c9b30ddb4265/resourceGroups/rg-aiml/providers/Microsoft.Storage/storageAccounts/baaimlstorage01o2katdvwv"
		},
		"SEC Form10Q Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceFileDropFileSystem": {
			"type": "string",
			"defaultValue": "doci"
		},
		"SEC Form10Q Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceFileDropFolder": {
			"type": "string",
			"defaultValue": "@triggerBody().folderPath"
		},
		"SEC Form10Q Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceFileDropFile": {
			"type": "string",
			"defaultValue": "@triggerBody().fileName"
		},
		"SEC Form10Q Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceSystemName": {
			"type": "string",
			"defaultValue": "AIML-OCR"
		},
		"SEC Form10Q Event_properties_Ingest_AIML_CustomInferenceFile_parameters_StreamName": {
			"type": "string",
			"defaultValue": "form10q"
		},
		"SEC Form10Q Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SparkPool": {
			"type": "string",
			"defaultValue": "smallMO"
		},
		"SEC Form10Q Event_properties_typeProperties_scope": {
			"type": "string",
			"defaultValue": "/subscriptions/735994b1-b3b0-46d5-96bc-c9b30ddb4265/resourceGroups/rg-aiml/providers/Microsoft.Storage/storageAccounts/baaimlstorage01o2katdvwv"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/Copy from REST API')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "CopyREST2Parquet",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "RestSource",
								"httpRequestTimeout": "00:01:40",
								"requestInterval": "00.00:00:00.010",
								"requestMethod": "GET"
							},
							"sink": {
								"type": "ParquetSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings",
									"copyBehavior": "FlattenHierarchy"
								},
								"formatSettings": {
									"type": "ParquetWriteSettings"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"path": "['name']"
										},
										"sink": {
											"name": "name",
											"type": "String"
										}
									},
									{
										"source": {
											"path": "['friendlyName']"
										},
										"sink": {
											"name": "friendlyName",
											"type": "String"
										}
									},
									{
										"source": {
											"path": "['description']"
										},
										"sink": {
											"name": "description",
											"type": "String"
										}
									},
									{
										"source": {
											"path": "['systemData']['createdBy']"
										},
										"sink": {
											"name": "createdBy",
											"type": "String"
										}
									},
									{
										"source": {
											"path": "['systemData']['createdByType']"
										},
										"sink": {
											"name": "createdByType",
											"type": "String"
										}
									},
									{
										"source": {
											"path": "['systemData']['createdAt']"
										},
										"sink": {
											"name": "createdAt",
											"type": "DateTime"
										}
									},
									{
										"source": {
											"path": "['systemData']['lastModifiedByType']"
										},
										"sink": {
											"name": "lastModifiedByType",
											"type": "String"
										}
									},
									{
										"source": {
											"path": "['systemData']['lastModifiedAt']"
										},
										"sink": {
											"name": "lastModifiedAt",
											"type": "DateTime"
										}
									},
									{
										"source": {
											"path": "['collectionProvisioningState']"
										},
										"sink": {
											"name": "collectionProvisioningState",
											"type": "String"
										}
									},
									{
										"source": {
											"path": "['parentCollection']['type']"
										},
										"sink": {
											"name": "parentCollectionType",
											"type": "String"
										}
									},
									{
										"source": {
											"path": "['parentCollection']['referenceName']"
										},
										"sink": {
											"name": "parentCollectionReferenceName",
											"type": "String"
										}
									}
								],
								"collectionReference": "$['value']",
								"mapComplexValuesToString": true
							}
						},
						"inputs": [
							{
								"referenceName": "AtlasREST_API",
								"type": "DatasetReference",
								"parameters": {
									"RelativeUrl": {
										"value": "@pipeline().parameters.EntityName",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "Bronze_Parquet",
								"type": "DatasetReference",
								"parameters": {
									"FileSystem": {
										"value": "@pipeline().parameters.DestinationRawFileSystem",
										"type": "Expression"
									},
									"Folder": {
										"value": "@pipeline().parameters.DestinationRawFolder",
										"type": "Expression"
									},
									"File": {
										"value": "@pipeline().parameters.DestinationRawFile",
										"type": "Expression"
									}
								}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"EntityName": {
						"type": "string",
						"defaultValue": "/collections?api-version=2019-11-01-preview"
					},
					"DestinationRawFileSystem": {
						"type": "string",
						"defaultValue": "raw-bronze"
					},
					"DestinationRawFolder": {
						"type": "string",
						"defaultValue": "purview/collections/2022-06"
					},
					"DestinationRawFile": {
						"type": "string",
						"defaultValue": "collections_20220625.parquet"
					}
				},
				"folder": {
					"name": "Sandbox"
				},
				"annotations": [],
				"lastPublishTime": "2023-06-25T08:42:47Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/AtlasREST_API')]",
				"[concat(variables('workspaceId'), '/datasets/Bronze_Parquet')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Copy using Parametrized DataMapping')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "CopyREST2Parquet",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Set datamapping",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "RestSource",
								"httpRequestTimeout": "00:01:40",
								"requestInterval": "00.00:00:00.010",
								"requestMethod": "GET"
							},
							"sink": {
								"type": "ParquetSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings",
									"copyBehavior": "FlattenHierarchy"
								},
								"formatSettings": {
									"type": "ParquetWriteSettings"
								}
							},
							"enableStaging": false,
							"translator": {
								"value": "@json(variables('datamapping'))",
								"type": "Expression"
							}
						},
						"inputs": [
							{
								"referenceName": "AtlasREST_API",
								"type": "DatasetReference",
								"parameters": {
									"RelativeUrl": {
										"value": "@pipeline().parameters.EntityName",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "Bronze_Parquet",
								"type": "DatasetReference",
								"parameters": {
									"FileSystem": {
										"value": "@pipeline().parameters.DestinationRawFileSystem",
										"type": "Expression"
									},
									"Folder": {
										"value": "@pipeline().parameters.DestinationRawFolder",
										"type": "Expression"
									},
									"File": {
										"value": "@pipeline().parameters.DestinationRawFile",
										"type": "Expression"
									}
								}
							}
						]
					},
					{
						"name": "Set datamapping",
						"type": "SetVariable",
						"dependsOn": [],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "datamapping",
							"value": " {\n    \"type\": \"TabularTranslator\",\n    \"mappings\": [\n        {\n            \"source\": {\n                \"path\": \"['name']\"\n            },\n            \"sink\": {\n                \"name\": \"name\",\n                \"type\": \"String\"\n            }\n        },\n        {\n            \"source\": {\n                \"path\": \"['friendlyName']\"\n            },\n            \"sink\": {\n                \"name\": \"friendlyName\",\n                \"type\": \"String\"\n            }\n        },\n        {\n            \"source\": {\n                \"path\": \"['description']\"\n            },\n            \"sink\": {\n                \"name\": \"description\",\n                \"type\": \"String\"\n            }\n        },\n        {\n            \"source\": {\n                \"path\": \"['systemData']['createdBy']\"\n            },\n            \"sink\": {\n                \"name\": \"createdBy\",\n                \"type\": \"String\"\n            }\n        },\n        {\n            \"source\": {\n                \"path\": \"['systemData']['createdByType']\"\n            },\n            \"sink\": {\n                \"name\": \"createdByType\",\n                \"type\": \"String\"\n            }\n        },\n        {\n            \"source\": {\n                \"path\": \"['systemData']['createdAt']\"\n            },\n            \"sink\": {\n                \"name\": \"createdAt\",\n                \"type\": \"DateTime\"\n            }\n        },\n        {\n            \"source\": {\n                \"path\": \"['systemData']['lastModifiedByType']\"\n            },\n            \"sink\": {\n                \"name\": \"lastModifiedByType\",\n                \"type\": \"String\"\n            }\n        },\n        {\n            \"source\": {\n                \"path\": \"['systemData']['lastModifiedAt']\"\n            },\n            \"sink\": {\n                \"name\": \"lastModifiedAt\",\n                \"type\": \"DateTime\"\n            }\n        },\n        {\n            \"source\": {\n                \"path\": \"['collectionProvisioningState']\"\n            },\n            \"sink\": {\n                \"name\": \"collectionProvisioningState\",\n                \"type\": \"String\"\n            }\n        },\n        {\n            \"source\": {\n                \"path\": \"['parentCollection']['type']\"\n            },\n            \"sink\": {\n                \"name\": \"parentCollectionType\",\n                \"type\": \"String\"\n            }\n        },\n        {\n            \"source\": {\n                \"path\": \"['parentCollection']['referenceName']\"\n            },\n            \"sink\": {\n                \"name\": \"parentCollectionReferenceName\",\n                \"type\": \"String\"\n            }\n        }\n    ],\n    \"collectionReference\": \"$['value']\",\n    \"mapComplexValuesToString\": true\n}"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"EntityName": {
						"type": "string",
						"defaultValue": "collections?api-version=2019-11-01-preview"
					},
					"DestinationRawFileSystem": {
						"type": "string",
						"defaultValue": "raw-bronze"
					},
					"DestinationRawFolder": {
						"type": "string",
						"defaultValue": "purview/collections/2022-06"
					},
					"DestinationRawFile": {
						"type": "string",
						"defaultValue": "collections_20220625.parquet"
					}
				},
				"variables": {
					"datamapping": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Sandbox"
				},
				"annotations": [],
				"lastPublishTime": "2023-06-25T08:42:52Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/AtlasREST_API')]",
				"[concat(variables('workspaceId'), '/datasets/Bronze_Parquet')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Get Bearer Auth')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Get Bearer Token",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "POST",
							"headers": {
								"Content-Type": "application/x-www-form-urlencoded"
							},
							"url": "https://login.microsoftonline.com/72f988bf-86f1-41af-91ab-2d7cd011db47/oauth2/token",
							"connectVia": {
								"referenceName": "AutoResolveIntegrationRuntime",
								"type": "IntegrationRuntimeReference"
							},
							"body": {
								"value": "tenant=@{pipeline().parameters.TenantID}&client_id=@{pipeline().parameters.ClientID}&client_secret=@{pipeline().parameters.ClientSecret}&grant_type=client_credentials&scope=https://purview.azure.net",
								"type": "Expression"
							}
						}
					},
					{
						"name": "Set BearerToken",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Get Bearer Token",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "BearerToken",
							"value": {
								"value": "@activity('Get Bearer Token').output.access_token",
								"type": "Expression"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"TenantID": {
						"type": "string",
						"defaultValue": "72f988bf-86f1-41af-91ab-2d7cd011db47"
					},
					"ClientID": {
						"type": "string",
						"defaultValue": "5e07b142-92b4-4671-83c0-e824bc93da6c"
					},
					"ClientSecret": {
						"type": "string"
					}
				},
				"variables": {
					"BearerToken": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Sandbox"
				},
				"annotations": [],
				"lastPublishTime": "2023-06-25T08:39:18Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/IngestREST')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Generic Pipeline to ingest data from any REST API",
				"activities": [
					{
						"name": "Ingest Running",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ADFPipelineRunID",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[ELT].[InsertIngestInstance]",
							"storedProcedureParameters": {
								"ADFPipelineRunID": {
									"value": {
										"value": "@variables('ADFPipelineRunID')",
										"type": "Expression"
									},
									"type": "Guid"
								},
								"DestinationRawFile": {
									"value": {
										"value": "@pipeline().parameters.DestinationRawFile",
										"type": "Expression"
									},
									"type": "String"
								},
								"DestinationRawFileSystem": {
									"value": {
										"value": "@pipeline().parameters.DestinationRawFileSystem",
										"type": "Expression"
									},
									"type": "String"
								},
								"DestinationRawFolder": {
									"value": {
										"value": "@pipeline().parameters.DestinationRawFolder",
										"type": "Expression"
									},
									"type": "String"
								},
								"IngestID": {
									"value": {
										"value": "@pipeline().parameters.IngestID",
										"type": "Expression"
									},
									"type": "Int32"
								},
								"ReloadFlag": {
									"value": {
										"value": "@pipeline().parameters.ReloadFlag",
										"type": "Expression"
									},
									"type": "Boolean"
								},
								"SourceFileDropFile": {
									"value": null,
									"type": "String"
								},
								"SourceFileDropFileSystem": {
									"value": null,
									"type": "String"
								},
								"SourceFileDropFolder": {
									"value": null,
									"type": "String"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "ControlDB",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Source To Datalake Bronze Zone",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Ingest Running",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "RestSource",
								"httpRequestTimeout": "00:01:40",
								"requestInterval": "00.00:00:00.010",
								"requestMethod": "GET",
								"paginationRules": {
									"supportRFC5988": "true"
								}
							},
							"sink": {
								"type": "ParquetSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "ParquetWriteSettings"
								}
							},
							"enableStaging": false,
							"translator": {
								"value": "@json(pipeline().parameters.DataMapping)",
								"type": "Expression"
							}
						},
						"inputs": [
							{
								"referenceName": "REST_API",
								"type": "DatasetReference",
								"parameters": {
									"BaseURL": {
										"value": "@pipeline().parameters.BaseURL",
										"type": "Expression"
									},
									"ServicePrincipalID": {
										"value": "@pipeline().parameters.ServicePrincipalID",
										"type": "Expression"
									},
									"TenantID": {
										"value": "@pipeline().parameters.TenantID",
										"type": "Expression"
									},
									"AADResource": {
										"value": "@pipeline().parameters.AADResource",
										"type": "Expression"
									},
									"RelativeURL": {
										"value": "@pipeline().parameters.SourceSQL",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "Bronze_Parquet",
								"type": "DatasetReference",
								"parameters": {
									"FileSystem": {
										"value": "@pipeline().parameters.DestinationRawFileSystem",
										"type": "Expression"
									},
									"Folder": {
										"value": "@pipeline().parameters.DestinationRawFolder",
										"type": "Expression"
									},
									"File": {
										"value": "@pipeline().parameters.DestinationRawFile",
										"type": "Expression"
									}
								}
							}
						]
					},
					{
						"name": "ADFPipelineRunID",
						"type": "SetVariable",
						"dependsOn": [],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "ADFPipelineRunID",
							"value": {
								"value": "@{if(empty(pipeline().parameters.ADFPipelineRunID),pipeline().RunId,pipeline().parameters.ADFPipelineRunID)}",
								"type": "Expression"
							}
						}
					},
					{
						"name": "Ingest Success",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Source To Datalake Bronze Zone",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[ELT].[UpdateIngestInstance]",
							"storedProcedureParameters": {
								"ADFIngestPipelineRunID": {
									"value": {
										"value": "@variables('ADFPipelineRunID')",
										"type": "Expression"
									},
									"type": "Guid"
								},
								"DataFromNumber": {
									"value": null,
									"type": "Int32"
								},
								"DataFromTimestamp": {
									"value": null,
									"type": "DateTime"
								},
								"DataToNumber": {
									"value": null,
									"type": "Int32"
								},
								"DataToTimestamp": {
									"value": null,
									"type": "DateTime"
								},
								"IngestCount": {
									"value": {
										"value": "@activity('Source To Datalake Bronze Zone').output.rowsCopied",
										"type": "Expression"
									},
									"type": "Int32"
								},
								"IngestStatus": {
									"value": "Success",
									"type": "String"
								},
								"ReloadFlag": {
									"value": {
										"value": "@pipeline().parameters.ReloadFlag",
										"type": "Expression"
									},
									"type": "Boolean"
								},
								"SourceCount": {
									"value": {
										"value": "@activity('Source To Datalake Bronze Zone').output.rowsRead",
										"type": "Expression"
									},
									"type": "Int32"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "ControlDB",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Ingest Failure",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Source To Datalake Bronze Zone",
								"dependencyConditions": [
									"Failed"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[ELT].[UpdateIngestInstance]",
							"storedProcedureParameters": {
								"ADFIngestPipelineRunID": {
									"value": {
										"value": "@variables('ADFPipelineRunID')",
										"type": "Expression"
									},
									"type": "Guid"
								},
								"DataFromNumber": {
									"value": null,
									"type": "Int32"
								},
								"DataFromTimestamp": {
									"value": null,
									"type": "DateTime"
								},
								"DataToNumber": {
									"value": null,
									"type": "Int32"
								},
								"DataToTimestamp": {
									"value": null,
									"type": "DateTime"
								},
								"IngestCount": {
									"value": null,
									"type": "Int32"
								},
								"IngestStatus": {
									"value": "Failure",
									"type": "String"
								},
								"ReloadFlag": {
									"value": {
										"value": "@pipeline().parameters.ReloadFlag",
										"type": "Expression"
									},
									"type": "Boolean"
								},
								"SourceCount": {
									"value": null,
									"type": "Int32"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "ControlDB",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Get L1Transform Definition",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "Ingest Success",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderStoredProcedureName": "[ELT].[GetTransformDefinition_L1]",
								"storedProcedureParameters": {
									"DeltaDate": {
										"type": "DateTime",
										"value": {
											"value": "@pipeline().parameters.DataFromTimestamp",
											"type": "Expression"
										}
									},
									"IngestID": {
										"type": "Int32",
										"value": {
											"value": "@pipeline().parameters.IngestID",
											"type": "Expression"
										}
									}
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "ControlDB_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"Table": "NotApplicable",
									"Schema": "NotApplicable"
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "Get L2Transform Definition",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "ForEach L1Transform",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderStoredProcedureName": "[ELT].[GetTransformDefinition_L2]",
								"storedProcedureParameters": {
									"DeltaDate": {
										"type": "DateTime",
										"value": {
											"value": "@pipeline().parameters.DataFromTimestamp",
											"type": "Expression"
										}
									},
									"IngestID": {
										"type": "Int32",
										"value": {
											"value": "@pipeline().parameters.IngestID",
											"type": "Expression"
										}
									},
									"InputType": {
										"type": "String",
										"value": null
									}
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "ControlDB_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"Table": "NotApplicable",
									"Schema": "NotApplicable"
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ForEach L2Transform",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get L2Transform Definition",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get L2Transform Definition').output.value",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Insert L2Transform Instance",
									"type": "SqlServerStoredProcedure",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"storedProcedureName": "[ELT].[InsertTransformInstance_L2]",
										"storedProcedureParameters": {
											"CustomParameters": {
												"value": {
													"value": "@item().CustomParameters",
													"type": "Expression"
												},
												"type": "String"
											},
											"DataFromNumber": {
												"value": {
													"value": "@item().DataFromNumber",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"DataFromTimestamp": {
												"value": {
													"value": "@item().DataToTimestamp",
													"type": "Expression"
												},
												"type": "DateTime"
											},
											"DataToNumber": {
												"value": {
													"value": "@item().DataToNumber",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"DataToTimestamp": {
												"value": {
													"value": "@item().DataToTimestamp",
													"type": "Expression"
												},
												"type": "DateTime"
											},
											"DeltaName": {
												"value": {
													"value": "@item().DeltaName",
													"type": "Expression"
												},
												"type": "String"
											},
											"IngestADFPipelineRunID": {
												"value": {
													"value": "@variables('ADFPipelineRunID')",
													"type": "Expression"
												},
												"type": "Guid"
											},
											"IngestID": {
												"value": {
													"value": "@item().IngestID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"InputDWTable": {
												"value": {
													"value": "@item().InputDWTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFile": {
												"value": {
													"value": "@item().InputFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFileDelimiter": {
												"value": {
													"value": "@item().InputFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFileFolder": {
												"value": {
													"value": "@item().InputFileFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFileHeaderFlag": {
												"value": {
													"value": "@item().InputFileHeaderFlag",
													"type": "Expression"
												},
												"type": "Boolean"
											},
											"InputFileSystem": {
												"value": {
													"value": "@item().InputFileSystem",
													"type": "Expression"
												},
												"type": "String"
											},
											"L1TransformADFPipelineRunID": {
												"value": null,
												"type": "Guid"
											},
											"L1TransformID": {
												"value": {
													"value": "@item().L1TransformID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"L2TransformID": {
												"value": {
													"value": "@item().L2TransformID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"LastDeltaDate": {
												"value": null,
												"type": "DateTime"
											},
											"LastDeltaNumber": {
												"value": null,
												"type": "Int32"
											},
											"LookupColumns": {
												"value": {
													"value": "@item().LookupColumns",
													"type": "Expression"
												},
												"type": "String"
											},
											"MaxRetries": {
												"value": {
													"value": "@item().MaxRetries",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"NotebookName": {
												"value": {
													"value": "@item().NotebookName",
													"type": "Expression"
												},
												"type": "String"
											},
											"NotebookPath": {
												"value": {
													"value": "@item().NotebookPath",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWStagingTable": {
												"value": {
													"value": "@item().OutputDWStagingTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTable": {
												"value": {
													"value": "@item().OutputDWTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTableWriteMode": {
												"value": {
													"value": "@item().OutputDWTableWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFile": {
												"value": {
													"value": "@item().OutputL2CuratedFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFileDelimiter": {
												"value": {
													"value": "@item().OutputL2CuratedFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFileFormat": {
												"value": {
													"value": "@item().OutputL2CuratedFileFormat",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFileWriteMode": {
												"value": {
													"value": "@item().OutputL2CuratedFileWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFolder": {
												"value": {
													"value": "@item().OutputL2CuratedFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CurateFileSystem": {
												"value": {
													"value": "@item().OutputL2CurateFileSystem",
													"type": "Expression"
												},
												"type": "String"
											}
										}
									},
									"linkedServiceName": {
										"referenceName": "ControlDB",
										"type": "LinkedServiceReference"
									}
								}
							]
						}
					},
					{
						"name": "ForEach L1Transform",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get L1Transform Definition",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get L1Transform Definition').output.value",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Insert L1Transform Instance",
									"type": "SqlServerStoredProcedure",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"storedProcedureName": "[ELT].[InsertTransformInstance_L1]",
										"storedProcedureParameters": {
											"CustomParameters": {
												"value": {
													"value": "@item().CustomParameters",
													"type": "Expression"
												},
												"type": "String"
											},
											"IngestADFPipelineRunID": {
												"value": {
													"value": "@variables('ADFPipelineRunID')",
													"type": "Expression"
												},
												"type": "Guid"
											},
											"IngestCount": {
												"value": {
													"value": "@activity('Source To Datalake Bronze Zone').output.rowsCopied",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"IngestID": {
												"value": {
													"value": "@item().IngestID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"IngestInstanceID": {
												"value": null,
												"type": "Int32"
											},
											"InputFileHeaderFlag": {
												"value": {
													"value": "@item().InputFileHeaderFlag",
													"type": "Expression"
												},
												"type": "Boolean"
											},
											"InputRawFile": {
												"value": {
													"value": "@pipeline().parameters.DestinationRawFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputRawFileDelimiter": {
												"value": {
													"value": "@item().InputRawFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputRawFileFolder": {
												"value": {
													"value": "@pipeline().parameters.DestinationRawFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputRawFileSystem": {
												"value": {
													"value": "@pipeline().parameters.DestinationRawFileSystem",
													"type": "Expression"
												},
												"type": "String"
											},
											"L1TransformID": {
												"value": {
													"value": "@item().L1TransformID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"LookupColumns": {
												"value": {
													"value": "@item().LookupColumns",
													"type": "Expression"
												},
												"type": "String"
											},
											"NotebookName": {
												"value": {
													"value": "@item().NotebookName",
													"type": "Expression"
												},
												"type": "String"
											},
											"NotebookPath": {
												"value": {
													"value": "@item().NotebookPath",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWStagingTable": {
												"value": {
													"value": "@item().OutputDWStagingTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTable": {
												"value": {
													"value": "@item().OutputDWTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTableWriteMode": {
												"value": {
													"value": "@item().OutputDWTableWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFile": {
												"value": {
													"value": "@item().OutputL1CuratedFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFileDelimiter": {
												"value": {
													"value": "@item().OutputL1CuratedFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFileFormat": {
												"value": {
													"value": "@item().OutputL1CuratedFileFormat",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFileWriteMode": {
												"value": {
													"value": "@item().OutputL1CuratedFileWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFolder": {
												"value": {
													"value": "@item().OutputL1CuratedFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CurateFileSystem": {
												"value": {
													"value": "@item().OutputL1CurateFileSystem",
													"type": "Expression"
												},
												"type": "String"
											}
										}
									},
									"linkedServiceName": {
										"referenceName": "ControlDB",
										"type": "LinkedServiceReference"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"IngestID": {
						"type": "int"
					},
					"SourceSystemName": {
						"type": "string"
					},
					"StreamName": {
						"type": "string"
					},
					"Backend": {
						"type": "string"
					},
					"EntityName": {
						"type": "string"
					},
					"DeltaName": {
						"type": "string"
					},
					"LastDeltaDate": {
						"type": "string"
					},
					"DataFromTimestamp": {
						"type": "string"
					},
					"DataToTimestamp": {
						"type": "string"
					},
					"LastDeltaNumber": {
						"type": "int"
					},
					"DataFromNumber": {
						"type": "int"
					},
					"DataToNumber": {
						"type": "int"
					},
					"DataFormat": {
						"type": "string"
					},
					"SourceStructure": {
						"type": "string"
					},
					"MaxIntervalMinutes": {
						"type": "int"
					},
					"MaxIntervalNumber": {
						"type": "int"
					},
					"DataMapping": {
						"type": "string"
					},
					"RunSequence": {
						"type": "int"
					},
					"ActiveFlag": {
						"type": "bool"
					},
					"L1TransformationReqdFlag": {
						"type": "string"
					},
					"L2TransformationReqdFlag": {
						"type": "string"
					},
					"DelayL1TransformationFlag": {
						"type": "bool"
					},
					"DelayL2TransformationFlag": {
						"type": "bool"
					},
					"DestinationRawFileSystem": {
						"type": "string"
					},
					"DestinationRawFolder": {
						"type": "string"
					},
					"DestinationRawFile": {
						"type": "string"
					},
					"SourceSQL": {
						"type": "string"
					},
					"StatSQL": {
						"type": "string"
					},
					"ReloadFlag": {
						"type": "bool"
					},
					"ADFPipelineRunID": {
						"type": "string"
					},
					"BaseURL": {
						"type": "string"
					},
					"ServicePrincipalID": {
						"type": "string"
					},
					"TenantID": {
						"type": "string"
					},
					"AADResource": {
						"type": "string"
					}
				},
				"variables": {
					"ADFPipelineRunID": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Extract and Load/REST API Pipelines"
				},
				"annotations": [],
				"lastPublishTime": "2023-06-25T08:42:57Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ControlDB')]",
				"[concat(variables('workspaceId'), '/datasets/REST_API')]",
				"[concat(variables('workspaceId'), '/datasets/Bronze_Parquet')]",
				"[concat(variables('workspaceId'), '/datasets/ControlDB_Dataset')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/IngestUploadFile')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Pipelines that ingests a file from drop-zone of data lake",
				"activities": [
					{
						"name": "Get_IngestDefinition_FileDrop",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderStoredProcedureName": "[ELT].[GetIngestDefinition_FileDrop]",
								"storedProcedureParameters": {
									"SourceFile": {
										"type": "String",
										"value": {
											"value": "@pipeline().parameters.SourceFileDropFile",
											"type": "Expression"
										}
									},
									"SourceFolder": {
										"type": "String",
										"value": {
											"value": "@pipeline().parameters.SourceFileDropFolder",
											"type": "Expression"
										}
									},
									"SourceSystemName": {
										"type": "String",
										"value": {
											"value": "@pipeline().parameters.SourceSystemName",
											"type": "Expression"
										}
									},
									"StreamName": {
										"type": "String",
										"value": {
											"value": "@pipeline().parameters.StreamName",
											"type": "Expression"
										}
									}
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "ControlDB_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"Table": "Not Applicable",
									"Schema": "Not Applicable"
								}
							}
						}
					},
					{
						"name": "IngestInstance - Running",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Set PipelineRunID",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[ELT].[InsertIngestInstance]",
							"storedProcedureParameters": {
								"ADFPipelineRunID": {
									"value": {
										"value": "@variables('PipelineRunID')",
										"type": "Expression"
									},
									"type": "Guid"
								},
								"DestinationRawFile": {
									"value": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFile",
										"type": "Expression"
									},
									"type": "String"
								},
								"DestinationRawFileSystem": {
									"value": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFileSystem",
										"type": "Expression"
									},
									"type": "String"
								},
								"DestinationRawFolder": {
									"value": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFolder",
										"type": "Expression"
									},
									"type": "String"
								},
								"IngestID": {
									"value": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.IngestID",
										"type": "Expression"
									},
									"type": "Int32"
								},
								"ReloadFlag": {
									"value": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.ReloadFlag",
										"type": "Expression"
									},
									"type": "Boolean"
								},
								"SourceFileDropFile": {
									"value": {
										"value": "@pipeline().parameters.SourceFileDropFile",
										"type": "Expression"
									},
									"type": "String"
								},
								"SourceFileDropFileSystem": {
									"value": {
										"value": "@pipeline().parameters.SourceFileDropFileSystem",
										"type": "Expression"
									},
									"type": "String"
								},
								"SourceFileDropFolder": {
									"value": {
										"value": "@pipeline().parameters.SourceFileDropFolder",
										"type": "Expression"
									},
									"type": "String"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "ControlDB",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Set PipelineRunID",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Get_IngestDefinition_FileDrop",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "PipelineRunID",
							"value": {
								"value": "@pipeline().RunId",
								"type": "Expression"
							}
						}
					},
					{
						"name": "DropZone2Raw",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "IngestInstance - Running",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "JsonSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "JsonReadSettings"
								}
							},
							"sink": {
								"type": "JsonSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "JsonWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "Drop_JSON",
								"type": "DatasetReference",
								"parameters": {
									"FileSystem": {
										"value": "@pipeline().parameters.SourceFileDropFileSystem",
										"type": "Expression"
									},
									"Folder": {
										"value": "@replace(pipeline().parameters.SourceFileDropFolder,concat(pipeline().parameters.SourceFileDropFileSystem,'/'),'')",
										"type": "Expression"
									},
									"File": {
										"value": "@pipeline().parameters.SourceFileDropFile",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "Bronze_JSON",
								"type": "DatasetReference",
								"parameters": {
									"FileSystem": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFileSystem",
										"type": "Expression"
									},
									"Folder": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFolder",
										"type": "Expression"
									},
									"File": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFile",
										"type": "Expression"
									}
								}
							}
						]
					},
					{
						"name": "IngestInstance - Success",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "DropZone2Raw",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[ELT].[UpdateIngestInstance]",
							"storedProcedureParameters": {
								"ADFIngestPipelineRunID": {
									"value": {
										"value": "@variables('PipelineRunID')",
										"type": "Expression"
									},
									"type": "Guid"
								},
								"DataFromNumber": {
									"value": null,
									"type": "Int32"
								},
								"DataFromTimestamp": {
									"value": null,
									"type": "DateTime"
								},
								"DataToNumber": {
									"value": null,
									"type": "Int32"
								},
								"DataToTimestamp": {
									"value": null,
									"type": "DateTime"
								},
								"IngestCount": {
									"value": {
										"value": "@activity('DropZone2Raw').output.filesWritten",
										"type": "Expression"
									},
									"type": "Int32"
								},
								"IngestStatus": {
									"value": "Success",
									"type": "String"
								},
								"ReloadFlag": {
									"value": "false",
									"type": "Boolean"
								},
								"SourceCount": {
									"value": {
										"value": "@activity('DropZone2Raw').output.filesRead",
										"type": "Expression"
									},
									"type": "Int32"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "ControlDB",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "IngestInstance - Failure",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "DropZone2Raw",
								"dependencyConditions": [
									"Failed"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[ELT].[UpdateIngestInstance]",
							"storedProcedureParameters": {
								"ADFIngestPipelineRunID": {
									"value": {
										"value": "@variables('PipelineRunID')",
										"type": "Expression"
									},
									"type": "Guid"
								},
								"DataFromNumber": {
									"value": null,
									"type": "Int32"
								},
								"DataFromTimestamp": {
									"value": null,
									"type": "DateTime"
								},
								"DataToNumber": {
									"value": null,
									"type": "Int32"
								},
								"DataToTimestamp": {
									"value": null,
									"type": "DateTime"
								},
								"IngestCount": {
									"value": null,
									"type": "Int32"
								},
								"IngestStatus": {
									"value": "Failure",
									"type": "String"
								},
								"ReloadFlag": {
									"value": "true",
									"type": "Boolean"
								},
								"SourceCount": {
									"value": null,
									"type": "Int32"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "ControlDB",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Get L1Transform Definition",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "IngestInstance - Success",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderStoredProcedureName": "[ELT].[GetTransformDefinition_L1]",
								"storedProcedureParameters": {
									"DeltaDate": {
										"type": "DateTime",
										"value": null
									},
									"IngestID": {
										"type": "Int32",
										"value": {
											"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.IngestID",
											"type": "Expression"
										}
									}
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "ControlDB_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"Table": "NotApplicable",
									"Schema": "NotApplicable"
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "Get L2Transform Definition",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "ForEach L1Transform",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderStoredProcedureName": "[ELT].[GetTransformDefinition_L2]",
								"storedProcedureParameters": {
									"DeltaDate": {
										"type": "DateTime",
										"value": null
									},
									"IngestID": {
										"type": "Int32",
										"value": {
											"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.IngestID",
											"type": "Expression"
										}
									},
									"InputType": {
										"type": "String",
										"value": null
									}
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "ControlDB_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"Table": "NotApplicable",
									"Schema": "NotApplicable"
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ForEach L2Transform",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get L2Transform Definition",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get L2Transform Definition').output.value",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Insert L2Transform Instance",
									"type": "SqlServerStoredProcedure",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"storedProcedureName": "[ELT].[InsertTransformInstance_L2]",
										"storedProcedureParameters": {
											"CustomParameters": {
												"value": {
													"value": "@item().CustomParameters",
													"type": "Expression"
												},
												"type": "String"
											},
											"DataFromNumber": {
												"value": {
													"value": "@item().DataFromNumber",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"DataFromTimestamp": {
												"value": {
													"value": "@item().DataToTimestamp",
													"type": "Expression"
												},
												"type": "DateTime"
											},
											"DataToNumber": {
												"value": {
													"value": "@item().DataToNumber",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"DataToTimestamp": {
												"value": {
													"value": "@item().DataToTimestamp",
													"type": "Expression"
												},
												"type": "DateTime"
											},
											"DeltaName": {
												"value": {
													"value": "@item().DeltaName",
													"type": "Expression"
												},
												"type": "String"
											},
											"IngestADFPipelineRunID": {
												"value": {
													"value": "@variables('PipelineRunID')",
													"type": "Expression"
												},
												"type": "Guid"
											},
											"IngestID": {
												"value": {
													"value": "@item().IngestID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"InputDWTable": {
												"value": {
													"value": "@item().InputDWTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFile": {
												"value": {
													"value": "@item().InputFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFileDelimiter": {
												"value": {
													"value": "@item().InputFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFileFolder": {
												"value": {
													"value": "@item().InputFileFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFileHeaderFlag": {
												"value": {
													"value": "@item().InputFileHeaderFlag",
													"type": "Expression"
												},
												"type": "Boolean"
											},
											"InputFileSystem": {
												"value": {
													"value": "@item().InputFileSystem",
													"type": "Expression"
												},
												"type": "String"
											},
											"L1TransformADFPipelineRunID": {
												"value": null,
												"type": "Guid"
											},
											"L1TransformID": {
												"value": {
													"value": "@item().L1TransformID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"L2TransformID": {
												"value": {
													"value": "@item().L2TransformID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"LastDeltaDate": {
												"value": null,
												"type": "DateTime"
											},
											"LastDeltaNumber": {
												"value": null,
												"type": "Int32"
											},
											"LookupColumns": {
												"value": {
													"value": "@item().LookupColumns",
													"type": "Expression"
												},
												"type": "String"
											},
											"MaxRetries": {
												"value": {
													"value": "@item().MaxRetries",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"NotebookName": {
												"value": {
													"value": "@item().NotebookName",
													"type": "Expression"
												},
												"type": "String"
											},
											"NotebookPath": {
												"value": {
													"value": "@item().NotebookPath",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWStagingTable": {
												"value": {
													"value": "@item().OutputDWStagingTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTable": {
												"value": {
													"value": "@item().OutputDWTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTableWriteMode": {
												"value": {
													"value": "@item().OutputDWTableWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFile": {
												"value": {
													"value": "@item().OutputL2CuratedFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFileDelimiter": {
												"value": {
													"value": "@item().OutputL2CuratedFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFileFormat": {
												"value": {
													"value": "@item().OutputL2CuratedFileFormat",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFileWriteMode": {
												"value": {
													"value": "@item().OutputL2CuratedFileWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFolder": {
												"value": {
													"value": "@item().OutputL2CuratedFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CurateFileSystem": {
												"value": {
													"value": "@item().OutputL2CurateFileSystem",
													"type": "Expression"
												},
												"type": "String"
											}
										}
									},
									"linkedServiceName": {
										"referenceName": "ControlDB",
										"type": "LinkedServiceReference"
									}
								}
							]
						}
					},
					{
						"name": "ForEach L1Transform",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get L1Transform Definition",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get L1Transform Definition').output.value",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Insert L1Transform Instance",
									"type": "SqlServerStoredProcedure",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"storedProcedureName": "[ELT].[InsertTransformInstance_L1]",
										"storedProcedureParameters": {
											"CustomParameters": {
												"value": {
													"value": "@item().CustomParameters",
													"type": "Expression"
												},
												"type": "String"
											},
											"IngestADFPipelineRunID": {
												"value": {
													"value": "@variables('PipelineRunID')",
													"type": "Expression"
												},
												"type": "Guid"
											},
											"IngestCount": {
												"value": {
													"value": "@activity('DropZone2Raw').output.filesWritten",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"IngestID": {
												"value": {
													"value": "@item().IngestID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"IngestInstanceID": {
												"value": null,
												"type": "Int32"
											},
											"InputFileHeaderFlag": {
												"value": {
													"value": "@item().InputFileHeaderFlag",
													"type": "Expression"
												},
												"type": "Boolean"
											},
											"InputRawFile": {
												"value": {
													"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputRawFileDelimiter": {
												"value": {
													"value": "@item().InputRawFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputRawFileFolder": {
												"value": {
													"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputRawFileSystem": {
												"value": {
													"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFileSystem",
													"type": "Expression"
												},
												"type": "String"
											},
											"L1TransformID": {
												"value": {
													"value": "@item().L1TransformID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"LookupColumns": {
												"value": {
													"value": "@item().LookupColumns",
													"type": "Expression"
												},
												"type": "String"
											},
											"NotebookName": {
												"value": {
													"value": "@item().NotebookName",
													"type": "Expression"
												},
												"type": "String"
											},
											"NotebookPath": {
												"value": {
													"value": "@item().NotebookPath",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWStagingTable": {
												"value": {
													"value": "@item().OutputDWStagingTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTable": {
												"value": {
													"value": "@item().OutputDWTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTableWriteMode": {
												"value": {
													"value": "@item().OutputDWTableWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFile": {
												"value": {
													"value": "@item().OutputL1CuratedFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFileDelimiter": {
												"value": {
													"value": "@item().OutputL1CuratedFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFileFormat": {
												"value": {
													"value": "@item().OutputL1CuratedFileFormat",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFileWriteMode": {
												"value": {
													"value": "@item().OutputL1CuratedFileWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFolder": {
												"value": {
													"value": "@item().OutputL1CuratedFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CurateFileSystem": {
												"value": {
													"value": "@item().OutputL1CurateFileSystem",
													"type": "Expression"
												},
												"type": "String"
											}
										}
									},
									"linkedServiceName": {
										"referenceName": "ControlDB",
										"type": "LinkedServiceReference"
									}
								}
							]
						}
					},
					{
						"name": "L1 Transform",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "ForEach L1Transform",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "Master L1Transform Generic",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"SourceSystemName": {
									"value": "@pipeline().parameters.SourceSystemName",
									"type": "Expression"
								},
								"StreamName": {
									"value": "@pipeline().parameters.StreamName",
									"type": "Expression"
								},
								"MaxTransformInstance": 20,
								"DelayL1TransformationFlag": 0,
								"SparkPool": {
									"value": "@pipeline().parameters.SparkPool",
									"type": "Expression"
								}
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"SourceFileDropFileSystem": {
						"type": "string"
					},
					"SourceFileDropFolder": {
						"type": "string"
					},
					"SourceFileDropFile": {
						"type": "string"
					},
					"SourceSystemName": {
						"type": "string"
					},
					"StreamName": {
						"type": "string"
					},
					"SparkPool": {
						"type": "string"
					}
				},
				"variables": {
					"PipelineRunID": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Extract and Load/Upload File Pipelines"
				},
				"annotations": [],
				"lastPublishTime": "2023-06-25T08:43:05Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/ControlDB_Dataset')]",
				"[concat(variables('workspaceId'), '/linkedServices/ControlDB')]",
				"[concat(variables('workspaceId'), '/datasets/Drop_JSON')]",
				"[concat(variables('workspaceId'), '/datasets/Bronze_JSON')]",
				"[concat(variables('workspaceId'), '/pipelines/Master L1Transform Generic')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Ingest_AIML_CustomInferenceFile')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Pipelines that ingests a file from drop-zone of data lake",
				"activities": [
					{
						"name": "Get_IngestDefinition_FileDrop",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderStoredProcedureName": "[ELT].[GetIngestDefinition_FileDrop]",
								"storedProcedureParameters": {
									"SourceFile": {
										"type": "String",
										"value": {
											"value": "@pipeline().parameters.SourceFileDropFile",
											"type": "Expression"
										}
									},
									"SourceFolder": {
										"type": "String",
										"value": {
											"value": "@pipeline().parameters.SourceFileDropFolder",
											"type": "Expression"
										}
									},
									"SourceSystemName": {
										"type": "String",
										"value": {
											"value": "@pipeline().parameters.SourceSystemName",
											"type": "Expression"
										}
									},
									"StreamName": {
										"type": "String",
										"value": {
											"value": "@pipeline().parameters.StreamName",
											"type": "Expression"
										}
									}
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "ControlDB_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"Table": "Not Applicable",
									"Schema": "Not Applicable"
								}
							}
						}
					},
					{
						"name": "IngestInstance - Running",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Set PipelineRunID",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[ELT].[InsertIngestInstance]",
							"storedProcedureParameters": {
								"ADFPipelineRunID": {
									"value": {
										"value": "@variables('PipelineRunID')",
										"type": "Expression"
									},
									"type": "Guid"
								},
								"DestinationRawFile": {
									"value": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFile",
										"type": "Expression"
									},
									"type": "String"
								},
								"DestinationRawFileSystem": {
									"value": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFileSystem",
										"type": "Expression"
									},
									"type": "String"
								},
								"DestinationRawFolder": {
									"value": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFolder",
										"type": "Expression"
									},
									"type": "String"
								},
								"IngestID": {
									"value": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.IngestID",
										"type": "Expression"
									},
									"type": "Int32"
								},
								"ReloadFlag": {
									"value": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.ReloadFlag",
										"type": "Expression"
									},
									"type": "Boolean"
								},
								"SourceFileDropFile": {
									"value": {
										"value": "@pipeline().parameters.SourceFileDropFile",
										"type": "Expression"
									},
									"type": "String"
								},
								"SourceFileDropFileSystem": {
									"value": {
										"value": "@pipeline().parameters.SourceFileDropFileSystem",
										"type": "Expression"
									},
									"type": "String"
								},
								"SourceFileDropFolder": {
									"value": {
										"value": "@pipeline().parameters.SourceFileDropFolder",
										"type": "Expression"
									},
									"type": "String"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "ControlDB",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Set PipelineRunID",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Get_IngestDefinition_FileDrop",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "PipelineRunID",
							"value": {
								"value": "@pipeline().RunId",
								"type": "Expression"
							}
						}
					},
					{
						"name": "AIMLCustom2Raw",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "IngestInstance - Running",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "JsonSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "JsonReadSettings"
								}
							},
							"sink": {
								"type": "JsonSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "JsonWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "AIMLCustomModels_JSON",
								"type": "DatasetReference",
								"parameters": {
									"FileSystem": {
										"value": "@pipeline().parameters.SourceFileDropFileSystem",
										"type": "Expression"
									},
									"Folder": {
										"value": "@replace(pipeline().parameters.SourceFileDropFolder,concat(pipeline().parameters.SourceFileDropFileSystem,'/'),'')",
										"type": "Expression"
									},
									"File": {
										"value": "@pipeline().parameters.SourceFileDropFile",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "Bronze_JSON",
								"type": "DatasetReference",
								"parameters": {
									"FileSystem": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFileSystem",
										"type": "Expression"
									},
									"Folder": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFolder",
										"type": "Expression"
									},
									"File": {
										"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFile",
										"type": "Expression"
									}
								}
							}
						]
					},
					{
						"name": "IngestInstance - Success",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "AIMLCustom2Raw",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[ELT].[UpdateIngestInstance]",
							"storedProcedureParameters": {
								"ADFIngestPipelineRunID": {
									"value": {
										"value": "@variables('PipelineRunID')",
										"type": "Expression"
									},
									"type": "Guid"
								},
								"DataFromNumber": {
									"value": null,
									"type": "Int32"
								},
								"DataFromTimestamp": {
									"value": null,
									"type": "DateTime"
								},
								"DataToNumber": {
									"value": null,
									"type": "Int32"
								},
								"DataToTimestamp": {
									"value": null,
									"type": "DateTime"
								},
								"IngestCount": {
									"value": {
										"value": "@activity('AIMLCustom2Raw').output.filesWritten",
										"type": "Expression"
									},
									"type": "Int32"
								},
								"IngestStatus": {
									"value": "Success",
									"type": "String"
								},
								"ReloadFlag": {
									"value": "false",
									"type": "Boolean"
								},
								"SourceCount": {
									"value": {
										"value": "@activity('AIMLCustom2Raw').output.filesRead",
										"type": "Expression"
									},
									"type": "Int32"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "ControlDB",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "IngestInstance - Failure",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "AIMLCustom2Raw",
								"dependencyConditions": [
									"Failed"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[ELT].[UpdateIngestInstance]",
							"storedProcedureParameters": {
								"ADFIngestPipelineRunID": {
									"value": {
										"value": "@variables('PipelineRunID')",
										"type": "Expression"
									},
									"type": "Guid"
								},
								"DataFromNumber": {
									"value": null,
									"type": "Int32"
								},
								"DataFromTimestamp": {
									"value": null,
									"type": "DateTime"
								},
								"DataToNumber": {
									"value": null,
									"type": "Int32"
								},
								"DataToTimestamp": {
									"value": null,
									"type": "DateTime"
								},
								"IngestCount": {
									"value": null,
									"type": "Int32"
								},
								"IngestStatus": {
									"value": "Failure",
									"type": "String"
								},
								"ReloadFlag": {
									"value": "true",
									"type": "Boolean"
								},
								"SourceCount": {
									"value": null,
									"type": "Int32"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "ControlDB",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Get L1Transform Definition",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "IngestInstance - Success",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderStoredProcedureName": "[ELT].[GetTransformDefinition_L1]",
								"storedProcedureParameters": {
									"DeltaDate": {
										"type": "DateTime",
										"value": null
									},
									"IngestID": {
										"type": "Int32",
										"value": {
											"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.IngestID",
											"type": "Expression"
										}
									}
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "ControlDB_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"Table": "NotApplicable",
									"Schema": "NotApplicable"
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "Get L2Transform Definition",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "ForEach L1Transform",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderStoredProcedureName": "[ELT].[GetTransformDefinition_L2]",
								"storedProcedureParameters": {
									"DeltaDate": {
										"type": "DateTime",
										"value": null
									},
									"IngestID": {
										"type": "Int32",
										"value": {
											"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.IngestID",
											"type": "Expression"
										}
									},
									"InputType": {
										"type": "String",
										"value": null
									}
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "ControlDB_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"Table": "NotApplicable",
									"Schema": "NotApplicable"
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ForEach L2Transform",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get L2Transform Definition",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get L2Transform Definition').output.value",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Insert L2Transform Instance",
									"type": "SqlServerStoredProcedure",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"storedProcedureName": "[ELT].[InsertTransformInstance_L2]",
										"storedProcedureParameters": {
											"CustomParameters": {
												"value": {
													"value": "@item().CustomParameters",
													"type": "Expression"
												},
												"type": "String"
											},
											"DataFromNumber": {
												"value": {
													"value": "@item().DataFromNumber",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"DataFromTimestamp": {
												"value": {
													"value": "@item().DataToTimestamp",
													"type": "Expression"
												},
												"type": "DateTime"
											},
											"DataToNumber": {
												"value": {
													"value": "@item().DataToNumber",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"DataToTimestamp": {
												"value": {
													"value": "@item().DataToTimestamp",
													"type": "Expression"
												},
												"type": "DateTime"
											},
											"DeltaName": {
												"value": {
													"value": "@item().DeltaName",
													"type": "Expression"
												},
												"type": "String"
											},
											"IngestADFPipelineRunID": {
												"value": {
													"value": "@variables('PipelineRunID')",
													"type": "Expression"
												},
												"type": "Guid"
											},
											"IngestID": {
												"value": {
													"value": "@item().IngestID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"InputDWTable": {
												"value": {
													"value": "@item().InputDWTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFile": {
												"value": {
													"value": "@item().InputFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFileDelimiter": {
												"value": {
													"value": "@item().InputFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFileFolder": {
												"value": {
													"value": "@item().InputFileFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFileHeaderFlag": {
												"value": {
													"value": "@item().InputFileHeaderFlag",
													"type": "Expression"
												},
												"type": "Boolean"
											},
											"InputFileSystem": {
												"value": {
													"value": "@item().InputFileSystem",
													"type": "Expression"
												},
												"type": "String"
											},
											"L1TransformADFPipelineRunID": {
												"value": null,
												"type": "Guid"
											},
											"L1TransformID": {
												"value": {
													"value": "@item().L1TransformID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"L2TransformID": {
												"value": {
													"value": "@item().L2TransformID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"LastDeltaDate": {
												"value": null,
												"type": "DateTime"
											},
											"LastDeltaNumber": {
												"value": null,
												"type": "Int32"
											},
											"LookupColumns": {
												"value": {
													"value": "@item().LookupColumns",
													"type": "Expression"
												},
												"type": "String"
											},
											"MaxRetries": {
												"value": {
													"value": "@item().MaxRetries",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"NotebookName": {
												"value": {
													"value": "@item().NotebookName",
													"type": "Expression"
												},
												"type": "String"
											},
											"NotebookPath": {
												"value": {
													"value": "@item().NotebookPath",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWStagingTable": {
												"value": {
													"value": "@item().OutputDWStagingTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTable": {
												"value": {
													"value": "@item().OutputDWTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTableWriteMode": {
												"value": {
													"value": "@item().OutputDWTableWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFile": {
												"value": {
													"value": "@item().OutputL2CuratedFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFileDelimiter": {
												"value": {
													"value": "@item().OutputL2CuratedFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFileFormat": {
												"value": {
													"value": "@item().OutputL2CuratedFileFormat",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFileWriteMode": {
												"value": {
													"value": "@item().OutputL2CuratedFileWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFolder": {
												"value": {
													"value": "@item().OutputL2CuratedFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CurateFileSystem": {
												"value": {
													"value": "@item().OutputL2CurateFileSystem",
													"type": "Expression"
												},
												"type": "String"
											}
										}
									},
									"linkedServiceName": {
										"referenceName": "ControlDB",
										"type": "LinkedServiceReference"
									}
								}
							]
						}
					},
					{
						"name": "ForEach L1Transform",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get L1Transform Definition",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get L1Transform Definition').output.value",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Insert L1Transform Instance",
									"type": "SqlServerStoredProcedure",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"storedProcedureName": "[ELT].[InsertTransformInstance_L1]",
										"storedProcedureParameters": {
											"CustomParameters": {
												"value": {
													"value": "@item().CustomParameters",
													"type": "Expression"
												},
												"type": "String"
											},
											"IngestADFPipelineRunID": {
												"value": {
													"value": "@variables('PipelineRunID')",
													"type": "Expression"
												},
												"type": "Guid"
											},
											"IngestCount": {
												"value": {
													"value": "@activity('AIMLCustom2Raw').output.filesWritten",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"IngestID": {
												"value": {
													"value": "@item().IngestID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"IngestInstanceID": {
												"value": null,
												"type": "Int32"
											},
											"InputFileHeaderFlag": {
												"value": {
													"value": "@item().InputFileHeaderFlag",
													"type": "Expression"
												},
												"type": "Boolean"
											},
											"InputRawFile": {
												"value": {
													"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputRawFileDelimiter": {
												"value": {
													"value": "@item().InputRawFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputRawFileFolder": {
												"value": {
													"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputRawFileSystem": {
												"value": {
													"value": "@activity('Get_IngestDefinition_FileDrop').output.firstRow.DestinationRawFileSystem",
													"type": "Expression"
												},
												"type": "String"
											},
											"L1TransformID": {
												"value": {
													"value": "@item().L1TransformID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"LookupColumns": {
												"value": {
													"value": "@item().LookupColumns",
													"type": "Expression"
												},
												"type": "String"
											},
											"NotebookName": {
												"value": {
													"value": "@item().NotebookName",
													"type": "Expression"
												},
												"type": "String"
											},
											"NotebookPath": {
												"value": {
													"value": "@item().NotebookPath",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWStagingTable": {
												"value": {
													"value": "@item().OutputDWStagingTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTable": {
												"value": {
													"value": "@item().OutputDWTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTableWriteMode": {
												"value": {
													"value": "@item().OutputDWTableWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFile": {
												"value": {
													"value": "@item().OutputL1CuratedFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFileDelimiter": {
												"value": {
													"value": "@item().OutputL1CuratedFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFileFormat": {
												"value": {
													"value": "@item().OutputL1CuratedFileFormat",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFileWriteMode": {
												"value": {
													"value": "@item().OutputL1CuratedFileWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CuratedFolder": {
												"value": {
													"value": "@item().OutputL1CuratedFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL1CurateFileSystem": {
												"value": {
													"value": "@item().OutputL1CurateFileSystem",
													"type": "Expression"
												},
												"type": "String"
											}
										}
									},
									"linkedServiceName": {
										"referenceName": "ControlDB",
										"type": "LinkedServiceReference"
									}
								}
							]
						}
					},
					{
						"name": "L1 Transform",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "ForEach L1Transform",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "Master L1Transform Generic",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"SourceSystemName": {
									"value": "@pipeline().parameters.SourceSystemName",
									"type": "Expression"
								},
								"StreamName": {
									"value": "@pipeline().parameters.StreamName",
									"type": "Expression"
								},
								"MaxTransformInstance": 20,
								"DelayL1TransformationFlag": 0,
								"SparkPool": {
									"value": "@pipeline().parameters.SparkPool",
									"type": "Expression"
								}
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"SourceFileDropFileSystem": {
						"type": "string",
						"defaultValue": "doci"
					},
					"SourceFileDropFolder": {
						"type": "string",
						"defaultValue": "inference/form10q"
					},
					"SourceFileDropFile": {
						"type": "string",
						"defaultValue": "MA_202209Sep.json"
					},
					"SourceSystemName": {
						"type": "string",
						"defaultValue": "AIML-OCR"
					},
					"StreamName": {
						"type": "string",
						"defaultValue": "form10q"
					},
					"SparkPool": {
						"type": "string",
						"defaultValue": "smallMO"
					}
				},
				"variables": {
					"PipelineRunID": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Extract and Load/Upload File Pipelines"
				},
				"annotations": [],
				"lastPublishTime": "2023-06-25T08:43:07Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/ControlDB_Dataset')]",
				"[concat(variables('workspaceId'), '/linkedServices/ControlDB')]",
				"[concat(variables('workspaceId'), '/datasets/AIMLCustomModels_JSON')]",
				"[concat(variables('workspaceId'), '/datasets/Bronze_JSON')]",
				"[concat(variables('workspaceId'), '/pipelines/Master L1Transform Generic')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L1Transform-Generic')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Generic pipeline to execute a single instance of L1 Transform",
				"activities": [
					{
						"name": "Update L1 Instance - Running",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Set PipelineRunID",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[ELT].[UpdateTransformInstance_L1]",
							"storedProcedureParameters": {
								"IngestCount": {
									"value": null,
									"type": "Int32"
								},
								"L1TransformADFPipelineRunID": {
									"value": {
										"value": "@variables('PipelineRunID')",
										"type": "Expression"
									},
									"type": "Guid"
								},
								"L1TransformCount": {
									"value": null,
									"type": "Int32"
								},
								"L1TransformInstanceId": {
									"value": {
										"value": "@pipeline().parameters.L1TransformInstanceID",
										"type": "Expression"
									},
									"type": "Int32"
								},
								"L1TransformStatus": {
									"value": "Running",
									"type": "String"
								},
								"MaxRetries": {
									"value": {
										"value": "@pipeline().parameters.MaxRetries",
										"type": "Expression"
									},
									"type": "Int32"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "ControlDB",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Set PipelineRunID",
						"type": "SetVariable",
						"dependsOn": [],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "PipelineRunID",
							"value": {
								"value": "@pipeline().RunId",
								"type": "Expression"
							}
						}
					},
					{
						"name": "L1 Transform",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "Update L1 Instance - Running",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": {
									"value": "@pipeline().parameters.NotebookName",
									"type": "Expression"
								},
								"type": "NotebookReference"
							},
							"parameters": {
								"L1TransformInstanceID": {
									"value": {
										"value": "@pipeline().parameters.L1TransformInstanceID",
										"type": "Expression"
									},
									"type": "int"
								},
								"L1TransformID ": {
									"value": {
										"value": "@pipeline().parameters.L1TransformID",
										"type": "Expression"
									},
									"type": "int"
								},
								"IngestID": {
									"value": {
										"value": "@pipeline().parameters.IngestID",
										"type": "Expression"
									},
									"type": "int"
								},
								"CustomParameters": {
									"value": {
										"value": "@pipeline().parameters.CustomParameters",
										"type": "Expression"
									},
									"type": "string"
								},
								"InputRawFileSystem": {
									"value": {
										"value": "@pipeline().parameters.InputRawFileSystem",
										"type": "Expression"
									},
									"type": "string"
								},
								"InputRawFileFolder": {
									"value": {
										"value": "@pipeline().parameters.InputRawFileFolder",
										"type": "Expression"
									},
									"type": "string"
								},
								"InputRawFile": {
									"value": {
										"value": "@pipeline().parameters.InputRawFile",
										"type": "Expression"
									},
									"type": "string"
								},
								"InputRawFileDelimiter": {
									"value": {
										"value": "@pipeline().parameters.InputRawFileDelimiter",
										"type": "Expression"
									},
									"type": "string"
								},
								"InputFileHeaderFlag": {
									"value": {
										"value": "@pipeline().parameters.InputFileHeaderFlag",
										"type": "Expression"
									},
									"type": "bool"
								},
								"OutputL1CurateFileSystem": {
									"value": {
										"value": "@pipeline().parameters.OutputL1CurateFileSystem",
										"type": "Expression"
									},
									"type": "string"
								},
								"OutputL1CuratedFolder": {
									"value": {
										"value": "@pipeline().parameters.OutputL1CuratedFolder",
										"type": "Expression"
									},
									"type": "string"
								},
								"OutputL1CuratedFile": {
									"value": {
										"value": "@pipeline().parameters.OutputL1CuratedFile",
										"type": "Expression"
									},
									"type": "string"
								},
								"OutputL1CuratedFileDelimiter": {
									"value": {
										"value": "@pipeline().parameters.OutputL1CuratedFileDelimiter",
										"type": "Expression"
									},
									"type": "string"
								},
								"OutputL1CuratedFileFormat": {
									"value": {
										"value": "@pipeline().parameters.OutputL1CuratedFileFormat",
										"type": "Expression"
									},
									"type": "string"
								},
								"OutputL1CuratedFileWriteMode": {
									"value": {
										"value": "@pipeline().parameters.OutputL1CuratedFileWriteMode",
										"type": "Expression"
									},
									"type": "string"
								},
								"OutputDWStagingTable": {
									"value": {
										"value": "@pipeline().parameters.OutputDWStagingTable",
										"type": "Expression"
									},
									"type": "string"
								},
								"LookupColumns": {
									"value": {
										"value": "@pipeline().parameters.LookupColumns",
										"type": "Expression"
									},
									"type": "string"
								},
								"OutputDWTable": {
									"value": {
										"value": "@pipeline().parameters.OutputDWTable",
										"type": "Expression"
									},
									"type": "string"
								},
								"OutputDWTableWriteMode": {
									"value": {
										"value": "@pipeline().parameters.OutputDWTableWriteMode",
										"type": "Expression"
									},
									"type": "string"
								},
								"ReRunL1TransformFlag": {
									"value": {
										"value": "@pipeline().parameters.ReRunL1TransformFlag",
										"type": "Expression"
									},
									"type": "bool"
								},
								"DeltaName": {
									"value": {
										"value": "@pipeline().parameters.DeltaName",
										"type": "Expression"
									},
									"type": "string"
								}
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": {
									"value": "@pipeline().parameters.SparkPool",
									"type": "Expression"
								},
								"type": "BigDataPoolReference"
							},
							"conf": {
								"spark.dynamicAllocation.enabled": false
							}
						}
					},
					{
						"name": "Update L1 Instance - Success",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "L1 Transform",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[ELT].[UpdateTransformInstance_L1]",
							"storedProcedureParameters": {
								"IngestCount": {
									"value": {
										"value": "@json(activity('L1 Transform').output.status.Output.result.exitValue).IngestCount",
										"type": "Expression"
									},
									"type": "Int32"
								},
								"L1TransformADFPipelineRunID": {
									"value": {
										"value": "@variables('PipelineRunID')",
										"type": "Expression"
									},
									"type": "Guid"
								},
								"L1TransformCount": {
									"value": {
										"value": "@json(activity('L1 Transform').output.status.Output.result.exitValue).L1TransformCount",
										"type": "Expression"
									},
									"type": "Int32"
								},
								"L1TransformInstanceId": {
									"value": {
										"value": "@pipeline().parameters.L1TransformInstanceID",
										"type": "Expression"
									},
									"type": "Int32"
								},
								"L1TransformStatus": {
									"value": "Success",
									"type": "String"
								},
								"MaxRetries": {
									"value": {
										"value": "@pipeline().parameters.MaxRetries",
										"type": "Expression"
									},
									"type": "Int32"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "ControlDB",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Update L1 Instance - Failure",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "L1 Transform",
								"dependencyConditions": [
									"Failed"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[ELT].[UpdateTransformInstance_L1]",
							"storedProcedureParameters": {
								"IngestCount": {
									"value": null,
									"type": "Int32"
								},
								"L1TransformADFPipelineRunID": {
									"value": {
										"value": "@variables('PipelineRunID')",
										"type": "Expression"
									},
									"type": "Guid"
								},
								"L1TransformCount": {
									"value": null,
									"type": "Int32"
								},
								"L1TransformInstanceId": {
									"value": {
										"value": "@pipeline().parameters.L1TransformInstanceID",
										"type": "Expression"
									},
									"type": "Int32"
								},
								"L1TransformStatus": {
									"value": "Failure",
									"type": "String"
								},
								"MaxRetries": {
									"value": {
										"value": "@pipeline().parameters.MaxRetries",
										"type": "Expression"
									},
									"type": "Int32"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "ControlDB",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Get L2 Transform Definition",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "Update L1 Instance - Success",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderStoredProcedureName": "[ELT].[GetTransformDefinition_L2]",
								"storedProcedureParameters": {
									"DeltaDate": {
										"type": "DateTime",
										"value": null
									},
									"IngestID": {
										"type": "Int32",
										"value": {
											"value": "@pipeline().parameters.IngestID",
											"type": "Expression"
										}
									},
									"InputType": {
										"type": "String",
										"value": null
									}
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "ControlDB_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"Table": "Not Applicable",
									"Schema": "Not Applicable"
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ForEach L2 Definition",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get L2 Transform Definition",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get L2 Transform Definition').output.value",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Insert TransformInstance L2",
									"type": "SqlServerStoredProcedure",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"storedProcedureName": "[ELT].[InsertTransformInstance_L2]",
										"storedProcedureParameters": {
											"CustomParameters": {
												"value": {
													"value": "@item().CustomParameters",
													"type": "Expression"
												},
												"type": "String"
											},
											"DataFromNumber": {
												"value": {
													"value": "@item().DataFromNumber",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"DataFromTimestamp": {
												"value": {
													"value": "@item().DataFromTimestamp",
													"type": "Expression"
												},
												"type": "DateTime"
											},
											"DataToNumber": {
												"value": {
													"value": "@item().DataToNumber",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"DataToTimestamp": {
												"value": {
													"value": "@item().DataToTimestamp",
													"type": "Expression"
												},
												"type": "DateTime"
											},
											"DeltaName": {
												"value": {
													"value": "@item().DeltaName",
													"type": "Expression"
												},
												"type": "String"
											},
											"IngestADFPipelineRunID": {
												"value": {
													"value": "@item().IngestADFPipelineRunID",
													"type": "Expression"
												},
												"type": "Guid"
											},
											"IngestID": {
												"value": {
													"value": "@item().IngestID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"InputDWTable": {
												"value": {
													"value": "@item().InputDWTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFile": {
												"value": {
													"value": "@item().InputFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFileDelimiter": {
												"value": {
													"value": "@item().InputFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFileFolder": {
												"value": {
													"value": "@item().InputFileFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"InputFileHeaderFlag": {
												"value": {
													"value": "@item().InputFileHeaderFlag",
													"type": "Expression"
												},
												"type": "Boolean"
											},
											"InputFileSystem": {
												"value": {
													"value": "@item().InputFileSystem",
													"type": "Expression"
												},
												"type": "String"
											},
											"L1TransformADFPipelineRunID": {
												"value": {
													"value": "@item().L1TransformADFPipelineRunID",
													"type": "Expression"
												},
												"type": "Guid"
											},
											"L1TransformID": {
												"value": {
													"value": "@item().L1TransformID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"L2TransformID": {
												"value": {
													"value": "@item().L2TransformID",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"LastDeltaDate": {
												"value": {
													"value": "@item().LastDeltaDate",
													"type": "Expression"
												},
												"type": "DateTime"
											},
											"LastDeltaNumber": {
												"value": {
													"value": "@item().LastDeltaNumber",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"LookupColumns": {
												"value": {
													"value": "@item().LookupColumns",
													"type": "Expression"
												},
												"type": "String"
											},
											"MaxRetries": {
												"value": {
													"value": "@item().MaxRetries",
													"type": "Expression"
												},
												"type": "Int32"
											},
											"NotebookName": {
												"value": {
													"value": "@item().NotebookName",
													"type": "Expression"
												},
												"type": "String"
											},
											"NotebookPath": {
												"value": {
													"value": "@item().NotebookPath",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWStagingTable": {
												"value": {
													"value": "@item().OutputDWStagingTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTable": {
												"value": {
													"value": "@item().OutputDWTable",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputDWTableWriteMode": {
												"value": {
													"value": "@item().OutputDWTableWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFile": {
												"value": {
													"value": "@item().OutputL2CuratedFile",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFileDelimiter": {
												"value": {
													"value": "@item().OutputL2CuratedFileDelimiter",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFileFormat": {
												"value": {
													"value": "@item().OutputL2CuratedFileFormat",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFileWriteMode": {
												"value": {
													"value": "@item().OutputL2CuratedFileWriteMode",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CuratedFolder": {
												"value": {
													"value": "@item().OutputL2CuratedFolder",
													"type": "Expression"
												},
												"type": "String"
											},
											"OutputL2CurateFileSystem": {
												"value": {
													"value": "@item().OutputL2CurateFileSystem",
													"type": "Expression"
												},
												"type": "String"
											}
										}
									},
									"linkedServiceName": {
										"referenceName": "ControlDB",
										"type": "LinkedServiceReference"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"L1TransformInstanceID": {
						"type": "int",
						"defaultValue": 6
					},
					"L1TransformID": {
						"type": "int",
						"defaultValue": 8
					},
					"IngestID": {
						"type": "int",
						"defaultValue": 5
					},
					"NotebookName": {
						"type": "string",
						"defaultValue": "L1Transform-SEC-Form10Q"
					},
					"NotebookPath": {
						"type": "string",
						"defaultValue": "L1Transform"
					},
					"CustomParameters": {
						"type": "string"
					},
					"InputRawFileSystem": {
						"type": "string",
						"defaultValue": "raw-bronze"
					},
					"InputRawFileFolder": {
						"type": "string",
						"defaultValue": "sec-form10q/2023/04"
					},
					"InputRawFile": {
						"type": "string",
						"defaultValue": "2023-04-15_204450_sec-form10q.json"
					},
					"InputRawFileDelimiter": {
						"type": "string"
					},
					"InputFileHeaderFlag": {
						"type": "bool",
						"defaultValue": false
					},
					"OutputL1CurateFileSystem": {
						"type": "string",
						"defaultValue": "curated-silver"
					},
					"OutputL1CuratedFolder": {
						"type": "string",
						"defaultValue": "sec-form10q/2023/04"
					},
					"OutputL1CuratedFile": {
						"type": "string",
						"defaultValue": "standardized_2023-04-15_204525_sec-form10q.json"
					},
					"OutputL1CuratedFileDelimiter": {
						"type": "string"
					},
					"OutputL1CuratedFileFormat": {
						"type": "string",
						"defaultValue": "json"
					},
					"OutputL1CuratedFileWriteMode": {
						"type": "string",
						"defaultValue": "overwrite"
					},
					"OutputDWStagingTable": {
						"type": "string"
					},
					"LookupColumns": {
						"type": "string"
					},
					"OutputDWTable": {
						"type": "string"
					},
					"OutputDWTableWriteMode": {
						"type": "string"
					},
					"ReRunL1TransformFlag": {
						"type": "bool",
						"defaultValue": false
					},
					"MaxRetries": {
						"type": "int",
						"defaultValue": 3
					},
					"DeltaName": {
						"type": "string"
					},
					"SparkPool": {
						"type": "string",
						"defaultValue": "SmallMO"
					}
				},
				"variables": {
					"PipelineRunID": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Transform/L1 Transform Pipelines"
				},
				"annotations": [],
				"lastPublishTime": "2023-06-25T08:42:27Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ControlDB')]",
				"[concat(variables('workspaceId'), '/datasets/ControlDB_Dataset')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Manage-All-SQLPools')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Call Resource List Logic App",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "Set Logic App Parameters",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "POST",
							"headers": {},
							"url": {
								"value": "@pipeline().parameters.resourceList_logicapp_endpoint",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "AutoResolveIntegrationRuntime",
								"type": "IntegrationRuntimeReference"
							},
							"body": {
								"value": "@json(variables('parameters'))",
								"type": "Expression"
							}
						}
					},
					{
						"name": "Set Logic App Parameters",
						"type": "SetVariable",
						"dependsOn": [],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "parameters",
							"value": {
								"value": "{\"subscriptionId\": \"@{pipeline().parameters.subscriptionId}\",\n\"resourceType\": \"@{pipeline().parameters.resourceType}\",\n\"apiVersion\": \"@{pipeline().parameters.apiVersion}\"\n}",
								"type": "Expression"
							}
						}
					},
					{
						"name": "ForEach-SQLPool",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Call Resource List Logic App",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Call Resource List Logic App').output.value",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "resourceGroupName",
									"type": "SetVariable",
									"dependsOn": [],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "resourceGroupName",
										"value": {
											"value": "@last(take(split(item().id,'/'),5))",
											"type": "Expression"
										}
									}
								},
								{
									"name": "workspaceName",
									"type": "SetVariable",
									"dependsOn": [],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "workspaceName",
										"value": {
											"value": "@first(split(item().name,'/'))",
											"type": "Expression"
										}
									}
								},
								{
									"name": "sqlPoolName",
									"type": "SetVariable",
									"dependsOn": [],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "sqlPoolName",
										"value": {
											"value": "@last(split(item().name,'/'))",
											"type": "Expression"
										}
									}
								},
								{
									"name": "SQLPool-Pause-Resume-Scale",
									"type": "ExecutePipeline",
									"dependsOn": [
										{
											"activity": "resourceGroupName",
											"dependencyConditions": [
												"Succeeded"
											]
										},
										{
											"activity": "workspaceName",
											"dependencyConditions": [
												"Succeeded"
											]
										},
										{
											"activity": "sqlPoolName",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"pipeline": {
											"referenceName": "SQLPool-Pause-Resume-Scale",
											"type": "PipelineReference"
										},
										"waitOnCompletion": true,
										"parameters": {
											"logicapp_endpoint": {
												"value": "@pipeline().parameters.sqlPool_logicapp_endpoint",
												"type": "Expression"
											},
											"subscriptionId": {
												"value": "@pipeline().parameters.subscriptionId",
												"type": "Expression"
											},
											"resourceGroupName": {
												"value": "@variables('resourceGroupName')",
												"type": "Expression"
											},
											"workspaceName": {
												"value": "@variables('workspaceName')",
												"type": "Expression"
											},
											"sqlPoolName": {
												"value": "@variables('sqlPoolName')",
												"type": "Expression"
											},
											"apiVersion": {
												"value": "2021-03-01",
												"type": "Expression"
											},
											"action": {
												"value": "@pipeline().parameters.action",
												"type": "Expression"
											},
											"sku": {
												"value": "@pipeline().parameters.sku",
												"type": "Expression"
											}
										}
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"resourceList_logicapp_endpoint": {
						"type": "string"
					},
					"subscriptionId": {
						"type": "string"
					},
					"resourceType": {
						"type": "string",
						"defaultValue": "Microsoft.Synapse/workspaces/sqlPools"
					},
					"apiVersion": {
						"type": "string",
						"defaultValue": "2021-04-01"
					},
					"action": {
						"type": "string",
						"defaultValue": "pause"
					},
					"sku": {
						"type": "string",
						"defaultValue": "DW100c"
					},
					"sqlPool_logicapp_endpoint": {
						"type": "string"
					}
				},
				"variables": {
					"parameters": {
						"type": "String"
					},
					"resourceGroupName": {
						"type": "String"
					},
					"workspaceName": {
						"type": "String"
					},
					"sqlPoolName": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Manage-SQLPool"
				},
				"annotations": [],
				"lastPublishTime": "2023-06-25T08:41:52Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/pipelines/SQLPool-Pause-Resume-Scale')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Master ELT REST API')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Wrapper Pipeline that Extracts, Loads and Transforms data from a REST API data source",
				"activities": [
					{
						"name": "Get Ingest Instances",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderStoredProcedureName": "[ELT].[GetIngestDefinition]",
								"storedProcedureParameters": {
									"MaxIngestInstance": {
										"type": "Int32",
										"value": {
											"value": "@pipeline().parameters.MaxIngestInstance",
											"type": "Expression"
										}
									},
									"SourceSystemName": {
										"type": "String",
										"value": {
											"value": "@pipeline().parameters.SourceSystemName",
											"type": "Expression"
										}
									},
									"StreamName": {
										"type": "String",
										"value": {
											"value": "@pipeline().parameters.StreamName",
											"type": "Expression"
										}
									}
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "ControlDB_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"Table": "NotApplicable",
									"Schema": "NotApplicable"
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ForEach Ingest Instance",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Ingest Instances",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Ingest Instances').output.value",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "IngestREST",
									"type": "ExecutePipeline",
									"dependsOn": [],
									"policy": {
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"pipeline": {
											"referenceName": "IngestREST",
											"type": "PipelineReference"
										},
										"waitOnCompletion": true,
										"parameters": {
											"IngestID": {
												"value": "@item().IngestID",
												"type": "Expression"
											},
											"SourceSystemName": {
												"value": "@item().SourceSystemName",
												"type": "Expression"
											},
											"StreamName": {
												"value": "@item().StreamName",
												"type": "Expression"
											},
											"Backend": {
												"value": "@item().Backend",
												"type": "Expression"
											},
											"EntityName": {
												"value": "@item().EntityName",
												"type": "Expression"
											},
											"DeltaName": {
												"value": "@item().DeltaName",
												"type": "Expression"
											},
											"LastDeltaDate": {
												"value": "@item().LastDeltaDate",
												"type": "Expression"
											},
											"DataFromTimestamp": {
												"value": "@item().DataFromTimestamp",
												"type": "Expression"
											},
											"DataToTimestamp": {
												"value": "@item().DataToTimestamp",
												"type": "Expression"
											},
											"LastDeltaNumber": {
												"value": "@item().LastDeltaNumber",
												"type": "Expression"
											},
											"DataFromNumber": {
												"value": "@item().DataFromNumber",
												"type": "Expression"
											},
											"DataToNumber": {
												"value": "@item().DataToNumber",
												"type": "Expression"
											},
											"DataFormat": {
												"value": "@item().DataFormat",
												"type": "Expression"
											},
											"SourceStructure": {
												"value": "@item().SourceStructure",
												"type": "Expression"
											},
											"MaxIntervalMinutes": {
												"value": "@item().MaxIntervalMinutes",
												"type": "Expression"
											},
											"MaxIntervalNumber": {
												"value": "@item().MaxIntervalNumber",
												"type": "Expression"
											},
											"DataMapping": {
												"value": "@item().DataMapping",
												"type": "Expression"
											},
											"RunSequence": {
												"value": "@item().RunSequence",
												"type": "Expression"
											},
											"ActiveFlag": {
												"value": "@item().ActiveFlag",
												"type": "Expression"
											},
											"L1TransformationReqdFlag": {
												"value": "@item().L1TransformationReqdFlag",
												"type": "Expression"
											},
											"L2TransformationReqdFlag": {
												"value": "@item().L2TransformationReqdFlag",
												"type": "Expression"
											},
											"DelayL1TransformationFlag": {
												"value": "@item().DelayL1TransformationFlag",
												"type": "Expression"
											},
											"DelayL2TransformationFlag": {
												"value": "@item().DelayL2TransformationFlag",
												"type": "Expression"
											},
											"DestinationRawFileSystem": {
												"value": "@item().DestinationRawFileSystem",
												"type": "Expression"
											},
											"DestinationRawFolder": {
												"value": "@item().DestinationRawFolder",
												"type": "Expression"
											},
											"DestinationRawFile": {
												"value": "@item().DestinationRawFile",
												"type": "Expression"
											},
											"SourceSQL": {
												"value": "@item().SourceSQL",
												"type": "Expression"
											},
											"StatSQL": {
												"value": "@item().StatSQL",
												"type": "Expression"
											},
											"ReloadFlag": {
												"value": "@item().ReloadFlag",
												"type": "Expression"
											},
											"ADFPipelineRunID": {
												"value": "@item().ADFPipelineRunID",
												"type": "Expression"
											},
											"BaseURL": {
												"value": "@pipeline().parameters.BaseURL",
												"type": "Expression"
											},
											"ServicePrincipalID": {
												"value": "@pipeline().parameters.ServicePrincipalID",
												"type": "Expression"
											},
											"TenantID": {
												"value": "@pipeline().parameters.TenantID",
												"type": "Expression"
											},
											"AADResource": {
												"value": "@pipeline().parameters.AADResource",
												"type": "Expression"
											}
										}
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"SourceSystemName": {
						"type": "string",
						"defaultValue": "Purview"
					},
					"StreamName": {
						"type": "string",
						"defaultValue": "%"
					},
					"MaxIngestInstance": {
						"type": "string",
						"defaultValue": "20"
					},
					"BaseURL": {
						"type": "string",
						"defaultValue": "https://ba-purview02-aug-pubpreview.purview.azure.com"
					},
					"ServicePrincipalID": {
						"type": "string",
						"defaultValue": "5e07b142-92b4-4671-83c0-e824bc93da6c"
					},
					"TenantID": {
						"type": "string",
						"defaultValue": "72f988bf-86f1-41af-91ab-2d7cd011db47"
					},
					"AADResource": {
						"type": "string",
						"defaultValue": "https://purview.azure.net"
					}
				},
				"folder": {
					"name": "Extract and Load/REST API Pipelines"
				},
				"annotations": [],
				"lastPublishTime": "2023-06-25T08:43:14Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/ControlDB_Dataset')]",
				"[concat(variables('workspaceId'), '/pipelines/IngestREST')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Master L1Transform Generic')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Generic Level 1 Transformation Pipeline",
				"activities": [
					{
						"name": "Get L1 Instances",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderStoredProcedureName": "[ELT].[GetTransformInstance_L1]",
								"storedProcedureParameters": {
									"DelayL1TransformationFlag": {
										"type": "Int32",
										"value": {
											"value": "@pipeline().parameters.DelayL1TransformationFlag",
											"type": "Expression"
										}
									},
									"L1TransformInstanceId": {
										"type": "Int32",
										"value": null
									},
									"MaxTransformInstance": {
										"type": "Int32",
										"value": {
											"value": "@pipeline().parameters.MaxTransformInstance",
											"type": "Expression"
										}
									},
									"SourceSystemName": {
										"type": "String",
										"value": {
											"value": "@pipeline().parameters.SourceSystemName",
											"type": "Expression"
										}
									},
									"StreamName": {
										"type": "String",
										"value": {
											"value": "@pipeline().parameters.StreamName",
											"type": "Expression"
										}
									}
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "ControlDB_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"Table": "Not Applicable",
									"Schema": "Not Applicable"
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ForEach L1 Instance",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get L1 Instances",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get L1 Instances').output.value",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Run L1 Transform Pipeline",
									"type": "ExecutePipeline",
									"dependsOn": [],
									"policy": {
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"pipeline": {
											"referenceName": "L1Transform-Generic",
											"type": "PipelineReference"
										},
										"waitOnCompletion": true,
										"parameters": {
											"L1TransformInstanceID": {
												"value": "@item().L1TransformInstanceID",
												"type": "Expression"
											},
											"L1TransformID": {
												"value": "@item().L1TransformID",
												"type": "Expression"
											},
											"IngestID": {
												"value": "@item().IngestID",
												"type": "Expression"
											},
											"NotebookName": {
												"value": "@item().NotebookName",
												"type": "Expression"
											},
											"NotebookPath": {
												"value": "@item().NotebookPath",
												"type": "Expression"
											},
											"CustomParameters": {
												"value": "@item().CustomParameters",
												"type": "Expression"
											},
											"InputRawFileSystem": {
												"value": "@item().InputRawFileSystem",
												"type": "Expression"
											},
											"InputRawFileFolder": {
												"value": "@item().InputRawFileFolder",
												"type": "Expression"
											},
											"InputRawFile": {
												"value": "@item().InputRawFile",
												"type": "Expression"
											},
											"InputRawFileDelimiter": {
												"value": "@item().InputRawFileDelimiter",
												"type": "Expression"
											},
											"InputFileHeaderFlag": {
												"value": "@item().InputFileHeaderFlag",
												"type": "Expression"
											},
											"OutputL1CurateFileSystem": {
												"value": "@item().OutputL1CurateFileSystem",
												"type": "Expression"
											},
											"OutputL1CuratedFolder": {
												"value": "@item().OutputL1CuratedFolder",
												"type": "Expression"
											},
											"OutputL1CuratedFile": {
												"value": "@item().OutputL1CuratedFile",
												"type": "Expression"
											},
											"OutputL1CuratedFileDelimiter": {
												"value": "@item().OutputL1CuratedFileDelimiter",
												"type": "Expression"
											},
											"OutputL1CuratedFileFormat": {
												"value": "@item().OutputL1CuratedFileFormat",
												"type": "Expression"
											},
											"OutputL1CuratedFileWriteMode": {
												"value": "@item().OutputL1CuratedFileWriteMode",
												"type": "Expression"
											},
											"OutputDWStagingTable": {
												"value": "@item().OutputDWStagingTable",
												"type": "Expression"
											},
											"LookupColumns": {
												"value": "@item().LookupColumns",
												"type": "Expression"
											},
											"OutputDWTable": {
												"value": "@item().OutputDWTable",
												"type": "Expression"
											},
											"OutputDWTableWriteMode": {
												"value": "@item().OutputDWTableWriteMode",
												"type": "Expression"
											},
											"ReRunL1TransformFlag": {
												"value": "@item().ReRunL1TransformFlag",
												"type": "Expression"
											},
											"MaxRetries": {
												"value": "@item().MaxRetries",
												"type": "Expression"
											},
											"DeltaName": {
												"value": "@item().DeltaName",
												"type": "Expression"
											}
										}
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"SourceSystemName": {
						"type": "string",
						"defaultValue": "AIML-OCR"
					},
					"StreamName": {
						"type": "string",
						"defaultValue": "analyze-sec-form10q"
					},
					"MaxTransformInstance": {
						"type": "int",
						"defaultValue": 20
					},
					"DelayL1TransformationFlag": {
						"type": "int",
						"defaultValue": 0
					},
					"SparkPool": {
						"type": "string",
						"defaultValue": "smallMO"
					}
				},
				"folder": {
					"name": "Transform/L1 Transform Pipelines"
				},
				"annotations": [],
				"lastPublishTime": "2023-06-25T08:43:02Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/ControlDB_Dataset')]",
				"[concat(variables('workspaceId'), '/pipelines/L1Transform-Generic')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQLPool-Pause-Resume-Scale')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Call SQL Pool Logic App",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "Set Logic App Parameters",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "POST",
							"headers": {},
							"url": {
								"value": "@pipeline().parameters.logicapp_endpoint",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "AutoResolveIntegrationRuntime",
								"type": "IntegrationRuntimeReference"
							},
							"body": {
								"value": "@json(variables('parameters'))",
								"type": "Expression"
							}
						}
					},
					{
						"name": "Set Logic App Parameters",
						"type": "SetVariable",
						"dependsOn": [],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "parameters",
							"value": {
								"value": "{\n\"action\": \"@{pipeline().parameters.action}\",\n\"sku\": \"@{pipeline().parameters.sku}\",\n\"subscriptionId\": \"@{pipeline().parameters.subscriptionId}\",\n\"resourceGroupName\": \"@{pipeline().parameters.resourceGroupName}\",\n\"workspaceName\": \"@{pipeline().parameters.workspaceName}\",\n\"sqlPoolName\": \"@{pipeline().parameters.sqlPoolName}\",\n\"apiVersion\": \"@{pipeline().parameters.apiVersion}\"\n}",
								"type": "Expression"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"logicapp_endpoint": {
						"type": "string"
					},
					"subscriptionId": {
						"type": "string"
					},
					"resourceGroupName": {
						"type": "string"
					},
					"workspaceName": {
						"type": "string"
					},
					"sqlPoolName": {
						"type": "string"
					},
					"apiVersion": {
						"type": "string",
						"defaultValue": "2021-03-01"
					},
					"action": {
						"type": "string",
						"defaultValue": "pause"
					},
					"sku": {
						"type": "string",
						"defaultValue": "DW100c"
					}
				},
				"variables": {
					"parameters": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Manage-SQLPool"
				},
				"annotations": [],
				"lastPublishTime": "2023-06-25T08:39:24Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AIMLCustomModels_JSON')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AIMLCustomModels",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"FileSystem": {
						"type": "string"
					},
					"Folder": {
						"type": "string"
					},
					"File": {
						"type": "string"
					}
				},
				"folder": {
					"name": "Azure/AIML"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": {
							"value": "@dataset().File",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().Folder",
							"type": "Expression"
						},
						"container": {
							"value": "@dataset().FileSystem",
							"type": "Expression"
						}
					}
				},
				"schema": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AIMLCustomModels')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AtlasREST_API')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AtlasREST",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"RelativeUrl": {
						"type": "string"
					}
				},
				"folder": {
					"name": "Azure/REST"
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {
					"relativeUrl": {
						"value": "@dataset().RelativeUrl",
						"type": "Expression"
					}
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AtlasREST')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Bronze_JSON')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Bronze",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"FileSystem": {
						"type": "string"
					},
					"Folder": {
						"type": "string"
					},
					"File": {
						"type": "string"
					}
				},
				"folder": {
					"name": "Azure/Datalake"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().File",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().Folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().FileSystem",
							"type": "Expression"
						}
					}
				},
				"schema": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/Bronze')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Bronze_Parquet')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Bronze",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"FileSystem": {
						"type": "string"
					},
					"Folder": {
						"type": "string"
					},
					"File": {
						"type": "string"
					}
				},
				"folder": {
					"name": "Azure/Datalake"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().File",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().Folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().FileSystem",
							"type": "Expression"
						}
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/Bronze')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ControlDB_Dataset')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ControlDB",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Table": {
						"type": "string"
					},
					"Schema": {
						"type": "string"
					}
				},
				"folder": {
					"name": "Azure/Datalake"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [],
				"typeProperties": {
					"schema": {
						"value": "@dataset().Schema",
						"type": "Expression"
					},
					"table": {
						"value": "@dataset().Table",
						"type": "Expression"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ControlDB')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Drop_JSON')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "DropZone",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"FileSystem": {
						"type": "string"
					},
					"Folder": {
						"type": "string"
					},
					"File": {
						"type": "string"
					}
				},
				"folder": {
					"name": "Azure/Datalake"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().File",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().Folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().FileSystem",
							"type": "Expression"
						}
					}
				},
				"schema": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/DropZone')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/REST_API')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "REST",
					"type": "LinkedServiceReference",
					"parameters": {
						"BaseURL": {
							"value": "@dataset().BaseURL",
							"type": "Expression"
						},
						"ServicePrincipalID": {
							"value": "@dataset().ServicePrincipalID",
							"type": "Expression"
						},
						"TenantID": {
							"value": "@dataset().TenantID",
							"type": "Expression"
						},
						"AADResource": {
							"value": "@dataset().AADResource",
							"type": "Expression"
						}
					}
				},
				"parameters": {
					"BaseURL": {
						"type": "string"
					},
					"ServicePrincipalID": {
						"type": "string"
					},
					"TenantID": {
						"type": "string"
					},
					"AADResource": {
						"type": "string"
					},
					"RelativeURL": {
						"type": "string"
					}
				},
				"folder": {
					"name": "Azure/REST"
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {
					"relativeUrl": {
						"value": "@dataset().RelativeURL",
						"type": "Expression"
					}
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/REST')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AIMLCustomModels')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"serviceEndpoint": "[parameters('AIMLCustomModels_properties_typeProperties_serviceEndpoint')]",
					"accountKind": "StorageV2"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AtlasREST')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Endpoint for Purview Atlas REST APIs",
				"annotations": [],
				"type": "RestService",
				"typeProperties": {
					"url": "[parameters('AtlasREST_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "AadServicePrincipal",
					"servicePrincipalId": "[parameters('AtlasREST_properties_typeProperties_servicePrincipalId')]",
					"servicePrincipalKey": {
						"type": "AzureKeyVaultSecret",
						"store": {
							"referenceName": "keyvault01",
							"type": "LinkedServiceReference"
						},
						"secretName": "contoso-spn-secret"
					},
					"tenant": "[parameters('AtlasREST_properties_typeProperties_tenant')]",
					"aadResourceId": "[parameters('AtlasREST_properties_typeProperties_aadResourceId')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/linkedServices/keyvault01')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Bronze')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Bronze Zone of Datalake Storage",
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('Bronze_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ControlDB')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Linked service for ELT Framework database",
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"connectionString": "[parameters('ControlDB_connectionString')]",
					"alwaysEncryptedSettings": {
						"alwaysEncryptedAkvAuthType": "ManagedIdentity"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DeltaZone')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('DeltaZone_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DropZone')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Linked service for external files uploaded to the data platform",
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('DropZone_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/REST')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Parametrized Linked Service for a REST API data source using Service Principal AAD Authentication",
				"parameters": {
					"BaseURL": {
						"type": "String"
					},
					"ServicePrincipalID": {
						"type": "String"
					},
					"TenantID": {
						"type": "String"
					},
					"AADResource": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "RestService",
				"typeProperties": {
					"url": "[parameters('REST_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "AadServicePrincipal",
					"servicePrincipalId": "[parameters('REST_properties_typeProperties_servicePrincipalId')]",
					"servicePrincipalKey": {
						"type": "AzureKeyVaultSecret",
						"store": {
							"referenceName": "keyvault01",
							"type": "LinkedServiceReference"
						},
						"secretName": "contoso-spn-secret"
					},
					"tenant": "[parameters('REST_properties_typeProperties_tenant')]",
					"aadResourceId": "[parameters('REST_properties_typeProperties_aadResourceId')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/linkedServices/keyvault01')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ba-synapse01-lhf7sbrgc3jru-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('ba-synapse01-lhf7sbrgc3jru-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ba-synapse01-lhf7sbrgc3jru-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('ba-synapse01-lhf7sbrgc3jru-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/keyvault01')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureKeyVault",
				"typeProperties": {
					"baseUrl": "[parameters('keyvault01_properties_typeProperties_baseUrl')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Azure Daily')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Daily Trigger to Extract, Load and Transform data from Azure REST APIs",
				"annotations": [],
				"runtimeState": "Started",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "Master ELT REST API",
							"type": "PipelineReference"
						},
						"parameters": {
							"SourceSystemName": "[parameters('Azure Daily_properties_Master ELT REST API_parameters_SourceSystemName')]",
							"StreamName": "[parameters('Azure Daily_properties_Master ELT REST API_parameters_StreamName')]",
							"MaxIngestInstance": "[parameters('Azure Daily_properties_Master ELT REST API_parameters_MaxIngestInstance')]",
							"BaseURL": "[parameters('Azure Daily_properties_Master ELT REST API_parameters_BaseURL')]",
							"ServicePrincipalID": "[parameters('Azure Daily_properties_Master ELT REST API_parameters_ServicePrincipalID')]",
							"TenantID": "[parameters('Azure Daily_properties_Master ELT REST API_parameters_TenantID')]",
							"AADResource": "[parameters('Azure Daily_properties_Master ELT REST API_parameters_AADResource')]"
						}
					}
				],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Day",
						"interval": 1,
						"startTime": "2022-07-01T00:49:00",
						"timeZone": "AUS Eastern Standard Time",
						"schedule": {
							"minutes": [
								0
							],
							"hours": [
								4
							]
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/Master ELT REST API')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Pause-ALL-Dedicated-SQLPools')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Stopped",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "Manage-All-SQLPools",
							"type": "PipelineReference"
						},
						"parameters": {
							"resourceList_logicapp_endpoint": "[parameters('Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_resourceList_logicapp_endpoint')]",
							"subscriptionId": "[parameters('Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_subscriptionId')]",
							"resourceType": "[parameters('Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_resourceType')]",
							"apiVersion": "[parameters('Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_apiVersion')]",
							"action": "[parameters('Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_action')]",
							"sku": "[parameters('Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_sku')]",
							"sqlPool_logicapp_endpoint": "[parameters('Pause-ALL-Dedicated-SQLPools_properties_Manage-All-SQLPools_parameters_sqlPool_logicapp_endpoint')]"
						}
					}
				],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Day",
						"interval": 1,
						"startTime": "2021-07-11T19:00:00",
						"timeZone": "AUS Eastern Standard Time",
						"schedule": {
							"minutes": [
								0
							],
							"hours": [
								19
							]
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/Manage-All-SQLPools')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Purview Daily')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Daily trigger to refresh Purview data",
				"annotations": [],
				"runtimeState": "Stopped",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "Master ELT REST API",
							"type": "PipelineReference"
						},
						"parameters": {
							"SourceSystemName": "[parameters('Purview Daily_properties_Master ELT REST API_parameters_SourceSystemName')]",
							"StreamName": "[parameters('Purview Daily_properties_Master ELT REST API_parameters_StreamName')]",
							"MaxIngestInstance": "[parameters('Purview Daily_properties_Master ELT REST API_parameters_MaxIngestInstance')]",
							"BaseURL": "[parameters('Purview Daily_properties_Master ELT REST API_parameters_BaseURL')]",
							"ServicePrincipalID": "[parameters('Purview Daily_properties_Master ELT REST API_parameters_ServicePrincipalID')]",
							"TenantID": "[parameters('Purview Daily_properties_Master ELT REST API_parameters_TenantID')]",
							"AADResource": "[parameters('Purview Daily_properties_Master ELT REST API_parameters_AADResource')]"
						}
					}
				],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Day",
						"interval": 1,
						"startTime": "2022-06-30T00:00:00",
						"timeZone": "AUS Eastern Standard Time",
						"schedule": {
							"minutes": [
								0
							],
							"hours": [
								5
							]
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/Master ELT REST API')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Real Estate Statement Event')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Event grid trigger for real estate statements processed by Form Recognizer custom model ",
				"annotations": [],
				"runtimeState": "Stopped",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "Ingest_AIML_CustomInferenceFile",
							"type": "PipelineReference"
						},
						"parameters": {
							"SourceFileDropFileSystem": "[parameters('Real Estate Statement Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceFileDropFileSystem')]",
							"SourceFileDropFolder": "[parameters('Real Estate Statement Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceFileDropFolder')]",
							"SourceFileDropFile": "[parameters('Real Estate Statement Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceFileDropFile')]",
							"SourceSystemName": "[parameters('Real Estate Statement Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceSystemName')]",
							"StreamName": "[parameters('Real Estate Statement Event_properties_Ingest_AIML_CustomInferenceFile_parameters_StreamName')]",
							"SparkPool": "[parameters('Real Estate Statement Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SparkPool')]"
						}
					}
				],
				"type": "BlobEventsTrigger",
				"typeProperties": {
					"blobPathBeginsWith": "/doci/blobs/inference/re-statements/",
					"blobPathEndsWith": ".json",
					"ignoreEmptyBlobs": true,
					"scope": "[parameters('Real Estate Statement Event_properties_typeProperties_scope')]",
					"events": [
						"Microsoft.Storage.BlobCreated"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/Ingest_AIML_CustomInferenceFile')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SEC Form10Q Event')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Event grid trigger for SEC Form 10Q summarization",
				"annotations": [],
				"runtimeState": "Started",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "Ingest_AIML_CustomInferenceFile",
							"type": "PipelineReference"
						},
						"parameters": {
							"SourceFileDropFileSystem": "[parameters('SEC Form10Q Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceFileDropFileSystem')]",
							"SourceFileDropFolder": "[parameters('SEC Form10Q Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceFileDropFolder')]",
							"SourceFileDropFile": "[parameters('SEC Form10Q Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceFileDropFile')]",
							"SourceSystemName": "[parameters('SEC Form10Q Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SourceSystemName')]",
							"StreamName": "[parameters('SEC Form10Q Event_properties_Ingest_AIML_CustomInferenceFile_parameters_StreamName')]",
							"SparkPool": "[parameters('SEC Form10Q Event_properties_Ingest_AIML_CustomInferenceFile_parameters_SparkPool')]"
						}
					}
				],
				"type": "BlobEventsTrigger",
				"typeProperties": {
					"blobPathBeginsWith": "/doci/blobs/inference/form10q/",
					"blobPathEndsWith": ".json",
					"ignoreEmptyBlobs": true,
					"scope": "[parameters('SEC Form10Q Event_properties_typeProperties_scope')]",
					"events": [
						"Microsoft.Storage.BlobCreated"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/Ingest_AIML_CustomInferenceFile')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EnrichData_With_AML Model')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE PROCEDURE dbo.nyc_taxi_procedure\nAS\nBEGIN\n\nSELECT\n    CAST([paymentType] AS [bigint]) AS [paymentType],\n    CAST([passengerCount] AS [bigint]) AS [passengerCount],\n    [tripTimeSecs],\n    CAST([pickupTimeBin] AS [varchar]) AS [pickupTimeBin]\nINTO [dbo].[#nyc_taxi]\nFROM [dbo].[nyc_taxi];\n\nSELECT *\nFROM PREDICT (MODEL = (SELECT [model] FROM dbo.nyc_taxi_tip_aml_model WHERE [ID] = 'nyc_taxi_tip_predict:3'),\n              DATA = [dbo].[#nyc_taxi],\n              RUNTIME = ONNX) WITH ([output_label] [bigint])\n\nEND\nGO\n\nEXEC dbo.nyc_taxi_procedure",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "dw01",
						"poolName": "dw01"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Grant DSQL Pool Permissions')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE USER [ba-synapse01-kn3acb6lw3vr4] FROM EXTERNAL PROVIDER\nGO\n\nEXEC sp_addrolemember 'db_exporter', [ba-synapse01-kn3acb6lw3vr4]\n\nGO\n\nEXEC sp_addrolemember 'db_datawriter', [ba-synapse01-kn3acb6lw3vr4]\n\nGO\n\nCREATE USER [bennyaustin@microsoft.com] FROM EXTERNAL PROVIDER\nGO\n\nEXEC sp_addrolemember 'db_exporter', [bennyaustin@microsoft.com]\nGO\nGO\n\nEXEC sp_addrolemember 'db_owner', [bennyaustin@microsoft.com]\nGO\n\n\n--Make sure your user has the permissions to CREATE tables in the [dbo] schema\nGRANT CREATE TABLE TO [ba-synapse01-kn3acb6lw3vr4];\nGRANT ALTER ON SCHEMA::dbo TO [ba-synapse01-kn3acb6lw3vr4];\nGRANT ALTER ON SCHEMA::stg TO [ba-synapse01-kn3acb6lw3vr4];\nGRANT ALTER ON SCHEMA::sec TO [ba-synapse01-kn3acb6lw3vr4];\nGRANT ALTER ON SCHEMA::Purview TO [ba-synapse01-kn3acb6lw3vr4];\nGRANT ALTER ON SCHEMA::Azure TO [ba-synapse01-kn3acb6lw3vr4];\n\n--Make sure your user has ADMINISTER DATABASE BULK OPERATIONS permissions\nGRANT ADMINISTER DATABASE BULK OPERATIONS TO [ba-synapse01-kn3acb6lw3vr4];\n\n-- --Make sure your user has INSERT permissions on the target table\n-- GRANT INSERT ON nyct.nyc_tlc_yellow_trip TO [ba-synapse01-kn3acb6lw3vr4]\n\n-- GRANT INSERT ON nyct.nyc_tlc_yellow_trip_copy TO [ba-synapse01-kn3acb6lw3vr4]\n\n--Alternatively give db_owner for ease of maintenance\nEXEC sp_addrolemember 'db_owner', [ba-synapse01-kn3acb6lw3vr4]\nGO\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "dlsql01",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Serverless - Query Parquet')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "-- This is auto-generated code\nSELECT\n  top 100  *\nFROM\n    OPENROWSET(\n        BULK 'https://bastoragedatalake01.dfs.core.windows.net/raw-bronze/purview/operations/2022-07/*.parquet',\n        FORMAT = 'PARQUET'\n    ) AS [result]\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "default",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Serverless SQL JSON Queries')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "SQL Script to query JSON files in datalake",
				"content": {
					"query": "-- Create a db master key if one does not already exist, using your own password.\n-- CREATE MASTER KEY ENCRYPTION BY PASSWORD='<EnterStrongPasswordHere>';\n\n\n-- Create a database scoped credential with the workspace managed IDENTITY\nIF NOT EXISTS (select 1 from sys.database_scoped_credentials where name = 'ba-synapse01-lhf7sbrgc3jru')\n    CREATE DATABASE SCOPED CREDENTIAL [ba-synapse01-lhf7sbrgc3jru]\n    WITH IDENTITY = 'MANAGED IDENTITY'\n\n-- Create EXTERNAL FILE Format as JSON not explicitly required for SQL Serverless. The format used by OPENROWSET is CSV\n\n--Create External Data Source\nIF NOT EXISTS (select 1 from sys.external_data_sources where name ='form10q')\n    CREATE EXTERNAL DATA SOURCE [form10q]\n    WITH (    LOCATION   = 'https://badatalake01lhf7sbrgc3jr.dfs.core.windows.net/curated-silver/form10q' --'https://<storage_account>.dfs.core.windows.net/<container>/<path>'\n            ,CREDENTIAL = [ba-synapse01-lhf7sbrgc3jru]\n    )\n\n\n--Query Single file\nselect top 10 *\nfrom openrowset(\n        bulk '2024/08/standardized_2024-08-26_133839_form10q.json/part-00000-1c167e8d-bae1-483e-a3e8-c1dfc0a9c124-c000.json',\n        data_source = 'form10q',\n        format = 'csv',\n        fieldterminator ='0x0b',\n        fieldquote = '0x0b',\n        ROWTERMINATOR = '0x0b'\n    ) with (doc nvarchar(max)) as rows\n\n\n--Query multiple files using wildcards\nselect top 10 *\nfrom openrowset(\n        bulk '*/*/*/part*.json',\n        data_source = 'form10q',\n        format = 'csv',\n        fieldterminator ='0x0b',\n        fieldquote = '0x0b',\n        ROWTERMINATOR = '0x0b'\n    ) with (doc nvarchar(max)) as rows\n\n\n--Flatten with OPENJSON\nselect top 10 *\nfrom openrowset(\n        bulk '*/*/*/part*.json',\n        data_source = 'form10q',\n        format = 'csv',\n        fieldterminator ='0x0b',\n        fieldquote = '0x0b',\n        ROWTERMINATOR = '0x0b'\n    ) with (doc nvarchar(max)) as rows\ncross apply openjson(doc)\nwith (org_name varchar(50) '$.org_name'\n    ,org_address varchar(400) '$.org_address'\n    ,org_jurisdiction varchar(100) '$.org_jurisdiction'\n    ,org_stock_ticker varchar(5) '$.org_stock_ticker'\n    ,reporting_quarter varchar(20) '$.reporting_quarter'\n    ,stock_exchange varchar(10) '$.stock_exchange'\n    ,total_assets int '$.total_assets'\n    ,total_comprehensive_income int '$.total_comprehensive_income'\n    ,total_equity int '$.total_equity'\n    ,total_liabilities int '$.total_liabilities'\n    ,mgmt_analysis varchar(MAX) '$.mgmt_analysis'\n    ,risk_disclosure varchar(MAX) '$.risk_disclosure'\n    ,controls_procedures varchar(MAX) '$.controls_procedures'\n    ,mgmt_analysis_summary varchar(100) '$.mgmt_analysis_summary'\n    ,risk_disclosure_summary varchar(100) '$.risk_disclosure_summary'\n    ,controls_procedures_summary varchar(100) '$.controls_procedures_summary'\n    ) \n\n    DROP VIEW vwSecForm10Q\n    GO\n    --Create View\n    CREATE VIEW vwSecForm10Q AS\n        select * \n        from openrowset(\n                bulk '*/*/*/part*.json',\n                data_source = 'form10q',\n                format = 'csv',\n                fieldterminator ='0x0b',\n                fieldquote = '0x0b',\n                ROWTERMINATOR = '0x0b'\n            ) with (doc nvarchar(max)) as rows\n        cross apply openjson(doc)\n        with (org_name varchar(50) '$.org_name'\n            ,org_address varchar(400) '$.org_address'\n            ,org_jurisdiction varchar(100) '$.org_jurisdiction'\n            ,org_stock_ticker varchar(5) '$.org_stock_ticker'\n            ,reporting_quarter varchar(20) '$.reporting_quarter'\n            ,stock_exchange varchar(10) '$.stock_exchange'\n            ,total_assets int '$.total_assets'\n            ,total_comprehensive_income int '$.total_comprehensive_income'\n            ,total_equity int '$.total_equity'\n            ,total_liabilities int '$.total_liabilities'\n            ,mgmt_analysis varchar(MAX) '$.mgmt_analysis'\n            ,risk_disclosure varchar(MAX) '$.risk_disclosure'\n            ,controls_procedures varchar(MAX) '$.controls_procedures'\n            ,mgmt_analysis_summary varchar(MAX) '$.mgmt_analysis_summary'\n            ,risk_disclosure_summary varchar(MAX) '$.risk_disclosure_summary'\n            ,controls_procedures_summary varchar(MAX) '$.controls_procedures_summary'\n            ) \n--Query View all columns\n-- select * from vwSecForm10Q\n\n--Query Summaries\nselect distinct org_name, reporting_quarter,mgmt_analysis_summary,risk_disclosure_summary,controls_procedures_summary\nfrom vwSecForm10Q\n \n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "sldb01",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Synapse Link CosmosDB View')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Script to create a view from HTAP CosmosDB",
				"content": {
					"query": "IF (NOT EXISTS(SELECT * FROM sys.credentials WHERE name = 'ba-cosmosdb1'))\n    CREATE CREDENTIAL [ba-cosmosdb1] WITH IDENTITY = 'SHARED ACCESS SIGNATURE', SECRET = '<CosmodDBKey>'\n\nIF (NOT EXISTS(SELECT * FROM sys.schemas WHERE name = 'htap_cosmosdb'))\n   EXEC ('CREATE SCHEMA [htap_cosmosdb]')\n\nCREATE OR ALTER VIEW [htap_cosmosdb].[volcano_htap]\nAS SELECT id, Country, [Status], Elevation, [Type],Region, [Location]\nfrom OPENROWSET(​PROVIDER = 'CosmosDB',\n                CONNECTION = 'Account=ba-cosmosdb1;Database=SampleDB',\n                OBJECT = 'Volcano_HTAP',\n                SERVER_CREDENTIAL = 'ba-cosmosdb1'\n) WITH\n    (id varchar(50),\n    Country varchar(50),\n    Status varchar(20),\n    Elevation int,\n    Type varchar(20),\n    Region varchar(100),\n    Location varchar(1000)) as rows\n\n\n-- SELECT top 10 * from [htap_cosmosdb].[volcano_htap]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ldw01",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AAD-functions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Reusable functions for Azure Active Directory",
				"folder": {
					"name": "common"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "9be5f5d2-a7c7-452c-b09f-b0a4a3432f6f"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/735994b1-b3b0-46d5-96bc-c9b30ddb4265/resourceGroups/rg-synapse-dp/providers/Microsoft.Synapse/workspaces/ba-synapse01-lhf7sbrgc3jru/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-lhf7sbrgc3jru.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Re-usable functions for Azure Active Directory"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /common/keyvault-functions {\"kvLinkedService\": \"keyvault01\"}"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"tenandIdSecret = \"<Azure Key Vault Secret for TenantID>\"\n",
							"servicePrincipalIdSecret = \"<Azure Key Vault Secret for Service Principal ID>\"\n",
							"servicePrincipalSecret = \"<Azure Key Vault Secret for Service Principal secret>\"\n",
							"authUrl = \"https://login.windows.net\"\n",
							"resourceUrl = \"https://database.windows.net/\""
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import adal\n",
							"\n",
							""
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# getBearerToken()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def getBearerToken():\n",
							"    ############################################################################\n",
							"    # getBearerToken\n",
							"    # Returns a bearer token for a service principal AAD authentication\n",
							"    #\n",
							"    # Parameters:\n",
							"    #       None\n",
							"    #\n",
							"    # Returns:\n",
							"    #     Bearer Token  \n",
							"    ############################################################################\n",
							"\n",
							"    tenantId = getSecret(tenandIdSecret)\n",
							"    servicePrincipalId = getSecret(servicePrincipalIdSecret)\n",
							"    secret = getSecret(servicePrincipalSecret)\n",
							"\n",
							"    assert tenantId is not None, \"tenantId not specified\"\n",
							"    assert servicePrincipalId is not None, \"servicePrincipalId not specified\"\n",
							"    assert secret is not None, \"secret not specified\"\n",
							"    assert authUrl is not None, \"authUrl not specified\"\n",
							"    assert resourceUrl is not None, \"resourceUrl not specified\"\n",
							"\n",
							"    authority = authUrl + \"/\" + tenantId\n",
							"    try:\n",
							"        context = adal.AuthenticationContext(authority)\n",
							"        token = context.acquire_token_with_client_credentials(resourceUrl, servicePrincipalId, secret)\n",
							"        accessToken = token[\"accessToken\"]\n",
							"    except Exception as e:\n",
							"        print(\"getBearerToken failed with exception:\")\n",
							"        raise e\n",
							"    return accessToken"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L1Transform-Generic-Synapse')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Generic Level 1 Transform Notebook for Synapse Dedicated SQL Pool Target",
				"folder": {
					"name": "L1Transform"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "93ee6ac1-4daf-4d39-914b-2e203df892e8"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/735994b1-b3b0-46d5-96bc-c9b30ddb4265/resourceGroups/rg-synapse-dp/providers/Microsoft.Synapse/workspaces/ba-synapse01-lhf7sbrgc3jru/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-lhf7sbrgc3jru.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"%run /common/commonTransforms"
						],
						"outputs": [],
						"execution_count": 72
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /common/datalake-functions {\"storageAccount\": \"badatalake01lhf7sbrgc3jr\" }"
						],
						"outputs": [],
						"execution_count": 73
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /common/dedicatedSQLPool-functions {\"server\": \"ba-synapse01-lhf7sbrgc3jru.sql.azuresynapse.net,1433\",\"database\" :\"dwh01\" }"
						],
						"outputs": [],
						"execution_count": 74
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /common/upsertSdp-function {\"server\": \"ba-synapse01-lhf7sbrgc3jru.sql.azuresynapse.net,1433\",\"database\" :\"dwh01\",\"sqlUidSecret\": \"sqlserver-admin-username\",\"sqlPwdSecret\":\"sqlserver-admin-password\", \"sinkType\": \"Synapse\"}"
						],
						"outputs": [],
						"execution_count": 75
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Notebook Parameters"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"L1TransformInstanceID = None\n",
							"L1TransformID = None\n",
							"IngestID = None\n",
							"CustomParameters = None\n",
							"InputRawFileSystem = None\n",
							"InputRawFileFolder = None\n",
							"InputRawFile = None\n",
							"InputRawFileDelimiter = None\n",
							"InputFileHeaderFlag = None\n",
							"OutputL1CurateFileSystem = None\n",
							"OutputL1CuratedFolder = None\n",
							"OutputL1CuratedFile = None\n",
							"OutputL1CuratedFileDelimiter = None\n",
							"OutputL1CuratedFileFormat = None\n",
							"OutputL1CuratedFileWriteMode = None\n",
							"OutputDWStagingTable = None\n",
							"LookupColumns = None\n",
							"OutputDWTable = None\n",
							"OutputDWTableWriteMode = None\n",
							"ReRunL1TransformFlag = None\n",
							"DeltaName = None\n",
							""
						],
						"outputs": [],
						"execution_count": 76
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# # Parameters for Testing only, should be commented off\n",
							"# L1TransformInstanceID = 1\n",
							"# L1TransformID = 3\n",
							"# IngestID = 3\n",
							"# CustomParameters = None\n",
							"# InputRawFileSystem = 'raw-bronze'\n",
							"# InputRawFileFolder = 'purview/operations/2022-07'\n",
							"# InputRawFile = 'operations_20220720.parquet'\n",
							"# InputRawFileDelimiter = None\n",
							"# InputFileHeaderFlag = 1\n",
							"# OutputL1CurateFileSystem = 'curated-silver'\n",
							"# OutputL1CuratedFolder = 'purview/operations/1900-01'\n",
							"# OutputL1CuratedFile = 'standardized_operations_19000101.parquet'\n",
							"# OutputL1CuratedFileDelimiter = None\n",
							"# OutputL1CuratedFileFormat = 'parquet'\n",
							"# OutputL1CuratedFileWriteMode = 'overwrite'\n",
							"# OutputDWStagingTable = 'stg.merge_Azure_operations'\n",
							"# LookupColumns = ['name']\n",
							"# OutputDWTable = 'Azure.operations'\n",
							"# OutputDWTableWriteMode = 'append'\n",
							"# ReRunL1TransformFlag = None\n",
							"# DeltaName = None"
						],
						"outputs": [],
						"execution_count": 77
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Read Raw file and apply basic data cleansing and data enrichments"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"df = readFile(container=InputRawFileSystem, path= InputRawFileFolder + '/' + InputRawFile, colSeparator=InputRawFileDelimiter, headerFlag=InputFileHeaderFlag)\n",
							"ingestCount = df.count()\n",
							"\n",
							"ct=CommonTransforms(df)\n",
							"\n",
							"# Remove duplicates\n",
							"df=ct.deDuplicate()\n",
							"\n",
							"# Remove leading and trailing spaces from all string columns\n",
							"df=ct.trim()\n",
							"\n",
							"# Replace Null Value with generic values\n",
							"df = ct.replaceNull(0)\n",
							"df = ct.replaceNull(\"NA\")\n",
							"df = ct.replaceNull(\"2020-01-01\")\n",
							"\n",
							"# Add literal value columns for e.g SparkJobId\n",
							"audit={\"WorkspaceName\": mssparkutils.env.getWorkspaceName(), \"SparkJobId\":mssparkutils.env.getJobId(), \"SparkPool\" : mssparkutils.env.getPoolName(), \"SparkClusterId\" :mssparkutils.env.getClusterId()}\n",
							"df = ct.addLitCols(audit)"
						],
						"outputs": [],
						"execution_count": 78
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pos = OutputDWTable.find(\".\")\n",
							"schemaName = OutputDWTable[0:pos]\n",
							"tableName = OutputDWTable[pos+1:]\n",
							"\n",
							"posStg = OutputDWStagingTable.find(\".\")\n",
							"stgSchemaName = OutputDWStagingTable[0:posStg]\n",
							"stgTableName = OutputDWStagingTable[posStg+1:]\n",
							"\n",
							"l1TransformCount = df.count()\n",
							"\n",
							"if OutputDWTableWriteMode == 'append' and OutputDWStagingTable is not None and LookupColumns is not None:\n",
							"    upsertSdp(df,SchemaStagingTable=stgSchemaName,StagingTable=stgTableName, SchemaTargetTable=schemaName, TargetTable=tableName, KeyColumns=LookupColumns, DeltaColumn=DeltaName) \n",
							"else:\n",
							"    insertSdpTable(df, schema=schemaName,table=tableName, mode=OutputDWTableWriteMode)"
						],
						"outputs": [],
						"execution_count": 79
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Return Values"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import json\n",
							"mssparkutils.notebook.exit(json.dumps({\n",
							"  \"IngestCount\": ingestCount,\n",
							"  \"L1TransformCount\": l1TransformCount\n",
							"}))"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L1Transform-ReStatement')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Notebook to simplify the json generated by form recognizer",
				"folder": {
					"name": "L1Transform"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": true,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "34ea8cb3-a373-417e-8a3d-a26d70949192"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/735994b1-b3b0-46d5-96bc-c9b30ddb4265/resourceGroups/rg-synapse-dp/providers/Microsoft.Synapse/workspaces/ba-synapse01-lhf7sbrgc3jru/bigDataPools/smallMO",
						"name": "smallMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-lhf7sbrgc3jru.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"%run /common/datalake-functions {\"storageAccount\": \"badatalake01lhf7sbrgc3jr\" }"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Notebook Parameters"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"L1TransformInstanceID = None\n",
							"L1TransformID = None\n",
							"IngestID = None\n",
							"CustomParameters = None\n",
							"InputRawFileSystem = None\n",
							"InputRawFileFolder = None\n",
							"InputRawFile = None\n",
							"InputRawFileDelimiter = None\n",
							"InputFileHeaderFlag = None\n",
							"OutputL1CurateFileSystem = None\n",
							"OutputL1CuratedFolder = None\n",
							"OutputL1CuratedFile = None\n",
							"OutputL1CuratedFileDelimiter = None\n",
							"OutputL1CuratedFileFormat = None\n",
							"OutputL1CuratedFileWriteMode = None\n",
							"OutputDWStagingTable = None\n",
							"LookupColumns = None\n",
							"OutputDWTable = None\n",
							"OutputDWTableWriteMode = None\n",
							"ReRunL1TransformFlag = None\n",
							"DeltaName = None"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# # Parameters for Testing only, should be commented off\n",
							"# L1TransformInstanceID = 2\n",
							"# L1TransformID = 1\n",
							"# IngestID = 2\n",
							"# CustomParameters = None\n",
							"# InputRawFileSystem = 'raw-bronze'\n",
							"# InputRawFileFolder = 're-statements/2024/08'\n",
							"# InputRawFile = '2024-08-25_182410_re-statement.json'\n",
							"# InputRawFileDelimiter = None\n",
							"# InputFileHeaderFlag = None\n",
							"# OutputL1CurateFileSystem = 'curated-silver'\n",
							"# OutputL1CuratedFolder = 're-statements/2024/08'\n",
							"# OutputL1CuratedFile = 'standardized_2024-08-25_182504_re-statement.json'\n",
							"# OutputL1CuratedFileDelimiter = None\n",
							"# OutputL1CuratedFileFormat = 'json'\n",
							"# OutputL1CuratedFileWriteMode = 'overwrite'\n",
							"# OutputDWStagingTable = None\n",
							"# LookupColumns = None\n",
							"# OutputDWTable = None\n",
							"# OutputDWTableWriteMode = None\n",
							"# ReRunL1TransformFlag = None\n",
							"# DeltaName = None"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"from pyspark.sql.functions import col, explode\n",
							"df = readFile(InputRawFileSystem, InputRawFileFolder +\"/\" + InputRawFile, None, None)\n",
							"ingestCount = df.count()\n",
							"\n",
							"# extract datapoints of interest and explode array\n",
							"\n",
							"# df.printSchema()\n",
							"df = df.select(col(\"RE agency.valueString\").alias(\"re_agency\")\n",
							"            ,col(\"owner.valueString\").alias(\"owner\")\n",
							"            ,col(\"owner address.valueString\").alias(\"re_agency_address\")\n",
							"            ,col(\"rental address.valueString\").alias(\"rental_address\")\n",
							"            ,col(\"statement date.valueString\").alias(\"statement_date\")\n",
							"            ,col(\"tenant.valueString\").alias(\"tenant\")\n",
							"            ,col(\"total payment.valueNumber\").alias(\"total_payment\")\n",
							"            ,explode(col(\"statement details.valueArray\")).alias(\"statement details\")\n",
							"            )\n",
							"\n",
							"df = df.select(\"re_agency\",\"owner\",\"re_agency_address\",\"rental_address\",\"statement_date\",\"tenant\",\"total_payment\"\n",
							"                ,col(\"statement details.valueObject.amount.valueString\").alias(\"item_amount\")\n",
							"                ,col(\"statement details.valueObject.item description.valueString\").alias(\"item_description\"))\n",
							"# df.printSchema()\n",
							"\n",
							"#write flattened json to curated zone of data lake\n",
							"l1TransformCount = df.count()\n",
							"writeFile(df,OutputL1CurateFileSystem, OutputL1CuratedFolder + \"/\" + OutputL1CuratedFile)"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Return Values   "
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import json\n",
							"mssparkutils.notebook.exit(json.dumps({\n",
							"  \"IngestCount\": ingestCount,\n",
							"  \"L1TransformCount\": l1TransformCount\n",
							"}))"
						],
						"outputs": [],
						"execution_count": 18
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L1Transform-SEC-Form10Q')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Notebook to summarize SEC Form 10Q statement using AOAI",
				"folder": {
					"name": "L1Transform"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": true,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "e2488087-4053-4490-9d07-09e69e548e86"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/735994b1-b3b0-46d5-96bc-c9b30ddb4265/resourceGroups/rg-synapse-dp/providers/Microsoft.Synapse/workspaces/ba-synapse01-lhf7sbrgc3jru/bigDataPools/smallMO",
						"name": "smallMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-lhf7sbrgc3jru.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Install SynapseML for this spark session\n",
							"https://microsoft.github.io/SynapseML/docs/getting_started/installation/"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%%configure -f\n",
							"{\n",
							"  \"name\": \"synapseml\",\n",
							"  \"conf\": {\n",
							"      \"spark.jars.packages\": \"com.microsoft.azure:synapseml_2.12:0.11.0,org.apache.spark:spark-avro_2.12:3.3.1\",\n",
							"      \"spark.jars.repositories\": \"https://mmlspark.azureedge.net/maven\",\n",
							"      \"spark.jars.excludes\": \"org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12,com.fasterxml.jackson.core:jackson-databind\",\n",
							"      \"spark.yarn.user.classpath.first\": \"true\",\n",
							"      \"spark.sql.parquet.enableVectorizedReader\": \"false\",\n",
							"      \"spark.sql.legacy.replaceDatabricksSparkAvro.enabled\": \"true\"\n",
							"  }\n",
							"}"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"source": [
							"%run /common/datalake-functions {\"storageAccount\": \"badatalake01lhf7sbrgc3jr\" }"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /common/keyvault-functions {\"kvLinkedService\": \"keyvault01\"}"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# %run /common/dedicatedSQLPool-functions {\"server\": \"ba-synapse01-lhf7sbrgc3jru.sql.azuresynapse.net,1433\",\"database\" :\"dwh01\" }"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# %run /common/upsertSdp-function {\"server\": \"ba-synapse01-lhf7sbrgc3jru.sql.azuresynapse.net,1433\",\"database\" :\"dwh01\",\"sqlUidSecret\": \"sqlserver-admin-username\",\"sqlPwdSecret\":\"sqlserver-admin-password\", \"sinkType\": \"Synapse\"}"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Notebook Parameters"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"L1TransformInstanceID = None\n",
							"L1TransformID = None\n",
							"IngestID = None\n",
							"CustomParameters = None\n",
							"InputRawFileSystem = None\n",
							"InputRawFileFolder = None\n",
							"InputRawFile = None\n",
							"InputRawFileDelimiter = None\n",
							"InputFileHeaderFlag = None\n",
							"OutputL1CurateFileSystem = None\n",
							"OutputL1CuratedFolder = None\n",
							"OutputL1CuratedFile = None\n",
							"OutputL1CuratedFileDelimiter = None\n",
							"OutputL1CuratedFileFormat = None\n",
							"OutputL1CuratedFileWriteMode = None\n",
							"OutputDWStagingTable = None\n",
							"LookupColumns = None\n",
							"OutputDWTable = None\n",
							"OutputDWTableWriteMode = None\n",
							"ReRunL1TransformFlag = None\n",
							"DeltaName = None"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# # Parameters for Testing only, should be commented off\n",
							"# L1TransformInstanceID = 11\n",
							"# L1TransformID  = 2\n",
							"# IngestID = 1\n",
							"# CustomParameters = None\n",
							"# InputRawFileSystem = \"raw-bronze\"\n",
							"# InputRawFileFolder = \"form10q/2024/08\"\n",
							"# InputRawFile = \"2024-08-25_211827_form10q.json\"\n",
							"# InputRawFileDelimiter = None\n",
							"# InputFileHeaderFlag = None\n",
							"# OutputL1CurateFileSystem = \"curated-silver\"\n",
							"# OutputL1CuratedFolder = \"form10q/2024/08\"\n",
							"# OutputL1CuratedFile = \"standardized_2024-08-25_211913_form10q.json\"\n",
							"# OutputL1CuratedFileDelimiter = None\n",
							"# OutputL1CuratedFileFormat = \"json\"\n",
							"# OutputL1CuratedFileWriteMode = \"overwrite\"\n",
							"# OutputDWStagingTable = \"[stg].[merge_sec_form10q]\"\n",
							"# LookupColumns = \"['org_name','reporting_quarter']\"\n",
							"# OutputDWTable = \"[sec].[form10q]\"\n",
							"# OutputDWTableWriteMode = \"append\"\n",
							"# ReRunL1TransformFlag = None\n",
							"# DeltaName = None"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Extract datapoints of interest"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"from pyspark.sql.functions import *\n",
							"from pyspark.sql.types import *\n",
							"df = readFile(InputRawFileSystem, InputRawFileFolder +\"/\" + InputRawFile, None, None)\n",
							"ingestCount = df.count()\n",
							"\n",
							"# df.printSchema()\n",
							"\n",
							"df = df.select( col(\"org_name.content\").alias(\"org_name\")\n",
							"                ,col(\"org_address.content\").alias(\"org_address\")\n",
							"                ,col(\"org_jurisdiction.content\").alias(\"org_jurisdiction\")\n",
							"                ,col(\"org_stock_ticker.content\").alias(\"org_stock_ticker\")\n",
							"                ,col(\"reporting_quarter.content\").alias(\"reporting_quarter\")\n",
							"                ,col(\"stock_exchange.content\").alias(\"stock_exchange\")\n",
							"                ,regexp_replace(col(\"total_assets.content\"),\",\",\"\").cast(IntegerType()).alias(\"total_assets\")\n",
							"                ,regexp_replace(col(\"total_comprehensive_income.content\"),\",\",\"\").cast(IntegerType()).alias(\"total_comprehensive_income\")\n",
							"                ,regexp_replace(col(\"total_equity.content\"),\",\",\"\").cast(IntegerType()).alias(\"total_equity\")\n",
							"                ,regexp_replace(col(\"total_liabilities.content\"),\",\",\"\").cast(IntegerType()).alias(\"total_liabilities\")                \n",
							"                ,col(\"mgmt_analysis.content\").alias(\"mgmt_analysis\")\n",
							"                ,col(\"risk_disclosure.content\").alias(\"risk_disclosure\")\n",
							"                ,col(\"controls_procedures.content\").alias(\"controls_procedures\")\n",
							"            )"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# AOAI Summarization"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"import os\n",
							"from synapse.ml.core.platform import running_on_synapse, find_secret\n",
							"from synapse.ml.cognitive import OpenAICompletion\n",
							"\n",
							"aoaiEndpoint = getSecret(\"aoai-endpoint\")\n",
							"aoaiDeploymentName = \"gpt-35-turbo\"\n",
							"aoaiApiKey = getSecret(\"aoai-api-key\")\n",
							"\n",
							"#Summary1\n",
							"dfPrompt_mgmt_analysis = df.select( col(\"mgmt_analysis\")\n",
							"                                    , concat(lit(\"summarize the text below as bullet list. Keep the summary concise and only include key highlights\\n\"),lit(\"text:\"),col(\"mgmt_analysis\"),lit(\"\\n summary:\")).alias(\"mgmt_analysis_prompt\"))\n",
							"completion = (\n",
							"    OpenAICompletion()\n",
							"    .setSubscriptionKey(aoaiApiKey)\n",
							"    .setDeploymentName(aoaiDeploymentName)\n",
							"    .setUrl(aoaiEndpoint)\n",
							"    .setMaxTokens(100)\n",
							"    .setPromptCol(\"mgmt_analysis_prompt\")\n",
							"    .setErrorCol(\"error\")\n",
							"    .setOutputCol(\"mgmt_analysis_summary\")\n",
							")\n",
							"\n",
							"dfSummaryMgmtAnalysis = completion.transform(dfPrompt_mgmt_analysis).cache()\n",
							"# display(dfSummaryMgmtAnalysis.select(\n",
							"#   col(\"mgmt_analysis_prompt\"), col(\"error\"), col(\"mgmt_analysis_summary.choices.text\").getItem(0).alias(\"text\")))\n",
							"# dfSummaryMgmtAnalysis.printSchema()\n",
							"\n",
							"dfSummaryMgmtAnalysis = dfSummaryMgmtAnalysis.select(col(\"mgmt_analysis_summary.choices.text\").getItem(0).alias(\"mgmt_analysis_summary\"))\n",
							"\n",
							"#Summary2\n",
							"dfPrompt_risk_disclosure = df.select( col(\"risk_disclosure\")\n",
							"                                    , concat(lit(\"summarize the text below as bullet list. Keep the summary concise and only include key highlights.\\n\"),lit(\"text:\"),col(\"risk_disclosure\"),lit(\"\\n summary:\")).alias(\"risk_disclosure_prompt\"))\n",
							"completion = (\n",
							"    OpenAICompletion()\n",
							"    .setSubscriptionKey(aoaiApiKey)\n",
							"    .setDeploymentName(aoaiDeploymentName)\n",
							"    .setUrl(aoaiEndpoint)\n",
							"    .setMaxTokens(100)\n",
							"    .setPromptCol(\"risk_disclosure_prompt\")\n",
							"    .setErrorCol(\"error\")\n",
							"    .setOutputCol(\"risk_disclosure_summary\")\n",
							")\n",
							"\n",
							"dfSummaryRisk = completion.transform(dfPrompt_risk_disclosure).cache()\n",
							"# display(dfSummaryRisk.select(\n",
							"#   col(\"risk_disclosure_prompt\"), col(\"error\"), col(\"risk_disclosure_summary.choices.text\").getItem(0).alias(\"text\")))\n",
							"# dfSummaryRisk.printSchema()\n",
							"\n",
							"dfSummaryRisk = dfSummaryRisk.select(col(\"risk_disclosure_summary.choices.text\").getItem(0).alias(\"risk_disclosure_summary\"))\n",
							"\n",
							"#Summary3\n",
							"dfPrompt_controls_procedures = df.select( col(\"controls_procedures\")\n",
							"                                    , concat(lit(\"summarize the text below as bullet list. Keep the summary concise and only include key highlights\\n\"),lit(\"text:\"),col(\"controls_procedures\"),lit(\"\\n summary:\")).alias(\"controls_procedures_prompt\"))\n",
							"completion = (\n",
							"    OpenAICompletion()\n",
							"    .setSubscriptionKey(aoaiApiKey)\n",
							"    .setDeploymentName(aoaiDeploymentName)\n",
							"    .setUrl(aoaiEndpoint)\n",
							"    .setMaxTokens(100)\n",
							"    .setPromptCol(\"controls_procedures_prompt\")\n",
							"    .setErrorCol(\"error\")\n",
							"    .setOutputCol(\"controls_procedures_summary\")\n",
							")\n",
							"\n",
							"dfSummaryCP = completion.transform(dfPrompt_controls_procedures).cache()\n",
							"# display(dfSummaryCP.select(\n",
							"#   col(\"controls_procedures_prompt\"), col(\"error\"), col(\"controls_procedures_summary.choices.text\").getItem(0).alias(\"text\")))\n",
							"# dfSummaryCP.printSchema()\n",
							"\n",
							"dfSummaryCP = dfSummaryCP.select(col(\"controls_procedures_summary.choices.text\").getItem(0).alias(\"controls_procedures_summary\"))"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"from functools import reduce\n",
							"from pyspark.sql import DataFrame\n",
							"\n",
							"#Merge all the dataframes\n",
							"dfs = [df,dfSummaryMgmtAnalysis,dfSummaryRisk,dfSummaryCP]\n",
							"dfFinal = reduce(DataFrame.crossJoin, dfs)\n",
							"display(dfFinal)\n",
							""
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Write summarized json to curated zone of data lake"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"l1TransformCount = dfFinal.count()\n",
							"writeFile(dfFinal,OutputL1CurateFileSystem, OutputL1CuratedFolder + \"/\" + OutputL1CuratedFile)"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# pos = OutputDWTable.find(\".\")\n",
							"# schemaName = OutputDWTable[0:pos]\n",
							"# tableName = OutputDWTable[pos+1:]\n",
							"\n",
							"# posStg = OutputDWStagingTable.find(\".\")\n",
							"# stgSchemaName = OutputDWStagingTable[0:posStg]\n",
							"# stgTableName = OutputDWStagingTable[posStg+1:]\n",
							"\n",
							"# if OutputDWTableWriteMode == 'append' and OutputDWStagingTable is not None and LookupColumns is not None:\n",
							"#     upsertSdp(df,SchemaStagingTable=stgSchemaName,StagingTable=stgTableName, SchemaTargetTable=schemaName, TargetTable=tableName, KeyColumns=LookupColumns, DeltaColumn=DeltaName) \n",
							"# else:\n",
							"#     insertSdpTable(df, schema=schemaName,table=tableName, mode=OutputDWTableWriteMode)"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Return Values"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import json\n",
							"mssparkutils.notebook.exit(json.dumps({\n",
							"  \"IngestCount\": ingestCount,\n",
							"  \"L1TransformCount\": l1TransformCount\n",
							"}))\n",
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL-functions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Reusable functions for Azure SQL and SQL Server",
				"folder": {
					"name": "common"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "3b130b4a-6d47-4230-88f8-9d3a5f32527c"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/735994b1-b3b0-46d5-96bc-c9b30ddb4265/resourceGroups/rg-synapse-dp/providers/Microsoft.Synapse/workspaces/ba-synapse01-lhf7sbrgc3jru/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-lhf7sbrgc3jru.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Re-usable functions for Azure SQL and SQL Server"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /common/keyvault-functions {\"kvLinkedService\": \"keyvault01\"}"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"server=\"<Azure SQL Server/ SQL Server>\"\n",
							"database = \"<Database Name>\"\n",
							"usernameSecret = \"<Azure Key Vault Secret for SQL User>\"\n",
							"passwordSecret = \"<Azure Key Vault Secret for SQL User Password>\""
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pyodbc"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# getJdbcUrl()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def getJdbcUrl():\n",
							"  # ##########################################################################################################################  \n",
							"  # Function: getJdbcUrl\n",
							"  # Creates the JDBC Connection String from the input parameters to this notebook\n",
							"  # \n",
							"  # Parameters:\n",
							"  # None\n",
							"  #\n",
							"  # Returns:\n",
							"  # JDBC Connection String\n",
							"  # ##########################################################################################################################  \n",
							"    assert server is not None, \"server not specified\"\n",
							"    assert database is not None, \"database not specified\"\n",
							"    assert usernameSecret is not None, \"usernameSecret not specified\"\n",
							"    assert passwordSecret is not None, \"passwordSecret not specified\"\n",
							"\n",
							"    user =  getSecret(usernameSecret)\n",
							"    password = getSecret(passwordSecret)\n",
							"    jdbcUrl = \"jdbc:sqlserver://\" + server + \".database.windows.net:1433;database=\" + database + \";user=\" + user + \"@\" + server + \";password=\" + password + \";encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\"\n",
							"    return jdbcUrl"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# readTable()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def readTable(table):\n",
							"  # ##########################################################################################################################  \n",
							"  # Function: readTable\n",
							"  # Reads all the rows and columns of an Azure SQL table/view and returns the records as dataframe\n",
							"  # \n",
							"  # Parameters:\n",
							"  # table = Input Table/View including the schema name. E.g soccer.goalpost, afl.goalpost\n",
							"  #\n",
							"  # Returns:\n",
							"  # Dataframe containing all rows and columns of a table/view in Azure SQL\n",
							"  # ##########################################################################################################################  \n",
							"    assert table is not None, \"table not specified\"\n",
							"\n",
							"    jdbcUrl = getJdbcUrl()\n",
							"\n",
							"    try:\n",
							"      df = (spark.read\n",
							"              .format(\"jdbc\")\n",
							"              .option(\"driver\",\"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\n",
							"              .option(\"url\",jdbcUrl)\n",
							"              .option(\"dbtable\",table)\n",
							"              .load()\n",
							"          )\n",
							"    except Exception as e:\n",
							"        print(\"readTable({}) failed with exception:\".format(table))\n",
							"        raise e\n",
							"\n",
							"\n",
							"    ## Use Apache Spark Connector in Future instead of JDBC connector for faster execution. At the moment Apache Spark Connector is not available on newer Spark Runtime\n",
							"    ## Have to install a library from maven coordinates:com.microsoft.azure:spark-mssql-connector_2.12:1.2.0\n",
							"    ## https://docs.microsoft.com/en-us/sql/connect/spark/connector?view=sql-server-ver16\n",
							"    #   df = (spark.read\n",
							"    #           .format(\"com.microsoft.sqlserver.jdbc.spark\")\n",
							"    #           .option(\"url\",jdbcUrl)\n",
							"    #           .option(\"dbtable\",table)\n",
							"    #           .load()\n",
							"    #       )\n",
							"    return df"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# readQuery()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def readQuery(query):\n",
							"  # ##########################################################################################################################  \n",
							"  # Function: readQuery\n",
							"  # Executes the input query at Azure SQL and returns the records as dataframe\n",
							"  # \n",
							"  # Parameters:\n",
							"  # query = A valid input query\n",
							"  #\n",
							"  # Returns:\n",
							"  # Dataframe containing all rows and columns returned by query from Azure SQL\n",
							"  # ##########################################################################################################################  \n",
							"  assert query is not None, \"query not specified\"\n",
							"\n",
							"  jdbcUrl = getJdbcUrl()\n",
							"  try:\n",
							"    df = (spark.read\n",
							"            .format(\"jdbc\")\n",
							"            .option(\"driver\",\"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\n",
							"            .option(\"url\",jdbcUrl)\n",
							"            .option(\"query\",query)\n",
							"            .load()\n",
							"        )\n",
							"  except Exception as e:\n",
							"        print(\"readQuery({}) failed with exception:\".format(query))\n",
							"        raise e\n",
							"    ## Use Apache Spark Connector in Future instead of JDBC connector for faster execution. At the moment Apache Spark Connector is not available on newer Spark Runtime\n",
							"    ## Have to install a library from maven coordinates:com.microsoft.azure:spark-mssql-connector_2.12:1.2.0\n",
							"    ## https://docs.microsoft.com/en-us/sql/connect/spark/connector?view=sql-server-ver16\n",
							"    #   df = (spark.read\n",
							"    #           .format(\"com.microsoft.sqlserver.jdbc.spark\")\n",
							"    #           .option(\"url\",jdbcUrl)\n",
							"    #           .option(\"dbtable\",table)\n",
							"    #           .load()\n",
							"    #       )\n",
							"  return df"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# insertTable()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def insertTable(df,table,writeMode,preserveSchema = None):\n",
							"  # ##########################################################################################################################  \n",
							"  # Function: insertTable\n",
							"  # Inserts a dataframe to a Azure SQL\n",
							"  # \n",
							"  # Parameters:\n",
							"  # df = Input dataframe\n",
							"  # table = Target table where the datafframe is loaded\n",
							"  # writeMode = Describes how data from dataframe is inserted to datawarehouse table. Allowed values are - append/overwrite/ignore/error/errorifexists\n",
							"  # preserveSchema = True/False. Applicable only in overwrite mode when schema needs to be preserved\n",
							"  # Returns:\n",
							"  # None\n",
							"  # ########################################################################################################################## \n",
							"  assert table is not None, \"query not specified\"\n",
							"  assert writeMode is not None, \"writeMode not specified\"\n",
							"  assert writeMode in [\"append\",\"overwrite\",\"ignore\",\"error\",\"errorifexists\"] , \"writeMode is invalid. Allowed values are append,overwrite,ignore,error,errorifexists\"\n",
							"\n",
							"  jdbcUrl = getJdbcUrl()\n",
							"  \n",
							"  try:\n",
							"    if writeMode == \"overwrite\" and preserveSchema == True :\n",
							"      #Truncate and Append instead of overwrite to preserve table schema\n",
							"      (df.write\n",
							"      .format(\"jdbc\")\n",
							"      .option(\"driver\",\"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\n",
							"      .option(\"url\",jdbcUrl)\n",
							"      .mode(\"append\")\n",
							"      .option(\"truncate\", \"true\") # Must be string \"true\" and not boolean True\n",
							"      .option(\"dbtable\",table)\n",
							"      .save()\n",
							"      )\n",
							"    else:\n",
							"      (df.write\n",
							"      .format(\"jdbc\")\n",
							"      .option(\"driver\",\"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\n",
							"      .option(\"url\",jdbcUrl)\n",
							"      .mode(writeMode)\n",
							"      .option(\"dbtable\",table)\n",
							"      .save()\n",
							"      ) \n",
							"  except Exception as e:\n",
							"        print(\"insertTable({}) failed with exception:\".format(query))\n",
							"        raise e \n",
							"    ## Use Apache Spark Connector in Future instead of JDBC connector for faster execution. At the moment Apache Spark Connector is not available on newer Spark Runtime\n",
							"    ## Have to install a library from maven coordinates:com.microsoft.azure:spark-mssql-connector_2.12:1.2.0\n",
							"    ## https://docs.microsoft.com/en-us/sql/connect/spark/connector?view=sql-server-ver16\n",
							"    #   df = (spark.read\n",
							"    #           .format(\"com.microsoft.sqlserver.jdbc.spark\")\n",
							"    #           .option(\"url\",jdbcUrl)\n",
							"    #           .option(\"dbtable\",table)\n",
							"    #           .load()\n",
							"    #       )"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# upsert()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upsert(df,SchemaStagingTable,StagingTable, SchemaTargetTable, TargetTable, KeyColumns,IdentityColumns=None, DeltaColumn=None) :\n",
							"# ##########################################################################################################################  \n",
							"# Function: upsert\n",
							"# Performs a Merge/Upsert action on a Azure SQL table\n",
							"# \n",
							"# Parameters:\n",
							"# df = Input dataframe\n",
							"# StagingTable = Name of Table used to temporarily stage the input data frame\n",
							"# SchemaStagingTable = Database schema of staging table\n",
							"# SchemaTargetTable = Database schema of target table\n",
							"# TargetTable  = Name of Target Table\n",
							"# KeyColumns = List of columns that uniquely defines a record in input dataframe\n",
							"# IdentityColumns = List of Identity Columns that needs to be excluded from Inserts and Updates\n",
							"# DeltaColumn = Name of watermark column in input dataframe\n",
							"#\n",
							"# Returns:\n",
							"# None\n",
							"# ##########################################################################################################################  \n",
							"\n",
							"    insertTable(df,SchemaStagingTable + \".\" + StagingTable,\"overwrite\")\n",
							"    \n",
							"\n",
							"    insertCols=\"\"\n",
							"    updateCols=\"\"\n",
							"    whereCols =\"\"\n",
							"    keyCols = \"\"\n",
							"\n",
							"    # MATCHED Clause of MERGE\n",
							"    for keyCol in KeyColumns:\n",
							"        keyCols = keyCols + \"source.\" + keyCol + \" = \" + \"target.\" + keyCol + \" and \"\n",
							"\n",
							"    whereClause = keyCols\n",
							"    #Tidy up where clause and remove last \"and\"\n",
							"    remove=\"and\"\n",
							"    reverse_remove=remove[::-1]\n",
							"    whereClause = whereClause[::-1].replace(reverse_remove,\"\",1)[::-1]\n",
							"\n",
							"    # INSERT and UPDATE part of MERGE\n",
							"    for col in df.schema.fieldNames():\n",
							"        if col not in IdentityColumns: # Exclude Identity columns in Insert statement\n",
							"            insertCols = insertCols + col + \",\"\n",
							"        if col not in KeyColumns and col not in IdentityColumns: # Exclude key and Identity columns in update statement\n",
							"            updateCols =  updateCols + \"target.\" + col + \" = \" + \"source.\" + col + \",\"\n",
							"\n",
							"    #Tidy up insertCols and remove last \",\"\n",
							"    remove=\",\"\n",
							"    reverse_remove=remove[::-1]\n",
							"    insertCols = insertCols[::-1].replace(reverse_remove,\"\",1)[::-1]  \n",
							"\n",
							"    #Tidy up insertCols and remove last \",\"\n",
							"    remove=\",\"\n",
							"    reverse_remove=remove[::-1]\n",
							"    updateCols = updateCols[::-1].replace(reverse_remove,\"\",1)[::-1]   \n",
							"\n",
							"    # MERGE Statement in full\n",
							"    mergeSQL= \"MERGE INTO \" + SchemaTargetTable +\".\" + TargetTable + \" AS target\" +  \" USING \" + SchemaStagingTable + \".\" + StagingTable + \" AS source\" + \" ON \"\n",
							"    mergeSQL = mergeSQL + whereClause\n",
							"\n",
							"    # WHEN MATCHED\n",
							"    if DeltaColumn != None:\n",
							"        mergeSQL =  mergeSQL + \" WHEN MATCHED AND \" + \"source.\" + DeltaColumn + \" > \" + \"target.\" + DeltaColumn \n",
							"    else:\n",
							"        mergeSQL =  mergeSQL + \" WHEN MATCHED\"\n",
							"\n",
							"    mergeSQL = mergeSQL + \" THEN UPDATE SET \" + updateCols\n",
							"\n",
							"    # WHEN NOT MATCHED BY TARGET\n",
							"    mergeSQL = mergeSQL + \" WHEN NOT MATCHED BY TARGET \" # including BY TARGET clause for Synapse requires the table to be Hash Distributed\n",
							"    mergeSQL = mergeSQL + \" THEN INSERT \" +  \"(\"+ insertCols +\")\" + \" VALUES \" + \" ( \"+ insertCols +\" ) \"\n",
							"\n",
							"    mergeSQL = mergeSQL +\";\"\n",
							"    \n",
							"    #Execute Merge Statement using Pyodbc\n",
							"    uid = getSecret(usernameSecret)\n",
							"    pwd = getSecret(passwordSecret)\n",
							" \n",
							"    try:\n",
							"        cnxn = pyodbc.connect(\"DRIVER={ODBC Driver 17 for SQL Server};SERVER=\" + server + \".database.windows.net\" + \";DATABASE=\" + database + \";UID=\" + uid + \";PWD=\" + pwd )\n",
							"        cursor = cnxn.cursor()\n",
							"        cnxn.autocommit = True\n",
							"\n",
							"        cursor.execute(mergeSQL)\n",
							"    except Exception as e:\n",
							"        print(\"Upsert to {}.{} failed with exception:\".format(SchemaTargetTable,TargetTable))\n",
							"        raise e\n",
							"\n",
							"    print(\"Upsert statement executed successfully : {} \".format(mergeSQL))\n",
							"    return"
						],
						"outputs": [],
						"execution_count": 8
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/commonTransforms')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "A collection of reusable Python classes that extends out of box PySpark capabilities",
				"folder": {
					"name": "common"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "4e983031-73bb-40b3-9422-56e55e9b94d7"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e836675f-2508-4873-ad4f-754d70253b22/resourceGroups/rg-synapse-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapse01-kn3acb6lw3vr4/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-kn3acb6lw3vr4.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# What is CommonTransforms and how to use them in your notebooks ?  \r\n",
							"CommonTransforms is a Python class that uses PySpark libraries to apply common transformations to a Spark dataframe. https://github.com/bennyaustin/pyspark-utils/blob/main/CommonTransforms/README.md"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# CommonTransforms Class"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql.functions import trim,when,isnull,lit,col,from_utc_timestamp,to_utc_timestamp,concat_ws,sha1,length,substring,lit,concat,date_add,expr,year,datediff\r\n",
							"from pyspark.sql import functions as F \r\n",
							"import datetime"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"class CommonTransforms:\r\n",
							"  inputDf=None\r\n",
							"  inputSchema=None\r\n",
							"  inputColums=None\r\n",
							"  \r\n",
							"#   Constructor\r\n",
							"  def __init__(self, input):\r\n",
							"    self.inputDf=input\r\n",
							"    self.inputSchema=self.inputDf.schema\r\n",
							"    self.inputColumns=self.inputDf.schema.fieldNames()\r\n",
							"    \r\n",
							"#  Remove Leading and Trailing Spaces \r\n",
							"  def trim(self):\r\n",
							"    stringCol= (col for col in self.inputSchema if str(col.dataType)==\"StringType\")\r\n",
							"    for col in stringCol:\r\n",
							"        self.inputDf = self.inputDf.withColumn(col.name,trim(col.name))\r\n",
							"    return self.inputDf\r\n",
							"  \r\n",
							"#   Replace Null values with Default values based on datatypes\r\n",
							"  def replaceNull(self,value, subset=None):\r\n",
							"    isDate=False\r\n",
							"    isTimestamp =False\r\n",
							"    \r\n",
							"    try:\r\n",
							"      if isinstance(value, str):\r\n",
							"        date_obj = datetime.datetime.strptime(value, \"%Y-%m-%d\") #YYYY-MM-DD format e.g \"2020-10-01\"\r\n",
							"        isDate= True\r\n",
							"    except ValueError:\r\n",
							"      isDate=False\r\n",
							"      \r\n",
							"    try:\r\n",
							"      if isinstance(value, str):\r\n",
							"        date_obj = datetime.datetime.strptime(value, \"%Y-%m-%dT%H:%M:%S\") #YYYY-MM-DDThh:mm:ss format e.g \"2020-10-01T19:50:06\"\r\n",
							"        isTimestamp= True\r\n",
							"    except ValueError:\r\n",
							"      isTimestamp=False\r\n",
							"      \r\n",
							"    if isDate and subset is not None:\r\n",
							"      dateCol = (x for x in self.inputSchema if str(x.dataType)==\"DateType\" and x.nullable==True and x.name in subset)\r\n",
							"      for x in dateCol:\r\n",
							"        self.inputDf = self.inputDf.withColumn(x.name, when(isnull(col(x.name)),lit(value)).otherwise(col(x.name)))\r\n",
							"    elif isDate and subset is None:\r\n",
							"      dateCol = (x for x in self.inputSchema if str(x.dataType)==\"DateType\" and x.nullable==True)\r\n",
							"      for x in dateCol:\r\n",
							"        self.inputDf = self.inputDf.withColumn(x.name, when(isnull(col(x.name)),lit(value)).otherwise(col(x.name)))\r\n",
							"    elif isTimestamp and subset is not None:\r\n",
							"      tsCol = (x for x in self.inputSchema if str(x.dataType)==\"TimestampType\" and x.nullable==True and x.name in subset)\r\n",
							"      for x in tsCol:\r\n",
							"        self.inputDf = self.inputDf.withColumn(x.name, when(isnull(col(x.name)),lit(value)).otherwise(col(x.name)))\r\n",
							"    elif isTimestamp and subset is None:\r\n",
							"      tsCol = (x for x in self.inputSchema if str(x.dataType)==\"TimestampType\" and x.nullable==True)\r\n",
							"      for x in tsCol:\r\n",
							"        self.inputDf = self.inputDf.withColumn(x.name, when(isnull(col(x.name)),lit(value)).otherwise(col(x.name)))        \r\n",
							"    else:\r\n",
							"      self.inputDf = self.inputDf.fillna(value,subset)\r\n",
							"      \r\n",
							"    return self.inputDf\r\n",
							"\r\n",
							"#  Remove duplicates\r\n",
							"  def deDuplicate(self, subset=None):\r\n",
							"    self.inputDf = self.inputDf.dropDuplicates(subset)\r\n",
							"    return self.inputDf\r\n",
							"  \r\n",
							"#   Convert UTC timestamp to local\r\n",
							"  def utc_to_local(self,localTimeZone,subset=None):\r\n",
							"    if subset is not None:\r\n",
							"      tsCol = (x for x in  self.inputSchema if str(x.dataType)==\"TimestampType\" and x.name in subset)\r\n",
							"    else:\r\n",
							"      tsCol = (x for x in  self.inputSchema if str(x.dataType)==\"TimestampType\")\r\n",
							"      \r\n",
							"    for x in tsCol:\r\n",
							"      self.inputDf = self.inputDf.withColumn(x.name,from_utc_timestamp(col(x.name),localTimeZone))\r\n",
							"    return self.inputDf\r\n",
							"\r\n",
							"#   Convert timestamp in local timezone to UTC\r\n",
							"  def local_to_utc(self,localTimeZone,subset=None):\r\n",
							"    if subset is not None:\r\n",
							"      tsCol = (x for x in  self.inputSchema if str(x.dataType)==\"TimestampType\" and x.name in subset)\r\n",
							"    else:\r\n",
							"      tsCol = (x for x in  self.inputSchema if str(x.dataType)==\"TimestampType\")\r\n",
							"      \r\n",
							"    for x in tsCol:\r\n",
							"      self.inputDf = self.inputDf.withColumn(x.name,to_utc_timestamp(col(x.name),localTimeZone))\r\n",
							"    return self.inputDf\r\n",
							"  \r\n",
							"#   Change Timezone\r\n",
							"  def changeTimezone(self,fromTimezone,toTimezone,subset=None):\r\n",
							"    if subset is not None:\r\n",
							"      tsCol = (x for x in  self.inputSchema if str(x.dataType)==\"TimestampType\" and x.name in subset)\r\n",
							"    else:\r\n",
							"      tsCol = (x for x in  self.inputSchema if str(x.dataType)==\"TimestampType\")\r\n",
							"    \r\n",
							"    for x in tsCol:\r\n",
							"      self.inputDf = self.inputDf.withColumn(x.name,to_utc_timestamp(col(x.name),fromTimezone))\r\n",
							"      self.inputDf = self.inputDf.withColumn(x.name,from_utc_timestamp(col(x.name),toTimezone))\r\n",
							"    return self.inputDf\r\n",
							"\r\n",
							"#   Drop System/Non-Business Columns\r\n",
							"  def dropSysColumns(self,columns):\r\n",
							"    self.inputDf = self.inputDf.drop(columns)\r\n",
							"    return self.inputDf \r\n",
							"  \r\n",
							"#  Create Checksum Column \r\n",
							"  def addChecksumCol(self,colName):\r\n",
							"    self.inputDf = self.inputDf.withColumn(colName,sha1(concat_ws(\"~~\", *self.inputDf.columns)))\r\n",
							"    return self.inputDf\r\n",
							"\r\n",
							"# Convert Julian Date to Calendar Date  \r\n",
							"  def julian_to_calendar(self,subset):\r\n",
							"    julCol = (x for x in self.inputSchema if str(x.dataType)==\"IntegerType\" and x.name in subset)\r\n",
							"    for x in julCol:\r\n",
							"      self.inputDf = (self.inputDf.withColumn(x.name,col(x.name).cast(\"string\"))\r\n",
							"                                 .withColumn(x.name+\"_year\",\r\n",
							"                                             when((length(col(x.name))==5) & (substring(col(x.name),1,2) <=50),concat(lit('20'),substring(col(x.name),1,2)))\r\n",
							"                                             .when((length(col(x.name))==5) & (substring(col(x.name),1,2) >50),concat(lit('19'),substring(col(x.name),1,2)))\r\n",
							"                                             .when(length(col(x.name))==7,substring(col(x.name),1,4))\r\n",
							"                                             .otherwise(lit(0))\r\n",
							"                                            )\r\n",
							"                                 .withColumn(x.name+\"_days\",\r\n",
							"                                             when(length(col(x.name))==5,substring(col(x.name),3,3).cast(\"int\"))\r\n",
							"                                             .when(length(col(x.name))==7,substring(col(x.name),5,3).cast(\"int\"))\r\n",
							"                                             .otherwise(lit(0))\r\n",
							"                                            )\r\n",
							"                                 .withColumn(x.name+\"_ref_year\",concat(col(x.name+\"_year\"),lit(\"-01\"),lit(\"-01\")).cast(\"date\"))\r\n",
							"                                 .withColumn(x.name+\"_calendar\",expr(\"date_add(\" + x.name+\"_ref_year\"+\",\"+ x.name+\"_days)-1\"))\r\n",
							"                                 .drop(x.name, x.name+\"_year\",x.name+\"_days\",x.name+\"_ref_year\")\r\n",
							"                                 .withColumnRenamed(x.name+\"_calendar\",x.name)\r\n",
							"                                 \r\n",
							"                     )\r\n",
							"    return self.inputDf \r\n",
							"  \r\n",
							"# Convert Calendar Date to Julian Date \r\n",
							"  def calendar_to_julian(self, subset):\r\n",
							"    calCol = (x for x in self.inputSchema if ((str(x.dataType)==\"DateType\" or str(x.dataType)==\"TimestampType\") and x.name in subset))\r\n",
							"\r\n",
							"    for x in calCol:\r\n",
							"      self.inputDf = (self.inputDf.withColumn(x.name+\"_ref_year\", concat(year(col(x.name)).cast(\"string\"),lit(\"-01\"),lit(\"-01\")))\r\n",
							"                                  .withColumn(x.name+\"_datediff\", datediff(col(x.name),col(x.name+\"_ref_year\"))+1)\r\n",
							"                                  .withColumn(x.name+\"_julian\", concat(substring(year(col(x.name)).cast(\"string\"),3,2),col(x.name+\"_datediff\")).cast(\"int\"))\r\n",
							"                                  .drop(x.name,x.name+\"_ref_year\",x.name+\"_datediff\")\r\n",
							"                                  .withColumnRenamed(x.name+\"_julian\",x.name)\r\n",
							"                     )\r\n",
							"    return self.inputDf\r\n",
							"\r\n",
							"# Add a set of literal value columns to dataframe, pass as dictionary parameter  \r\n",
							"  def addLitCols(self,colDict):\r\n",
							"    for x in colDict.items():\r\n",
							"      self.inputDf = self.inputDf.withColumn(x[0],lit(x[1]))\r\n",
							"    return self.inputDf"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def flattenNested(df):\r\n",
							"    ###########################################################################################################################  \r\n",
							"    # Function: flattenNested\r\n",
							"    # Returns a flattened version of XML, JSON\r\n",
							"    #\r\n",
							"    # Parameters:\r\n",
							"    # df = Dataframe loaded with the Nested XML or JSON structure\r\n",
							"    #\r\n",
							"    # Returns:\r\n",
							"    # The dataframe with the flattened version of the XML or JSON structure\r\n",
							"    ##########################################################################################################################      \r\n",
							"    structCols = []\r\n",
							"    sep = \"_\"\r\n",
							"\r\n",
							"    for colName, colType in df.dtypes:\r\n",
							"        if colType.startswith(\"struct\"):\r\n",
							"            structCols.append(colName)\r\n",
							"\r\n",
							"    arrayCols = []\r\n",
							"    for colName, colType in df.dtypes:\r\n",
							"        if colType.startswith(\"array\"):\r\n",
							"            arrayCols.append(colName)\r\n",
							"\r\n",
							"    if structCols:  \r\n",
							"        structElement = []\r\n",
							"        for colName, colType in df.dtypes:\r\n",
							"            if colType.startswith(\"struct\"):\r\n",
							"                structElement.append(colName)\r\n",
							"        flattenCols = [fc for fc, _ in df.dtypes if fc not in structElement]\r\n",
							"        for nc in structElement:\r\n",
							"            for cc in df.select(f\"{nc}.*\").columns:\r\n",
							"                 flattenCols.append(F.col(f\"{nc}.{cc}\").alias(f\"{nc}{sep}{cc}\"))\r\n",
							"\r\n",
							"        df = df.select(flattenCols)          \r\n",
							"        return FlattenNested(df)\r\n",
							"\r\n",
							"    if arrayCols:\r\n",
							"        arrayElement = []\r\n",
							"        for colName, colType in df.dtypes:\r\n",
							"            if colType.startswith(\"array\"):\r\n",
							"                arrayElement.append(colName)\r\n",
							"\r\n",
							"        explodeddf = df\r\n",
							"        for nc in arrayElement:\r\n",
							"            explodeddf = explodeddf.withColumn(nc, F.explode_outer(F.col(nc)))     \r\n",
							"\r\n",
							"        df = explodeddf \r\n",
							"        return FlattenNested(df) \r\n",
							"\r\n",
							"    return df    "
						],
						"outputs": [],
						"execution_count": 3
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/datalake-functions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "common"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "bf683815-96a7-4b32-a34d-3938b06310af"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e836675f-2508-4873-ad4f-754d70253b22/resourceGroups/rg-synapse-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapse01-kn3acb6lw3vr4/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-kn3acb6lw3vr4.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Re-usable Datalake Functions"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"from notebookutils import mssparkutils"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /linkedServiceFunctions"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"storageAccount = '<Storage Account Name>'"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# readFile()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"def readFile(container, path, colSeparator=None, headerFlag=None):\r\n",
							"  # ##########################################################################################################################  \r\n",
							"  # Function: readFile\r\n",
							"  # Reads a file from Azure Gen2 Storage and returns as dataframe\r\n",
							"  # \r\n",
							"  # Parameters:\r\n",
							"  # storageAccount = Name of Storage Account  \r\n",
							"  # container = File System/Container of Azure Data Lake Storage\r\n",
							"  # path = realtive path of file including folder name, file name and file extension. For e.g /folder/file.extension\r\n",
							"  # colSeparator = Column separator for text files\r\n",
							"  # headerFlag = boolean flag to indicate whether the text file has a header or not  \r\n",
							"  # \r\n",
							"  # Returns:\r\n",
							"  # A dataframe of the raw file\r\n",
							"  # ##########################################################################################################################    \r\n",
							"\r\n",
							"    assert storageAccount is not None, \"Storage Account not specified\"   \r\n",
							"\r\n",
							"    filePath = \"abfss://\" + container + \"@\"+ storageAccount + \".dfs.core.windows.net/\" + path\r\n",
							"    if \".csv\" in path or \".txt\" in path:\r\n",
							"        df = spark.read.csv(path=filePath, sep=colSeparator, header=headerFlag, inferSchema=\"true\")\r\n",
							"    elif \".parquet\" in path:\r\n",
							"        df = spark.read.parquet(filePath)\r\n",
							"    elif \".json\" in path:\r\n",
							"        df = spark.read.json(filePath, multiLine= True)\r\n",
							"    elif \".orc\" in path:\r\n",
							"        df = spark.read.orc(filePath)\r\n",
							"    else:\r\n",
							"        df = spark.read.format(\"csv\").load(filePath)\r\n",
							"  \r\n",
							"    df =df.dropDuplicates()\r\n",
							"    return df\r\n",
							""
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# writeFile()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"def writeFile(df,container, path, writeMode=\"overwrite\", colSeparator=\",\"):\r\n",
							"  # ##########################################################################################################################  \r\n",
							"  # Function: writeFile\r\n",
							"  # Writes the input dataframe to a file in Azure Gen2 Storage\r\n",
							"  # \r\n",
							"  # Parameters:\r\n",
							"  # df= input dataframe\r\n",
							"  # storageAccount = Name of Storage Account\r\n",
							"  # container = File System/Container of Azure Data Lake Storage\r\n",
							"  # path = realtive path of file including folder name, file name and file extension. For e.g /folder/file.extension\r\n",
							"  # writeMode= mode of writing the curated file. Allowed values - append/overwrite/ignore/error/errorifexists\r\n",
							"  # colSeparator = Column separator for text files\r\n",
							"  # \r\n",
							"  # Returns:\r\n",
							"  # A dataframe of the raw file\r\n",
							"  # ##########################################################################################################################     \r\n",
							"    assert storageAccount is not None, \"Storage Account not specified\"   \r\n",
							"    filePath = \"abfss://\" + container + \"@\"+ storageAccount + \".dfs.core.windows.net/\" + path\r\n",
							"    if \"csv\" in path or 'txt' in path:\r\n",
							"        df.write.csv(filePath,mode=writeMode,sep=colSeparator,header=\"true\")\r\n",
							"    elif \"parquet\" in path:\r\n",
							"        df.write.parquet(filePath,mode=writeMode)\r\n",
							"    elif \"orc\" in path:\r\n",
							"        df.write.orc(filePath,mode=writeMode)\r\n",
							"    elif \"json\" in path:\r\n",
							"        df.write.json(filePath, mode=writeMode)\r\n",
							"    else:\r\n",
							"        df.write.save(path=filePath,format=\"csv\",mode=writeMode)\r\n",
							"    return\r\n",
							""
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# getFolder()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def getFolder(storageZoneLinkedServiceName, container, folder):\r\n",
							"    # ##########################################################################################################################  \r\n",
							"    # Function: getFolder\r\n",
							"    # Returns a fully qualified name of a folder in ADLS Gen2 Storage\r\n",
							"    # \r\n",
							"    # Parameters:\r\n",
							"    # storageZoneLinkedServiceName = Linked service name for the storage zone\r\n",
							"    # container = File System/Container of Azure Data Lake Storage\r\n",
							"    # folder = Folder name\r\n",
							"    # \r\n",
							"    # Returns:\r\n",
							"    # The fully qualified name of a folder in Storage Account of Azure Data Lake Storage\r\n",
							"    # ##########################################################################################################################     \r\n",
							"\r\n",
							"    storageEndpoint = getLinkedServiceEndpoint(storageZoneLinkedServiceName)\r\n",
							"    folderPath = \"abfss://\" + container + \"@\" + storageEndpoint + folder\r\n",
							"    \r\n",
							"    return folderPath"
						],
						"outputs": [],
						"execution_count": 8
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dedicatedSQLPool-functions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "common"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "813a6500-1f06-43d5-9492-ca8cc6ad75b1"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/735994b1-b3b0-46d5-96bc-c9b30ddb4265/resourceGroups/rg-synapse-dp/providers/Microsoft.Synapse/workspaces/ba-synapse01-lhf7sbrgc3jru/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-lhf7sbrgc3jru.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Re-usable functions for Azure Synapse SQL Dedicated Pool"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /common/keyvault-functions {\"kvLinkedService\": \"keyvault01\"}"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"server=\"<SynapseWorkspaceName>.sql.azuresynapse.net,1433\"\n",
							"database = \"<DedicatedSQLPool>\""
						],
						"outputs": [],
						"execution_count": 44
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import com.microsoft.spark.sqlanalytics\n",
							"from com.microsoft.spark.sqlanalytics.Constants import Constants\n",
							"import sys"
						],
						"outputs": [],
						"execution_count": 45
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## readSdpTable()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def readSdpTable(schema,table,colList=None,filterCondition=None,limitRows=None):\n",
							"  # ##########################################################################################################################  \n",
							"  # Function: readSdpTable\n",
							"  # Reads records from the Azure Synapse Dedicated Pool table/view and returns as dataframe\n",
							"  # \n",
							"  # Parameters:\n",
							"  #     schema          = Schema name of the Azure Synapse Dedicated Pool table.\n",
							"  #     table           = Table Name.\n",
							"  #     colList         = (Optional) List of columns to be returned in the dataframe. \n",
							"  #                       E.g [\"col1\",\"col2\",\"col3\"].\n",
							"  #                       Returns all columns if none provided.\n",
							"  #     filterCondition = (Optional) Expression to filter the dataframe as push-down filter to database. \n",
							"  #                       E.g col(\"Title\").contains(\"E\").\n",
							"  #                       Returns all rows when not provided.\n",
							"  #     limitRows       = (Optional) Integer to fetch N records from the table.\n",
							"  #                       Returns all rows when none provided.\n",
							"  #\n",
							"  # Returns:\n",
							"  #     Dataframe containing the relevant rows and columns of an Azure Synapse Dedicated Pool table/view\n",
							"  # ##########################################################################################################################  \n",
							"    assert server is not None, \"Server not specified\"\n",
							"    assert database is not None, \"Database not specified\"\n",
							"    assert schema is not None, \"Schema not specified\"\n",
							"    assert table is not None, \"Table not specified\"\n",
							"\n",
							"    tableName = database + \".\" + schema+ \".\" + table\n",
							"   \n",
							"    try:\n",
							"        if server is not None and database is not None and schema is not None and table is not None:\n",
							"            df = (spark.read\n",
							"                        .option(Constants.SERVER,server)\n",
							"                        .synapsesql(tableName)\n",
							"                )\n",
							"\n",
							"        if colList is not None:\n",
							"            df = df.select(colList)\n",
							"        \n",
							"        if filterCondition is not None:\n",
							"            df = df.filter(filterCondition)\n",
							"\n",
							"        if limitRows is not None:\n",
							"            df = df.limit(limitRows)\n",
							"    except Exception as e:\n",
							"        print(\"Read from {}.{} failed with exception:\".format(schema,table))   \n",
							"        raise e\n",
							"    return df"
						],
						"outputs": [],
						"execution_count": 47
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## insertSdpTable()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def insertSdpTable(df, schema,table, mode):\n",
							"  # ##########################################################################################################################  \n",
							"  # Function: insertSdpTable\n",
							"  # Writes a dataframe to an Azure Synapse Dedicated Pool table\n",
							"  # \n",
							"  # Parameters:\n",
							"  #     df              = Dataframe to be written to Azure Synapse Dedicated Pool table.\n",
							"  #     schema          = Schema name of the Azure Synapse Dedicated Pool table.\n",
							"  #     table           = Table Name.\n",
							"  #     mode            = Write mode to table. \n",
							"  #                       Options for write modes are \"error\" or \"errorifexists\" (default), \"overwrite\", \"append\", \"ignore\".\n",
							"  #\n",
							"  # Returns:\n",
							"  #     None\n",
							"  # ##########################################################################################################################  \n",
							"    assert server is not None, \"Server not specified\"\n",
							"    assert database is not None, \"Database not specified\"\n",
							"    assert schema is not None, \"Schema not specified\"\n",
							"    assert table is not None, \"Table not specified\"\n",
							"    assert mode in [\"append\",\"overwrite\",\"error\",\"errorifexists\",\"ignore\"], \"Invalid mode specified. Mode should be either append,overwrite,error,errorifexists or ignore\"\n",
							"\n",
							"    tableName = database + \".\" + schema+ \".\" + table\n",
							"    try:\n",
							"      (df.write\n",
							"          .option(Constants.SERVER, server)\n",
							"          .mode(mode)\n",
							"          .synapsesql(tableName))\n",
							"    except Exception as e:\n",
							"      print(\"Insert to {}.{} failed with exception:\".format(schema,table))\n",
							"      raise e\n",
							"    return\n",
							""
						],
						"outputs": [],
						"execution_count": 1
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/deltaLakeFunctions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "common"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "d9f0597d-1178-4b5b-a42c-9342098c5790"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e836675f-2508-4873-ad4f-754d70253b22/resourceGroups/rg-synapse-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapse01-kn3acb6lw3vr4/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-kn3acb6lw3vr4.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /linkedServiceFunctions"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /datalake-functions"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"deltaZone = getLinkedServiceEndpoint(\"DeltaZone\")"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def readDeltaTable(tableName):\r\n",
							"    # ##########################################################################################################################  \r\n",
							"    # Function: readDeltaTable\r\n",
							"    # Returns a Delta Table records as a dataframe\r\n",
							"    # \r\n",
							"    # Parameters:\r\n",
							"    # tableName = A Valid Delta Table Name\r\n",
							"    #\r\n",
							"    # Returns:\r\n",
							"    # Dataframe containing all rows and columns returned by query from Delta Lake\r\n",
							"    # ##########################################################################################################################  \r\n",
							"    tableExist = False\r\n",
							"    try:\r\n",
							"        df = spark.read.table(tableName)\r\n",
							"        tableExist = True\r\n",
							"    except:\r\n",
							"        print(\"Table does not exist - \" + tableName)\r\n",
							"    return df"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"source": [
							"def snapshotDelta(df, targetTable,  container, folder, keyColumns):\r\n",
							"    # ##########################################################################################################################  \r\n",
							"    # Function: snapshotDelta\r\n",
							"    # Performs a Snapshot Delete reload action on Delta Table\r\n",
							"    #\r\n",
							"    # Parameters:\r\n",
							"    # df = input dataframe\r\n",
							"    # targetTable = Name of Target Table\r\n",
							"    # container = container used for creating Delta table schema and merging new data\r\n",
							"    # folder = folder used for creating Delta table schema and merging new data\r\n",
							"    # keyColumns = List of columns that uniquely defines a record in input dataframe\r\n",
							" \r\n",
							"    # Returns:\r\n",
							"    # \r\n",
							"    # ##########################################################################################################################\r\n",
							"\r\n",
							"    #Source and Target Alias\r\n",
							"    targetTableAlias = \"Target\"\r\n",
							"    stagingTableAlias = \"Source\"\r\n",
							"    \r\n",
							"    deltaPath = \"abfss://\" + container + \"@\"+ deltaZone + folder\r\n",
							" \r\n",
							"    uniqueCols = keyColumns.split(\"|\")\r\n",
							"\r\n",
							"    #Check the Table/Path is a Delta Table \r\n",
							"    pathExists = False\r\n",
							"    tableExists = False\r\n",
							"    try:\r\n",
							"        DeltaTable.forPath(spark, deltaPath)\r\n",
							"        pathExists = True        \r\n",
							"    except:\r\n",
							"        pass\r\n",
							"    try:\r\n",
							"        DeltaTable.forName(spark, targetTable)\r\n",
							"        tableExists = True        \r\n",
							"    except:\r\n",
							"        pass\r\n",
							"        \r\n",
							"    if pathExists == True and tableExists == True:\r\n",
							"                \r\n",
							"        # Delete records from destination for the snapshot period being loaded\r\n",
							"        deltaTable = DeltaTable.forName(spark, targetTable)\r\n",
							"        remove  = \"and\"\r\n",
							"        reverse_remove = remove[::-1]\r\n",
							"        \r\n",
							"        distinctCols = df.select(uniqueCols).distinct().collect()\r\n",
							"        for k in distinctCols :\r\n",
							"            deleteCondn = \"\"\r\n",
							"            for i in range(len(k)):\r\n",
							"                deleteCondn = deleteCondn + str(uniqueCols[i]) + \" = '\" + str(k[i]) + \"' and \"\r\n",
							"            deleteCondn = deleteCondn[::-1].replace(reverse_remove,\"\",1)[::-1]\r\n",
							"            deltaTable.delete(deleteCondn)\r\n",
							"            print(deleteCondn)\r\n",
							"\r\n",
							"        # Insert records from source\r\n",
							"        columns = (((str(df.columns).replace(\"'\", \"\")).replace(\"[\",\"\")).replace(\"]\",\"\")).replace(\" \",\"\")\r\n",
							"        insertStatement = \"\"\r\n",
							"        insertColumns   = columns.split(\",\")\r\n",
							"        for insertCols in insertColumns:\r\n",
							"            insertStatement = insertStatement + '\"' + insertCols  + '\": \"' +  stagingTableAlias + \".\" + insertCols + '\", ' \r\n",
							"\r\n",
							"        # Convert Insert Expression in to Dict\r\n",
							"        insertStatement = json.loads(\"{\"+insertStatement.rstrip(', ')+\"}\")\r\n",
							"\r\n",
							"        lookupStatement = \" 1 = 2 \" \r\n",
							"        deltaTable.alias(targetTableAlias).merge(df.alias(stagingTableAlias), lookupStatement).whenNotMatchedInsert(values = insertStatement).execute()\r\n",
							"        \r\n",
							"    elif pathExists == False and tableExists == True:\r\n",
							"        raise Exception(\"Table Exists.Path Does Not Exist - Please check deployment configuration\")\r\n",
							"    elif pathExists == True and tableExists == False:\r\n",
							"        raise Exception(\"Path Exists.Table does not Exist - Please check deployment configuration\")\r\n",
							"    elif pathExists == False and tableExists == False:\r\n",
							"        raise Exception(\"Table does not exist - Please create through deployment configuration\")"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upsertDelta(df, targetTable, container, folder, keyColumns=None, watermarkNames=None):\r\n",
							"    # ##########################################################################################################################  \r\n",
							"    # Function: upsertDeltaLake\r\n",
							"    # Performs a Merge/Upsert action on Delta Table\r\n",
							"    #\r\n",
							"    # Parameters:\r\n",
							"    # df = input dataframe\r\n",
							"    # targetTable = Name of Target Table\r\n",
							"    # container = container used for creating Delta table schema and merging new data\r\n",
							"    # folder = folder used for creating Delta table schema and merging new data\r\n",
							"    # keyColumns = List of columns that uniquely defines a record in input dataframe\r\n",
							"    # watermarkNames = Name of watermark columns in input dataframe\r\n",
							"    # \r\n",
							"    # Returns:\r\n",
							"    # Print - Lookup Statement\r\n",
							"\r\n",
							"    #Source and Target Alias\r\n",
							"    targetTableAlias = \"Target\"\r\n",
							"    stagingTableAlias = \"Source\"\r\n",
							"\r\n",
							"    #Read Columns Names from Dataframe\r\n",
							"    deltaPath    = \"abfss://\" + container + \"@\"+ deltaZone  + folder\r\n",
							"    columns = (((str(df.columns).replace(\"'\", \"\")).replace(\"[\",\"\")).replace(\"]\",\"\")).replace(\" \",\"\")\r\n",
							"    \r\n",
							"    #Check the Table/Path is a Delta Table \r\n",
							"    pathExists = False\r\n",
							"    tableExists = False\r\n",
							"    try:\r\n",
							"        DeltaTable.forPath(spark, deltaPath)\r\n",
							"        pathExists = True        \r\n",
							"    except:\r\n",
							"        pass\r\n",
							"    try:\r\n",
							"        DeltaTable.forName(spark, targetTable)\r\n",
							"        tableExists = True        \r\n",
							"    except:\r\n",
							"        pass\r\n",
							"        \r\n",
							"    if pathExists == True and tableExists == True:\r\n",
							"        uniqueCols = keyColumns.split(\"|\")\r\n",
							"        \r\n",
							"        lookupStatement = \"\"  \r\n",
							"        for lookupCol in uniqueCols:\r\n",
							"            lookupStatement = lookupStatement + targetTableAlias + \".\" + lookupCol  + \" = \" + stagingTableAlias + \".\" + lookupCol + \" and \" \r\n",
							"        \r\n",
							"        remove = \"and\"\r\n",
							"        reverse_remove = remove[::-1]\r\n",
							"        \r\n",
							"        if watermarkNames is not None and  len(watermarkNames) >0:\r\n",
							"            lookupUpdateStatement = lookupStatement + stagingTableAlias  +\".\"+ watermarkNames  + \" >= \"+ targetTableAlias + \".\" + watermarkNames\r\n",
							"            uniqueWatermarkCols = watermarkNames.split(\"|\") \r\n",
							"\r\n",
							"            if len(uniqueWatermarkCols) > 1:\r\n",
							"                stgGreatestWatermark = [stagingTableAlias + \".\" + col  for col in uniqueWatermarkCols]\r\n",
							"                tgtGreatestWatermark = [targetTableAlias + \".\" + col  for col in uniqueWatermarkCols]\r\n",
							"                uniqueWatermarkColsExpr = \"greatest(\" + \",\".join(stgGreatestWatermark) + \") >= \" + \"greatest(\" + \",\".join(tgtGreatestWatermark) + \")\"\r\n",
							"                lookupUpdateStatement   = lookupStatement + uniqueWatermarkColsExpr\r\n",
							"                \r\n",
							"            lookupStatement = lookupStatement[::-1].replace(reverse_remove,\"\",1)[::-1]\r\n",
							"\r\n",
							"        if watermarkNames is None or len(watermarkNames)==0:\r\n",
							"            lookupStatement = lookupStatement[::-1].replace(reverse_remove,\"\",1)[::-1]\r\n",
							"            lookupUpdateStatement = lookupStatement\r\n",
							"\r\n",
							"        #Update Expression\r\n",
							"        updateStatement = \"\"\r\n",
							"        insertStatement = \"\"\r\n",
							"        updateColumns = columns.split(\",\")\r\n",
							"        \r\n",
							"        for updateCols in updateColumns:\r\n",
							"            if updateCols == \"ActivityUpdateLogId\" :\r\n",
							"                updateStatement = updateStatement + '\"' +updateCols  + '\": \"' +  stagingTableAlias + \".ActivityLogId\" + '\", '\r\n",
							"            elif updateCols == \"MetaUpdateDt\" :\r\n",
							"                updateStatement = updateStatement + '\"' +updateCols  + '\": \"' +  stagingTableAlias + \".MetaLoadDt\" + '\", '\r\n",
							"            elif updateCols == \"MetaLoadDt\" or updateCols == \"ActivityLogId\" :\r\n",
							"                updateStatement = updateStatement            \r\n",
							"            else :\r\n",
							"                updateStatement = updateStatement + '\"' +updateCols  + '\": \"' +  stagingTableAlias + \".\" + updateCols + '\", '\r\n",
							"            insertStatement = insertStatement + '\"' +updateCols  + '\": \"' +  stagingTableAlias + \".\" + updateCols + '\", '\r\n",
							"\r\n",
							"        #Convert Insert and Update Expression in to Dict\r\n",
							"        updateStatement = json.loads(\"{\"+updateStatement.rstrip(', ')+\"}\")\r\n",
							"        insertStatement = json.loads(\"{\"+insertStatement.rstrip(', ')+\"}\")\r\n",
							"\r\n",
							"        updateCondition = stagingTableAlias + \".MetaRowHash <> \" + targetTableAlias + \".MetaRowHash\"\r\n",
							"\r\n",
							"        print(lookupUpdateStatement +\"; \" + lookupStatement)\r\n",
							"    \r\n",
							"        # Write to DeltaPath\r\n",
							"        deltaTable = DeltaTable.forPath(spark, deltaPath)\r\n",
							"        deltaTable.alias(targetTableAlias).merge(df.alias(stagingTableAlias), lookupUpdateStatement)\\\r\n",
							"        .whenMatchedUpdate(condition = updateCondition, set = updateStatement).execute()\r\n",
							"        deltaTable.alias(targetTableAlias).merge(df.alias(stagingTableAlias), lookupStatement).whenNotMatchedInsert(values = insertStatement).execute()\r\n",
							"        \r\n",
							"    elif pathExists == False and tableExists == True:\r\n",
							"        raise Exception(\"Table Exists.Path Does Not Exist - Please check deployment configuration\")\r\n",
							"    elif pathExists == True and tableExists == False:\r\n",
							"        raise Exception(\"Path Exists.Table does not Exist - Please check deployment configuration\")\r\n",
							"    elif pathExists == False and tableExists == False:\r\n",
							"        raise Exception(\"Table does not exist - Please create through deployment configuration\")"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def insertDelta(df, targetTable, container, folder):\r\n",
							"    # ##########################################################################################################################  \r\n",
							"    # Function: insertDelta\r\n",
							"    # Performs an Insert action on Delta Table\r\n",
							"    #\r\n",
							"    # Parameters:\r\n",
							"    # df = input dataframe\r\n",
							"    # targetTable = Name of Target Table\r\n",
							"    # container = container used for creating Delta table schema and merging new data\r\n",
							"    # folder = folder used for creating Delta table schema and merging new data\r\n",
							"    # \r\n",
							"    # Returns:\r\n",
							"    # \r\n",
							"    # ########################################################################################################################## \r\n",
							"    \r\n",
							"    deltaPath = \"abfss://\" + container + \"@\"+ deltaZone + folder\r\n",
							"    targetTableAlias = \"tgt\"\r\n",
							"    stagingTableAlias = \"stg\"\r\n",
							"    \r\n",
							"     #Check the Table/Path is a Delta Table \r\n",
							"    pathExists = False\r\n",
							"    tableExists = False\r\n",
							"    try:\r\n",
							"        DeltaTable.forPath(spark, deltaPath)\r\n",
							"        pathExists = True        \r\n",
							"    except:\r\n",
							"        pass\r\n",
							"    try:\r\n",
							"        DeltaTable.forName(spark, targetTable)\r\n",
							"        tableExists = True        \r\n",
							"    except:\r\n",
							"        pass\r\n",
							"        \r\n",
							"    #Write to targetTable - Append records from source\r\n",
							"    if pathExists == True and tableExists == True:\r\n",
							"        deltaTable = DeltaTable.forName(spark, targetTable)\r\n",
							"        columns = (((str(df.columns).replace(\"'\", \"\")).replace(\"[\",\"\")).replace(\"]\",\"\")).replace(\" \",\"\")\r\n",
							"        insertStatement = \"\"\r\n",
							"        insertColumns   = columns.split(\",\")\r\n",
							"        for insertCols in insertColumns:\r\n",
							"            insertStatement = insertStatement + '\"' + insertCols  + '\": \"' +  stagingTableAlias + \".\" + insertCols + '\", ' \r\n",
							"\r\n",
							"        # Convert Insert Expression in to Dict\r\n",
							"        insertStatement = json.loads(\"{\"+insertStatement.rstrip(', ')+\"}\")\r\n",
							"\r\n",
							"        lookupStatement = \" 1 = 2 \" \r\n",
							"        deltaTable.alias(targetTableAlias).merge(df.alias(stagingTableAlias), lookupStatement).whenNotMatchedInsert(values = insertStatement).execute()\r\n",
							"        \r\n",
							"    elif pathExists == False and tableExists == True:\r\n",
							"        raise Exception(\"Table Exists.Path Does Not Exist - Please check deployment configuration\")\r\n",
							"    elif pathExists == True and tableExists == False:\r\n",
							"        raise Exception(\"Path Exists.Table does not Exist - Please check deployment configuration\")\r\n",
							"    elif pathExists == False and tableExists == False:\r\n",
							"        raise Exception(\"Table does not exist - Please create through deployment configuration\")\r\n",
							""
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def deltaTableDeployment(tableName, storageZoneLinkedServiceName, fileSystem, folder, schema):\r\n",
							"    # ##########################################################################################################################  \r\n",
							"    # Function: deltaTableDeployment\r\n",
							"    # Performs Delta Table Schema Deployments\r\n",
							"    #\r\n",
							"    # Parameters:\r\n",
							"    # tableName = DeltaTable Name\r\n",
							"    # storageZoneLinkedServiceName = Linked service name for the storage zone\r\n",
							"    # fileSystem = fileSystem used for creating Delta table schema and merging new data\r\n",
							"    # folder = folder used for creating Delta table schema and merging new data\r\n",
							"    # schema = Delta Table Schema\r\n",
							"    # \r\n",
							"    # Returns:\r\n",
							"    # \r\n",
							"    # ########################################################################################################################## \r\n",
							"    deltapath = getFolder(storageZoneLinkedServiceName, fileSystem, folder)\r\n",
							"\r\n",
							"    #Creates an Empty Dataframe with the desired Schema\r\n",
							"    dfSchema = spark.createDataFrame([], schema)\r\n",
							"\r\n",
							"    #Check the Table/Path is a Delta Table \r\n",
							"    pathExists = False\r\n",
							"    tableExists = False\r\n",
							"    try:\r\n",
							"        DeltaTable.forPath(spark, deltapath)\r\n",
							"        pathExists = True        \r\n",
							"    except:\r\n",
							"        pass\r\n",
							"    try:\r\n",
							"        DeltaTable.forName(spark, tableName)\r\n",
							"        tableExists = True        \r\n",
							"    except:\r\n",
							"        pass\r\n",
							"\r\n",
							"    if pathExists == True and tableExists == True:\r\n",
							"        dfCurrentTable = spark.read.table(tableName)\r\n",
							"\r\n",
							"        if dfSchema.schema == dfCurrentTable.schema:\r\n",
							"            print(\"Schema is Identical, no change required - \" + tableName)\r\n",
							"        if dfSchema.schema != dfCurrentTable.schema:\r\n",
							"            print(\"Schema changes required\")\r\n",
							"            \r\n",
							"            #Select Schema Columns\r\n",
							"            dfFinal = dfSchema.unionByName(dfCurrentTable, allowMissingColumns=True)\r\n",
							"            dfFinal = dfFinal.select(dfSchema.columns)\r\n",
							"\r\n",
							"            for field in dfSchema.schema.fields:\r\n",
							"                dataType = str(field.dataType)\r\n",
							"                columnName = str(field.name)\r\n",
							"\r\n",
							"                if search(\"Decimal\", str(field.dataType)):\r\n",
							"                    dfFinal = dfFinal.withColumn(columnName, col(columnName).cast(eval(dataType)))\r\n",
							"                else:\r\n",
							"                    dataType = dataType + \"()\"\r\n",
							"                    dfFinal = dfFinal.withColumn(columnName, col(columnName).cast(eval(dataType)))\r\n",
							"\r\n",
							"            spark.sql(\"Drop table IF EXISTS \" + tableName)\r\n",
							"            dfFinal.write.option(\"overwriteSchema\", \"true\").format(\"delta\").mode(\"overwrite\").save(deltapath)\r\n",
							"            spark.sql(\"CREATE TABLE IF NOT EXISTS \" + tableName +\" USING DELTA LOCATION '\" + deltapath + \"'\")\r\n",
							"            print(\"Schema updated - \" + tableName)      \r\n",
							"\r\n",
							"    #Create Table if not exists\r\n",
							"    if pathExists == False and tableExists == False:\r\n",
							"            dfSchema.write.option(\"overwriteSchema\", \"true\").format(\"delta\").mode(\"overwrite\").save(deltapath)\r\n",
							"            spark.sql(\"CREATE TABLE IF NOT EXISTS \" + tableName +\" USING DELTA LOCATION '\" + deltapath + \"'\")\r\n",
							"            print(\"Delta Table did not exist, Table Created - \" + tableName)\r\n",
							"    if (pathExists == False and tableExists == True) or (pathExists == True and tableExists == False):\r\n",
							"        print(\"Path already exists - \" + str(pathExists))\r\n",
							"        print(\"Table already exists - \" + str(tableExists))"
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/keyvault-functions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "common"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "2fb28b6d-2802-4d63-a13e-19d1b3859c2c"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e836675f-2508-4873-ad4f-754d70253b22/resourceGroups/rg-synapse-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapse01-kn3acb6lw3vr4/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-kn3acb6lw3vr4.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Re-usable Azure Key Vault Functions"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Parameters and Init"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"kvLinkedService ='your Azure Key Vault Linked Service referenced by this Synapse Workspace'"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"from notebookutils import mssparkutils"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"source": [
							"## getSecret()\n",
							""
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"def getSecret (secretName):\n",
							"# ##########################################################################################################################  \n",
							"# Function: getSecret\n",
							"# Returns the value of a secret stored in Azure Key Vault that is referenced as link service\n",
							"# \n",
							"# Parameters:\n",
							"# secretName = Name of secret in Azure Key Vault\n",
							"# \n",
							"# Returns:\n",
							"# The value of secret stored in Azure Key Vault\n",
							"# ##########################################################################################################################\n",
							"    assert secretName is not None, \"secretName not specified\"\n",
							"    try:\n",
							"        return mssparkutils.credentials.getSecretWithLS(kvLinkedService,secretName) #kvLinkedService is a notebook parameter set by the calling notebook\n",
							"    except Exception as e:\n",
							"        print(\"Either Linked Service: \" + kvLinkedService + \" does not exist or Secret: \" + secretName + \" does not exist\")\n",
							"        raise e"
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/linkedServiceFunctions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "common"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "5d7d3e8d-6233-487f-aac3-7e8cbd09c85a"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import json"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def getSDPDatabaseName(sdpLinkedServiceName):\r\n",
							"    # ##########################################################################################################################  \r\n",
							"    # Function: getSDPDatabaseName\r\n",
							"    # \r\n",
							"    # Parameters:\r\n",
							"    # sdpLinkedServiceName = Linked service name for SQL Dedicated Pool\r\n",
							"    # \r\n",
							"    # Returns:\r\n",
							"    # The name of SQL Dedicated Pool Database Name\r\n",
							"    # ##########################################################################################################################     \r\n",
							"    linkedServiceProperties = mssparkutils.credentials.getPropertiesAll(sdpLinkedServiceName)\r\n",
							"    SDPDatabaseName = json.loads(linkedServiceProperties).get('Database')\r\n",
							"    SDPDatabaseName = SDPDatabaseName.replace('https://','')\r\n",
							"    return SDPDatabaseName"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def getLinkedServiceEndpoint(linkedServiceName):\r\n",
							"    # ##########################################################################################################################  \r\n",
							"    # Function: getLinkedServiceEndpoint\r\n",
							"    # \r\n",
							"    # Parameters:\r\n",
							"    # linkedServiceName = Linked service name Storage Account\r\n",
							"    # \r\n",
							"    # Returns:\r\n",
							"    # The Endpoint of the Linked Service Properties\r\n",
							"    # ##########################################################################################################################     \r\n",
							"    linkedServiceProperties = mssparkutils.credentials.getPropertiesAll(linkedServiceName)\r\n",
							"    endpoint = json.loads(linkedServiceProperties).get('Endpoint')\r\n",
							"    endpoint = endpoint.replace('https://','')\r\n",
							"    return endpoint"
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/test-AAD-functions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Notebook to unit test AAD-functions",
				"folder": {
					"name": "unit tests"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "f235c7e3-6252-4d2a-b6d5-4c941d90ea07"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/5a5ba4fb-f4e0-4eaf-a2d3-7db71dfd729d/resourceGroups/rg-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapseanalytics01/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapseanalytics01.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Unit Test AAD-functions"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"%run /common/AAD-functions {\"tenandIdSecret\":\"TenantID\", \"servicePrincipalIdSecret\": \"ba-automation-spn-clientID\",\"servicePrincipalSecret\": \"ba-automation-spn\",\"authUrl\": \"https://login.windows.net\",\"resourceUrl\": \"https://database.windows.net/\"}"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Test getBearerToken()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"bearerToken =getBearerToken()\r\n",
							"print(bearerToken)"
						],
						"outputs": [],
						"execution_count": 14
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/test-SQL-functions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Notebook to unit test SQL-functions",
				"folder": {
					"name": "unit tests"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "1aee67e7-d997-4d9b-a215-32d4b3083574"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/5a5ba4fb-f4e0-4eaf-a2d3-7db71dfd729d/resourceGroups/rg-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapseanalytics01/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapseanalytics01.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Unit Test SQL-functions"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"%run /common/SQL-functions {\"server\":\"ba-sqlserver1\", \"database\": \"AdventureWorks\",\"usernameSecret\": \"ba-sqlserver1-sqlusername\", \"passwordSecret\": \"ba-sqlserver1-password\"}"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Test readTable()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"df = readTable (\"Person.Address\")\r\n",
							"display(df)"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Test readQuery()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"query =(\"select Person.BusinessEntityAddress.AddressID, Person.AddressType.NAME\"\r\n",
							"        + \" from Person.BusinessEntityAddress \"\r\n",
							"        + \" inner join Person.AddressType \"\r\n",
							"       + \" ON Person.AddressType.AddressTypeID = Person.BusinessEntityAddress.AddressTypeID\")\r\n",
							"\r\n",
							"df = readQuery(query)\r\n",
							"display(df)\r\n",
							""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Test insertTable()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Overwrite, Create new table if doesn't exist\r\n",
							"insertTable(df,\"dbo.test\",\"overwrite\",preserveSchema = False)"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Overwrite, Preserve schema if table exists\r\n",
							"insertTable(df,\"dbo.test\",\"overwrite\",preserveSchema = True)"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Append\r\n",
							"insertTable(df,\"dbo.test\",\"append\")"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Test Upsert()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df = readTable (\"Person.Address\")\r\n",
							"\r\n",
							"upsert(df,\"dbo\",\"AddressStage\", \"dbo\", \"AddressMerge\", [\"AddressID\"], [\"AddressID\"],\"ModifiedDate\") "
						],
						"outputs": [],
						"execution_count": 14
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/test-commonTransforms')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Notebook to unit test commonTransforms class",
				"folder": {
					"name": "unit tests"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "11a5dc34-c89e-4ba8-bce3-f16f99df28c6"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/5a5ba4fb-f4e0-4eaf-a2d3-7db71dfd729d/resourceGroups/rg-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapseanalytics01/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapseanalytics01.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql import DataFrame,Column,functions,types"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /common/commonTransforms"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /common/datalake-functions"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# Test File\r\n",
							"file = \"abfss://raw-bronze@bastoragedatalake01.dfs.core.windows.net/nyc-yellowtaxi-trip/yellow_tripdata_2020-01.csv\"\r\n",
							"# Config schema explicitly for testing purposes\r\n",
							"dataSchema=\"VendorID STRING,tpep_pickup_datetime TIMESTAMP,tpep_dropoff_datetime TIMESTAMP,passenger_count INT,trip_distance DOUBLE,RatecodeID STRING,store_and_fwd_flag STRING,PULocationID INT,DOLocationID INT,payment_type INT,fare_amount DOUBLE,extra DOUBLE,mta_tax DOUBLE,tip_amount DOUBLE,tolls_amount DOUBLE,improvement_surcharge DOUBLE,total_amount DOUBLE,congestion_surcharge DOUBLE\"\r\n",
							"input=spark.read.csv(path=file,schema=dataSchema,header=True)\r\n",
							"display(input)"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"input = input.withColumn(\"sys_date1\",lit(20275)) #Date in Julian Format\r\n",
							"input = input.withColumn(\"sys_date2\",lit(\"2020-10-01\").cast(\"date\")) #Date in Gregorian Format"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"display(input)"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"ct=CommonTransforms(input)\r\n",
							"\r\n",
							"# Remove duplicates\r\n",
							"output=ct.deDuplicate()\r\n",
							"\r\n",
							"# Remove duplicates based on key columns\r\n",
							"output=ct.deDuplicate([\"VendorID\",\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\"])\r\n",
							"\r\n",
							"# Remove leading and trailing spaces from all string columns\r\n",
							"output=ct.trim()\r\n",
							"\r\n",
							"# Replace Null Value with generic values\r\n",
							"output = ct.replaceNull(0)\r\n",
							"output = ct.replaceNull(\"NA\")\r\n",
							"output = ct.replaceNull(\"2020-01-01\")\r\n",
							"\r\n",
							"# Replace Null value in Timestamp columns\r\n",
							"output = ct.replaceNull(\"1900-01-01T00:00:00\",\"tpep_pickup_datetime\")\r\n",
							"output = ct.replaceNull(\"9999-12-31T23:59:59\",\"tpep_dropoff_datetime\")\r\n",
							"\r\n",
							"# Replace Null Values with custom defaults\r\n",
							"output = ct.replaceNull({\"passenger_count\":1,\"store_and_fwd_flag\":\"N\",\"tip_amount\":0,\"tolls_amount\":0, \"improvement_surcharge\":0,\"congestion_surcharge\":0})\r\n",
							"\r\n",
							"# Convert UTC timestamps to local\r\n",
							"output = ct.utc_to_local(\"Australia/Sydney\")\r\n",
							"output = ct.utc_to_local(\"Australia/Sydney\",[\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\"])\r\n",
							"\r\n",
							"\r\n",
							"# Convert local timestamps to UTC\r\n",
							"output = ct.local_to_utc(\"Australia/Sydney\")\r\n",
							"output = ct.local_to_utc(\"Australia/Sydney\",[\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\"])\r\n",
							"\r\n",
							"# Convert time from one Timezone to another\r\n",
							"output = ct.changeTimezone(\"Australia/Sydney\",\"America/New_York\")\r\n",
							"\r\n",
							"# Drop system/non-business columns\r\n",
							"output = ct.dropSysColumns(\"store_and_fwd_flag\")\r\n",
							"\r\n",
							"# Add Checksum\r\n",
							"output = ct.addChecksumCol(\"checksum\")\r\n",
							"\r\n",
							"# Convert Julian date to Calendar date\r\n",
							"output = ct.julian_to_calendar(\"sys_date1\")\r\n",
							"\r\n",
							"# Convert Calendar date to Julian\r\n",
							"output =ct.calendar_to_julian(\"sys_date2\")\r\n",
							"\r\n",
							"# Add literal value columns for e.g audit columns\r\n",
							"audit={\"audit_key\":66363,\"pipeline_id\":\"56f63394bb06dd7f6945f636f1d4018bd50f1850\", \"start_datetime\": \"2020-10-01 10:00:00\", \"end_datetime\": \"2020-10-01 10:02:05\"}\r\n",
							"output = ct.addLitCols(audit)"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"display(output)"
						],
						"outputs": [],
						"execution_count": 11
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/test-datalake-functions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Notebook for unit testing test datalake-functions",
				"folder": {
					"name": "unit tests"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "7460c5a6-d11c-4bc9-b218-6b79e07c7441"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e836675f-2508-4873-ad4f-754d70253b22/resourceGroups/rg-synapse-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapse01-kn3acb6lw3vr4/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-kn3acb6lw3vr4.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Unit Test Datalake Functions"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"%run /common/datalake-functions {\"storageAccount\": \"bastoragedatalake01\" }"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"df = readFile(\"raw-bronze\", \"nyc-yellowtaxi-trip/yellow_tripdata_2020-01.csv\", \",\", True)\r\n",
							"display(df)"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"writeFile(df,\"curated-silver\", \"test/nyc-yellowtaxi-trip/yellow_tripdata_2020-01.parquet\", \"overwrite\")"
						],
						"outputs": [],
						"execution_count": 3
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/test-dedicatedSQL-functions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Notebook for unit testing dedicatedSQL-functions",
				"folder": {
					"name": "unit tests"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "7a30552c-dabd-4c03-ac5c-26c9582cb8be"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/5a5ba4fb-f4e0-4eaf-a2d3-7db71dfd729d/resourceGroups/rg-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapseanalytics01/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapseanalytics01.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Unit Test dedicatedSQL-functions"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"%run /common/dedicatedSQLPool-functions {\"server\": \"ba-synapseanalytics01.sql.azuresynapse.net,1433\",\"database\" :\"dw01\" }"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Test readSdpTable()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"df =readSdpTable(\"nyct\",\"nyc_tlc_yellow_trip\",None,None,10)\r\n",
							"display(df)"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Test insertSdpTable()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# Test Overwrite\r\n",
							"schema =\"nyct\"\r\n",
							"table = \"nyc_tlc_yellow_trip_copy\"\r\n",
							"insertSdpTable(df,schema,table,\"overwrite\")\r\n",
							"\r\n",
							"df =readSdpTable(schema,table,None,None,10)\r\n",
							"display(df)\r\n",
							""
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# Test Append\r\n",
							"schema =\"nyct\"\r\n",
							"table = \"nyc_tlc_yellow_trip_copy\"\r\n",
							"insertSdpTable(df,schema,table,\"append\")\r\n",
							"\r\n",
							"df =readSdpTable(schema,table,None,None,10)\r\n",
							"display(df)\r\n",
							""
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# # Test Error\r\n",
							"# schema =\"nyct\"\r\n",
							"# table = \"nyc_tlc_yellow_trip_copy\"\r\n",
							"# insertSdpTable(df,schema,table,\"error\")\r\n",
							""
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Test Ignore\r\n",
							"schema =\"nyct\"\r\n",
							"table = \"nyc_tlc_yellow_trip_copy\"\r\n",
							"insertSdpTable(df,schema,table,\"ignore\")\r\n",
							""
						],
						"outputs": [],
						"execution_count": 19
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/test-keyvault-functions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Notebook for unit testing keyvault-functions",
				"folder": {
					"name": "unit tests"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "b69c1284-9c15-4b15-a717-c78bb1277e61"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e836675f-2508-4873-ad4f-754d70253b22/resourceGroups/rg-synapse-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapse01-kn3acb6lw3vr4/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-kn3acb6lw3vr4.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Unit Test Key Vault Functions"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"%run /common/keyvault-functions {\"kvLinkedService\": \"Your AKV Linked Service name\"}"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"getSecret(\"SecretName\")"
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/test-pyodbc')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "unit tests"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "8875cffe-d178-472e-9035-115d3a77258c"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/5a5ba4fb-f4e0-4eaf-a2d3-7db71dfd729d/resourceGroups/rg-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapseanalytics01/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapseanalytics01.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Re-usable functions for Azure Synapse SQL Dedicated Pool"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /common/keyvault-functions {\"kvLinkedService\": \"keyvault01\"}"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"server = \"ba-synapseanalytics01.sql.azuresynapse.net,1433\"\r\n",
							"database = \"dw01\""
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"uid = getSecret(\"dw01-sqlusername\")\r\n",
							"pwd = getSecret(\"dw01-sqlpassword\")"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pyodbc\r\n",
							"\r\n",
							"cnxn = pyodbc.connect(\"DRIVER={ODBC Driver 17 for SQL Server};SERVER=\" + server + \";DATABASE=\" + database + \";UID=\" + uid + \";PWD=\" + pwd )\r\n",
							"cursor = cnxn.cursor()\r\n",
							"cnxn.autocommit = True"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"cursor.execute(\"truncate table dbo.DimActors\")\r\n",
							"row = cursor.fetchone()\r\n",
							"if row:\r\n",
							"    print(row)\r\n",
							""
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"sql = \"\"\"INSERT INTO stg.nyc_tlc_yellow_trip (vendorID,tpepPickupDateTime,tpepDropoffDateTime,passengerCount,tripDistance,puLocationId,doLocationId,startLon,startLat,endLon,endLat,rateCodeId,storeAndFwdFlag\r\n",
							"      ,paymentType\r\n",
							"      ,fareAmount\r\n",
							"      ,extra\r\n",
							"      ,mtaTax\r\n",
							"      ,improvementSurcharge\r\n",
							"      ,tipAmount\r\n",
							"      ,tollsAmount\r\n",
							"      ,totalAmount)\r\n",
							"SELECT top 100 vendorID\r\n",
							"      ,tpepPickupDateTime\r\n",
							"      ,tpepDropoffDateTime\r\n",
							"      ,passengerCount\r\n",
							"      ,tripDistance\r\n",
							"      ,puLocationId\r\n",
							"      ,doLocationId\r\n",
							"      ,startLon\r\n",
							"      ,startLat\r\n",
							"      ,endLon\r\n",
							"      ,endLat\r\n",
							"      ,rateCodeId\r\n",
							"      ,storeAndFwdFlag\r\n",
							"      ,paymentType\r\n",
							"      ,fareAmount\r\n",
							"      ,extra\r\n",
							"      ,mtaTax\r\n",
							"      ,improvementSurcharge\r\n",
							"      ,tipAmount\r\n",
							"      ,tollsAmount\r\n",
							"      ,totalAmount\r\n",
							"  FROM nyct.nyc_tlc_yellow_trip\r\n",
							"  WHERE NOT EXISTS\r\n",
							"  (SELECT 1 FROM stg.nyc_tlc_yellow_trip\r\n",
							"  where stg.nyc_tlc_yellow_trip.vendorID= nyct.nyc_tlc_yellow_trip.vendorID\r\n",
							"  and stg.nyc_tlc_yellow_trip.tpepPickupDateTime = nyct.nyc_tlc_yellow_trip.tpepPickupDateTime\r\n",
							"  and stg.nyc_tlc_yellow_trip.tpepDropoffDateTime = nyct.nyc_tlc_yellow_trip.tpepDropoffDateTime)\"\"\"\r\n",
							"\r\n",
							"cursor.execute(sql)"
						],
						"outputs": [],
						"execution_count": 21
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/test-upsertSdp-function')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Notebook for unit testing upsertSdp-function",
				"folder": {
					"name": "unit tests"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "eee5de17-be16-4ef8-850e-2a3f503ee964"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e836675f-2508-4873-ad4f-754d70253b22/resourceGroups/rg-synapse-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapse01-kn3acb6lw3vr4/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-kn3acb6lw3vr4.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Unit Test Upsert Function"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"%run /common/upsertSdp-function {\"server\": \"ba-synapseanalytics01.sql.azuresynapse.net,1433\",\"database\" :\"dw01\",\"sqlUidSecret\": \"dw01-sqlusername\",\"sqlPwdSecret\":\"dw01-sqlpassword\", \"sinkType\": \"Synapse\"}"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# upsert Synapse Dedicated SQL Pool Table"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df =readDspTable(\"nyct\",\"nyc_tlc_yellow_trip\",None,None,10)\r\n",
							"upsertDsp(df,\"nyct\",\"nyc_tlc_yellow_trip_stage\", \"nyct\", \"nyc_tlc_yellow_trip_merge\", [\"vendorID\",\"tpepPickupDateTime\",\"tpepDropoffDateTime\"], DeltaColumn=None) "
						],
						"outputs": [],
						"execution_count": 16
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/upsertSdp-function')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Notebook that implements upsert function using PyOdbc",
				"folder": {
					"name": "common"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "mediumMO",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "83d59507-e792-47b3-892b-27ea5188d7d9"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/735994b1-b3b0-46d5-96bc-c9b30ddb4265/resourceGroups/rg-synapse-dp/providers/Microsoft.Synapse/workspaces/ba-synapse01-lhf7sbrgc3jru/bigDataPools/mediumMO",
						"name": "mediumMO",
						"type": "Spark",
						"endpoint": "https://ba-synapse01-lhf7sbrgc3jru.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mediumMO",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Re-usable Upsert function for Azure Synapse Analytics SQL Dedicated Pool"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"server=\"<Azure Synapse DedicatedSQLPool>\"\n",
							"database = \"<Azure Synapse DedicatedSQLPool/Azure SQL>\"\n",
							"sqlUidSecret = \"Azure Key Vault Secret for DedicatedSQLPool user name\"\n",
							"sqlPwdSecret = \"Azure Key Vault Secret for DedicatedSQLPool password\""
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"source": [
							"%run /common/keyvault-functions {\"kvLinkedService\": \"keyvault01\"}"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /common/dedicatedSQLPool-functions {\"server\": \"ba-synapse01-lhf7sbrgc3jru.sql.azuresynapse.net,1433\",\"database\" : \"dwh01\"}"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pyodbc"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run /common/dedicatedSQLPool-functions {\"server\": \"ba-synapse01-lhf7sbrgc3jru.sql.azuresynapse.net,1433\",\"database\" :\"dwh01\" }"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# upsertSdp()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upsertSdp(df,SchemaStagingTable,StagingTable, SchemaTargetTable, TargetTable, KeyColumns, DeltaColumn=None) :\n",
							"# ##########################################################################################################################  \n",
							"# Function: upsertSdp\n",
							"# Performs a Merge/Upsert action on a Azure SQL table\n",
							"# \n",
							"# Parameters:\n",
							"# df = Input dataframe\n",
							"# StagingTable = Name of Table used to temporarily stage the input data frame\n",
							"# SchemaStagingTable = Database schema of staging table\n",
							"# SchemaTargetTable = Database schema of target table\n",
							"# TargetTable  = Name of Target Table\n",
							"# KeyColumns = List of columns that uniquely defines a record in input dataframe\n",
							"# DeltaColumn = Name of watermark column in input dataframe\n",
							"#\n",
							"# Returns:\n",
							"# None\n",
							"# ##########################################################################################################################  \n",
							"    insertSdpTable(df, SchemaStagingTable,StagingTable, \"overwrite\")\n",
							"\n",
							"    insertCols=\"\"\n",
							"    updateCols=\"\"\n",
							"    whereCols =\"\"\n",
							"    keyCols = \"\"\n",
							"\n",
							"    # MATCHED Clause of MERGE\n",
							"    for keyCol in KeyColumns:\n",
							"        keyCols = keyCols + \"source.\" + keyCol + \" = \" + \"target.\" + keyCol + \" and \"\n",
							"\n",
							"    whereClause = keyCols\n",
							"    #Tidy up where clause and remove last \"and\"\n",
							"    remove=\"and\"\n",
							"    reverse_remove=remove[::-1]\n",
							"    whereClause = whereClause[::-1].replace(reverse_remove,\"\",1)[::-1]\n",
							"\n",
							"    # INSERT and UPDATE part of MERGE\n",
							"    for col in df.schema.fieldNames():\n",
							"        insertCols = insertCols + col + \",\"\n",
							"        if col not in KeyColumns: # Exclude identity columns in update statement\n",
							"         updateCols =  updateCols + \"target.\" + col + \" = \" + \"source.\" + col + \",\"\n",
							"\n",
							"    #Tidy up insertCols and remove last \",\"\n",
							"    remove=\",\"\n",
							"    reverse_remove=remove[::-1]\n",
							"    insertCols = insertCols[::-1].replace(reverse_remove,\"\",1)[::-1]  \n",
							"\n",
							"    #Tidy up insertCols and remove last \",\"\n",
							"    remove=\",\"\n",
							"    reverse_remove=remove[::-1]\n",
							"    updateCols = updateCols[::-1].replace(reverse_remove,\"\",1)[::-1]   \n",
							"\n",
							"    # MERGE Statement in full\n",
							"    mergeSQL= \"MERGE INTO \" + SchemaTargetTable +\".\" + TargetTable + \" AS target\" +  \" USING \" + SchemaStagingTable + \".\" + StagingTable + \" AS source\" + \" ON \"\n",
							"    mergeSQL = mergeSQL + whereClause\n",
							"\n",
							"    # WHEN MATCHED\n",
							"    if DeltaColumn != None:\n",
							"        mergeSQL =  mergeSQL + \" WHEN MATCHED AND \" + \"source.\" + DeltaColumn + \" > \" + \"target.\" + DeltaColumn \n",
							"    else:\n",
							"        mergeSQL =  mergeSQL + \" WHEN MATCHED\"\n",
							"\n",
							"    mergeSQL = mergeSQL + \" THEN UPDATE SET \" + updateCols\n",
							"\n",
							"    # WHEN NOT MATCHED BY TARGET\n",
							"    mergeSQL = mergeSQL + \" WHEN NOT MATCHED BY TARGET \" # including BY TARGET clause for Synapse requires the table to be Hash Distributed\n",
							"    mergeSQL = mergeSQL + \" THEN INSERT \" +  \"(\"+ insertCols +\")\" + \" VALUES \" + \" ( \"+ insertCols +\" ) \"\n",
							"\n",
							"    mergeSQL = mergeSQL +\";\"\n",
							"    \n",
							"    #Execute Merge Statement using Pyodbc\n",
							"    uid = getSecret(sqlUidSecret)\n",
							"    pwd = getSecret(sqlPwdSecret)\n",
							" \n",
							"    try:\n",
							"        cnxn = pyodbc.connect(\"DRIVER={ODBC Driver 17 for SQL Server};SERVER=\" + server + \";DATABASE=\" + database + \";UID=\" + uid + \";PWD=\" + pwd )\n",
							"        cursor = cnxn.cursor()\n",
							"        cnxn.autocommit = True\n",
							"\n",
							"        cursor.execute(mergeSQL)\n",
							"    except Exception as e:\n",
							"        print(\"Upsert to {}.{} failed with exception:\".format(SchemaTargetTable,TargetTable))\n",
							"        raise e\n",
							"\n",
							"    print(\"Upsert statement executed successfully : {} \".format(mergeSQL))\n",
							"    return"
						],
						"outputs": [],
						"execution_count": 12
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/xlargeGPU')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 10
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 16,
					"minNodeCount": 8
				},
				"nodeCount": 0,
				"nodeSize": "XLarge",
				"nodeSizeFamily": "HardwareAcceleratedGPU",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "australiaeast"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/mediumGPU')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 10
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 8,
					"minNodeCount": 4
				},
				"nodeCount": 0,
				"nodeSize": "Medium",
				"nodeSizeFamily": "HardwareAcceleratedGPU",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "australiaeast"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/xlargeMO')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 10
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 16,
					"minNodeCount": 8
				},
				"nodeCount": 0,
				"nodeSize": "XLarge",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.1",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "australiaeast"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/mediumMO')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 10
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 8,
					"minNodeCount": 4
				},
				"nodeCount": 0,
				"nodeSize": "Medium",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "australiaeast"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/largeMO')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 10
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 12,
					"minNodeCount": 6
				},
				"nodeCount": 0,
				"nodeSize": "Large",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "australiaeast"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/largeGPU')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 10
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 12,
					"minNodeCount": 6
				},
				"nodeCount": 0,
				"nodeSize": "Large",
				"nodeSizeFamily": "HardwareAcceleratedGPU",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "australiaeast"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/smallGPU')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 10
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 4,
					"minNodeCount": 3
				},
				"nodeCount": 0,
				"nodeSize": "Small",
				"nodeSizeFamily": "HardwareAcceleratedGPU",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "australiaeast"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/xxlargeMO')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 10
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 24,
					"minNodeCount": 12
				},
				"nodeCount": 0,
				"nodeSize": "XXLarge",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "australiaeast"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/smallMO')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 10
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 4,
					"minNodeCount": 3
				},
				"nodeCount": 0,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "australiaeast"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dwh01')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"annotations": []
			},
			"dependsOn": [],
			"location": "australiaeast"
		}
	]
}