{
	"name": "L1Transform-SEC-Form10Q",
	"properties": {
		"description": "Notebook to summarize SEC Form 10Q statement using AOAI",
		"folder": {
			"name": "L1Transform"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "smallMO",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "85ad34bd-34b0-44d5-b4ee-5771667c6562"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/735994b1-b3b0-46d5-96bc-c9b30ddb4265/resourceGroups/rg-synapse-dp/providers/Microsoft.Synapse/workspaces/ba-synapse01-lhf7sbrgc3jru/bigDataPools/smallMO",
				"name": "smallMO",
				"type": "Spark",
				"endpoint": "https://ba-synapse01-lhf7sbrgc3jru.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallMO",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.2",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"%run /common/datalake-functions {\"storageAccount\": \"badatalake01lhf7sbrgc3jr\" }"
				],
				"execution_count": 41
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run /common/keyvault-functions {\"kvLinkedService\": \"keyvault01\"}"
				],
				"execution_count": 42
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Notebook Parameters"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": [
						"parameters"
					]
				},
				"source": [
					"L1TransformInstanceID = None\n",
					"L1TransformID = None\n",
					"IngestID = None\n",
					"CustomParameters = None\n",
					"InputRawFileSystem = None\n",
					"InputRawFileFolder = None\n",
					"InputRawFile = None\n",
					"InputRawFileDelimiter = None\n",
					"InputFileHeaderFlag = None\n",
					"OutputL1CurateFileSystem = None\n",
					"OutputL1CuratedFolder = None\n",
					"OutputL1CuratedFile = None\n",
					"OutputL1CuratedFileDelimiter = None\n",
					"OutputL1CuratedFileFormat = None\n",
					"OutputL1CuratedFileWriteMode = None\n",
					"OutputDWStagingTable = None\n",
					"LookupColumns = None\n",
					"OutputDWTable = None\n",
					"OutputDWTableWriteMode = None\n",
					"ReRunL1TransformFlag = None\n",
					"DeltaName = None"
				],
				"execution_count": 43
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# # Parameters for Testing only, should be commented off\n",
					"# L1TransformInstanceID = 9\n",
					"# L1TransformID  = 2\n",
					"# IngestID = 1\n",
					"# CustomParameters = None\n",
					"# InputRawFileSystem = \"raw-bronze\"\n",
					"# InputRawFileFolder = \"form10q/2024/08\"\n",
					"# InputRawFile = \"2024-08-26_133747_form10q.json\"\n",
					"# InputRawFileDelimiter = None\n",
					"# InputFileHeaderFlag = None\n",
					"# OutputL1CurateFileSystem = \"curated-silver\"\n",
					"# OutputL1CuratedFolder = \"form10q/2024/08\"\n",
					"# OutputL1CuratedFile = \"standardized_2024-08-26_133837_form10q.json\"\n",
					"# OutputL1CuratedFileDelimiter = None\n",
					"# OutputL1CuratedFileFormat = \"json\"\n",
					"# OutputL1CuratedFileWriteMode = \"overwrite\"\n",
					"# OutputDWStagingTable = None\n",
					"# LookupColumns = None\n",
					"# OutputDWTable = None\n",
					"# OutputDWTableWriteMode = None\n",
					"# ReRunL1TransformFlag = None\n",
					"# DeltaName = None"
				],
				"execution_count": 44
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Extract datapoints of interest"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import *\n",
					"from pyspark.sql.types import *\n",
					"df = readFile(InputRawFileSystem, InputRawFileFolder +\"/\" + InputRawFile, None, None)\n",
					"ingestCount = df.count()\n",
					"\n",
					"# df.printSchema()\n",
					"\n",
					"df = df.select( col(\"org_name.content\").alias(\"org_name\")\n",
					"                ,col(\"org_address.content\").alias(\"org_address\")\n",
					"                ,col(\"org_jurisdiction.content\").alias(\"org_jurisdiction\")\n",
					"                ,col(\"org_stock_ticker.content\").alias(\"org_stock_ticker\")\n",
					"                ,col(\"reporting_quarter.content\").alias(\"reporting_quarter\")\n",
					"                ,col(\"stock_exchange.content\").alias(\"stock_exchange\")\n",
					"                ,regexp_replace(col(\"total_assets.content\"),\",\",\"\").cast(IntegerType()).alias(\"total_assets\")\n",
					"                ,regexp_replace(col(\"total_comprehensive_income.content\"),\",\",\"\").cast(IntegerType()).alias(\"total_comprehensive_income\")\n",
					"                ,regexp_replace(col(\"total_equity.content\"),\",\",\"\").cast(IntegerType()).alias(\"total_equity\")\n",
					"                ,regexp_replace(col(\"total_liabilities.content\"),\",\",\"\").cast(IntegerType()).alias(\"total_liabilities\")                \n",
					"                ,col(\"mgmt_analysis.content\").alias(\"mgmt_analysis\")\n",
					"                ,col(\"risk_disclosure.content\").alias(\"risk_disclosure\")\n",
					"                ,col(\"controls_procedures.content\").alias(\"controls_procedures\")\n",
					"            )"
				],
				"execution_count": 45
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# AOAI Summarization"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"import os\n",
					"from synapse.ml.services.openai import OpenAIChatCompletion\n",
					"\n",
					"aoaiEndpoint = getSecret(\"aoai-endpoint\")\n",
					"aoaiDeploymentName = \"gpt-35-turbo\"\n",
					"aoaiApiKey = getSecret(\"aoai-api-key\")\n",
					"location = \"australiaeast\"\n",
					"\n",
					"def make_message(role, content):\n",
					"    return Row(role=role, content=content, name=role)\n",
					"\n",
					"systemPrompt = \"summarize the text as bullet points. Include key highligts. Generate concise summary. Exclude content not in supplied prompt\"\n",
					"\n",
					"#Summary1\n",
					"dfSummaryMgmtAnalysis = spark.createDataFrame(\n",
					"    [\n",
					"        (\n",
					"            [\n",
					"                make_message(\n",
					"                    \"system\", systemPrompt\n",
					"                ),\n",
					"                make_message(\"user\", df.first()[\"mgmt_analysis\"]),\n",
					"            ],\n",
					"        )\n",
					"    ]\n",
					").toDF(\"messages\")\n",
					"\n",
					"chat_completion = (\n",
					"    OpenAIChatCompletion()\n",
					"    .setSubscriptionKey(aoaiApiKey)\n",
					"    .setDeploymentName(aoaiDeploymentName)\n",
					"    .setCustomServiceName(location)\n",
					"    .setMessagesCol(\"messages\")\n",
					"    .setErrorCol(\"error\")\n",
					"    .setOutputCol(\"mgmt_analysis_summary\")\n",
					")\n",
					"\n",
					"# display(\n",
					"#     chat_completion.transform(dfSummaryMgmtAnalysis).select(\n",
					"#         \"messages\", \"error\",\"mgmt_analysis_summary.choices.message.content\"\n",
					"#     )\n",
					"# )\n",
					"dfSummaryMgmtAnalysis =  chat_completion.transform(dfSummaryMgmtAnalysis).select(col(\"mgmt_analysis_summary.choices.message.content\").alias(\"mgmt_analysis_summary\"))\n",
					"\n",
					"#Summary2\n",
					"dfSummaryRisk = spark.createDataFrame(\n",
					"    [\n",
					"        (\n",
					"            [\n",
					"                make_message(\n",
					"                    \"system\", systemPrompt\n",
					"                ),\n",
					"                make_message(\"user\", df.first()[\"risk_disclosure\"]),\n",
					"            ],\n",
					"        )\n",
					"    ]\n",
					").toDF(\"messages\")\n",
					"\n",
					"chat_completion = (\n",
					"    OpenAIChatCompletion()\n",
					"    .setSubscriptionKey(aoaiApiKey)\n",
					"    .setDeploymentName(aoaiDeploymentName)\n",
					"    .setCustomServiceName(location)\n",
					"    .setMessagesCol(\"messages\")\n",
					"    .setErrorCol(\"error\")\n",
					"    .setOutputCol(\"risk_disclosure_summary\")\n",
					")\n",
					"\n",
					"# display(\n",
					"#     chat_completion.transform(dfSummaryRisk).select(\n",
					"#         \"messages\", \"error\",\"risk_disclosure_summary.choices.message.content\"\n",
					"#     )\n",
					"# )\n",
					"\n",
					"dfSummaryRisk= chat_completion.transform(dfSummaryRisk).select(col(\"risk_disclosure_summary.choices.message.content\").alias(\"risk_disclosure_summary\"))\n",
					"\n",
					"#Summary3\n",
					"dfSummaryCP = spark.createDataFrame(\n",
					"    [\n",
					"        (\n",
					"            [\n",
					"                make_message(\n",
					"                    \"system\", systemPrompt\n",
					"                ),\n",
					"                make_message(\"user\", df.first()[\"controls_procedures\"]),\n",
					"            ],\n",
					"        )\n",
					"    ]\n",
					").toDF(\"messages\")\n",
					"\n",
					"chat_completion = (\n",
					"    OpenAIChatCompletion()\n",
					"    .setSubscriptionKey(aoaiApiKey)\n",
					"    .setDeploymentName(aoaiDeploymentName)\n",
					"    .setCustomServiceName(location)\n",
					"    .setMessagesCol(\"messages\")\n",
					"    .setErrorCol(\"error\")\n",
					"    .setOutputCol(\"controls_procedures_summary\")\n",
					")\n",
					"\n",
					"# display(\n",
					"#     chat_completion.transform(dfSummaryCP).select(\n",
					"#         \"messages\", \"error\",\"controls_procedures_summary.choices.message.content\"\n",
					"#     )\n",
					"# )\n",
					"dfSummaryCP = chat_completion.transform(dfSummaryCP).select(col(\"controls_procedures_summary.choices.message.content\").alias(\"controls_procedures_summary\"))"
				],
				"execution_count": 118
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from functools import reduce\n",
					"from pyspark.sql import DataFrame\n",
					"\n",
					"#Merge all the dataframes\n",
					"dfs = [df,dfSummaryMgmtAnalysis,dfSummaryRisk,dfSummaryCP]\n",
					"dfFinal = reduce(DataFrame.crossJoin, dfs)\n",
					"display(dfFinal)\n",
					""
				],
				"execution_count": 119
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Write summarized json to curated zone of data lake"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"l1TransformCount = dfFinal.count()\n",
					"writeFile(dfFinal,OutputL1CurateFileSystem, OutputL1CuratedFolder + \"/\" + OutputL1CuratedFile)"
				],
				"execution_count": 120
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Return Values"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import json\n",
					"mssparkutils.notebook.exit(json.dumps({\n",
					"  \"IngestCount\": ingestCount,\n",
					"  \"L1TransformCount\": l1TransformCount\n",
					"}))\n",
					""
				],
				"execution_count": 121
			}
		]
	}
}