{
	"name": "L1Transform-SEC-Form10Q",
	"properties": {
		"description": "Notebook to summarize SEC Form 10Q statement using AOAI",
		"folder": {
			"name": "L1Transform"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "smallMO",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": true,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "0de3ba68-bd5b-4b97-9b9d-32bd9f3fe06b"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": true,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/e836675f-2508-4873-ad4f-754d70253b22/resourceGroups/rg-synapse-dataplatform/providers/Microsoft.Synapse/workspaces/ba-synapse01-kn3acb6lw3vr4/bigDataPools/smallMO",
				"name": "smallMO",
				"type": "Spark",
				"endpoint": "https://ba-synapse01-kn3acb6lw3vr4.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallMO",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net",
					"authHeader": null
				},
				"sparkVersion": "3.2",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"extraHeader": null
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Install SynapseML for this spark session\r\n",
					"https://microsoft.github.io/SynapseML/docs/getting_started/installation/"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%%configure -f\r\n",
					"{\r\n",
					"  \"name\": \"synapseml\",\r\n",
					"  \"conf\": {\r\n",
					"      \"spark.jars.packages\": \"com.microsoft.azure:synapseml_2.12:0.11.0,org.apache.spark:spark-avro_2.12:3.3.1\",\r\n",
					"      \"spark.jars.repositories\": \"https://mmlspark.azureedge.net/maven\",\r\n",
					"      \"spark.jars.excludes\": \"org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12,com.fasterxml.jackson.core:jackson-databind\",\r\n",
					"      \"spark.yarn.user.classpath.first\": \"true\",\r\n",
					"      \"spark.sql.parquet.enableVectorizedReader\": \"false\",\r\n",
					"      \"spark.sql.legacy.replaceDatabricksSparkAvro.enabled\": \"true\"\r\n",
					"  }\r\n",
					"}"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"source": [
					"%run /common/datalake-functions {\"storageAccount\": \"badatalake01kn3acb6lw3vr\" }"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run /common/keyvault-functions {\"kvLinkedService\": \"keyvault01\"}"
				],
				"execution_count": 3
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Notebook Parameters"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": [
						"parameters"
					]
				},
				"source": [
					"L1TransformInstanceID = None\r\n",
					"L1TransformID = None\r\n",
					"IngestID = None\r\n",
					"CustomParameters = None\r\n",
					"InputRawFileSystem = None\r\n",
					"InputRawFileFolder = None\r\n",
					"InputRawFile = None\r\n",
					"InputRawFileDelimiter = None\r\n",
					"InputFileHeaderFlag = None\r\n",
					"OutputL1CurateFileSystem = None\r\n",
					"OutputL1CuratedFolder = None\r\n",
					"OutputL1CuratedFile = None\r\n",
					"OutputL1CuratedFileDelimiter = None\r\n",
					"OutputL1CuratedFileFormat = None\r\n",
					"OutputL1CuratedFileWriteMode = None\r\n",
					"OutputDWStagingTable = None\r\n",
					"LookupColumns = None\r\n",
					"OutputDWTable = None\r\n",
					"OutputDWTableWriteMode = None\r\n",
					"ReRunL1TransformFlag = None\r\n",
					"DeltaName = None"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# # Parameters for Testing only, should be commented off\r\n",
					"# L1TransformInstanceID = 6\r\n",
					"# L1TransformID = 8\r\n",
					"# IngestID = 5\r\n",
					"# CustomParameters = None\r\n",
					"# InputRawFileSystem = 'raw-bronze'\r\n",
					"# InputRawFileFolder = 'sec-form10q/2023/04'\r\n",
					"# InputRawFile = '2023-04-16_141247_sec-form10q.json'\r\n",
					"# InputRawFileDelimiter = None\r\n",
					"# InputFileHeaderFlag = None\r\n",
					"# OutputL1CurateFileSystem = 'curated-silver'\r\n",
					"# OutputL1CuratedFolder = 'sec-form10q/2023/04'\r\n",
					"# OutputL1CuratedFile = 'standardized_2023-04-16_141247_sec-form10q.json'\r\n",
					"# OutputL1CuratedFileDelimiter = None\r\n",
					"# OutputL1CuratedFileFormat = 'json'\r\n",
					"# OutputL1CuratedFileWriteMode = 'overwrite'\r\n",
					"# OutputDWStagingTable = '[stg].[merge_sec_form10q]'\r\n",
					"# LookupColumns = ['org_name','reporting_quarter']\r\n",
					"# OutputDWTable = '[sec].[form10q]'\r\n",
					"# OutputDWTableWriteMode = 'append'\r\n",
					"# ReRunL1TransformFlag = None\r\n",
					"# DeltaName = None"
				],
				"execution_count": 5
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Extract datapoints of interest"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import *\r\n",
					"from pyspark.sql.types import *\r\n",
					"df = readFile(InputRawFileSystem, InputRawFileFolder +\"/\" + InputRawFile, None, None)\r\n",
					"ingestCount = df.count()\r\n",
					"\r\n",
					"# df.printSchema()\r\n",
					"\r\n",
					"df = df.select( col(\"org_name.content\").alias(\"org_name\")\r\n",
					"                ,col(\"org_address.content\").alias(\"org_address\")\r\n",
					"                ,col(\"org_jurisdiction.content\").alias(\"org_jurisdiction\")\r\n",
					"                ,col(\"org_stock_ticker.content\").alias(\"org_stock_ticker\")\r\n",
					"                ,col(\"reporting_quarter.content\").alias(\"reporting_quarter\")\r\n",
					"                ,col(\"stock_exchange.content\").alias(\"stock_exchange\")\r\n",
					"                ,regexp_replace(col(\"total_assets.content\"),\",\",\"\").cast(IntegerType()).alias(\"total_assets\")\r\n",
					"                ,regexp_replace(col(\"total_comprehensive_income.content\"),\",\",\"\").cast(IntegerType()).alias(\"total_comprehensive_income\")\r\n",
					"                ,regexp_replace(col(\"total_equity.content\"),\",\",\"\").cast(IntegerType()).alias(\"total_equity\")\r\n",
					"                ,regexp_replace(col(\"total_liabilities.content\"),\",\",\"\").cast(IntegerType()).alias(\"total_liabilities\")                \r\n",
					"                ,col(\"mgmt_analysis.content\").alias(\"mgmt_analysis\")\r\n",
					"                ,col(\"risk_disclosure.content\").alias(\"risk_disclosure\")\r\n",
					"                ,col(\"controls_procedures.content\").alias(\"controls_procedures\")\r\n",
					"            )"
				],
				"execution_count": 6
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# AOAI Summarization GPT3.5"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"import os\r\n",
					"from synapse.ml.core.platform import running_on_synapse, find_secret\r\n",
					"from synapse.ml.cognitive import OpenAICompletion\r\n",
					"\r\n",
					"aoaiEndpoint = getSecret(\"aoai-endpoint\")\r\n",
					"aoaiDeploymentName = \"gpt35\"\r\n",
					"aoaiApiKey = getSecret(\"aoai-api-key\")\r\n",
					"\r\n",
					"#Summary1\r\n",
					"dfPrompt_mgmt_analysis = df.select( col(\"mgmt_analysis\")\r\n",
					"                                    , concat(lit(\"summarize the text below.\\n\"),lit(\"text:\"),col(\"mgmt_analysis\"),lit(\"\\n summary:\")).alias(\"mgmt_analysis_prompt\"))\r\n",
					"completion = (\r\n",
					"    OpenAICompletion()\r\n",
					"    .setSubscriptionKey(aoaiApiKey)\r\n",
					"    .setDeploymentName(aoaiDeploymentName)\r\n",
					"    .setUrl(aoaiEndpoint)\r\n",
					"    .setMaxTokens(100)\r\n",
					"    .setPromptCol(\"mgmt_analysis_prompt\")\r\n",
					"    .setErrorCol(\"error\")\r\n",
					"    .setOutputCol(\"mgmt_analysis_summary\")\r\n",
					")\r\n",
					"\r\n",
					"dfSummaryMgmtAnalysis = completion.transform(dfPrompt_mgmt_analysis).cache()\r\n",
					"# display(dfSummaryMgmtAnalysis.select(\r\n",
					"#   col(\"mgmt_analysis_prompt\"), col(\"error\"), col(\"mgmt_analysis_summary.choices.text\").getItem(0).alias(\"text\")))\r\n",
					"# dfSummaryMgmtAnalysis.printSchema()\r\n",
					"\r\n",
					"dfSummaryMgmtAnalysis = dfSummaryMgmtAnalysis.select(col(\"mgmt_analysis_summary.choices.text\").getItem(0).alias(\"mgmt_analysis_summary\"))\r\n",
					"\r\n",
					"#Summary2\r\n",
					"dfPrompt_risk_disclosure = df.select( col(\"risk_disclosure\")\r\n",
					"                                    , concat(lit(\"summarize the text below.\\n\"),lit(\"text:\"),col(\"risk_disclosure\"),lit(\"\\n summary:\")).alias(\"risk_disclosure_prompt\"))\r\n",
					"completion = (\r\n",
					"    OpenAICompletion()\r\n",
					"    .setSubscriptionKey(aoaiApiKey)\r\n",
					"    .setDeploymentName(aoaiDeploymentName)\r\n",
					"    .setUrl(aoaiEndpoint)\r\n",
					"    .setMaxTokens(100)\r\n",
					"    .setPromptCol(\"risk_disclosure_prompt\")\r\n",
					"    .setErrorCol(\"error\")\r\n",
					"    .setOutputCol(\"risk_disclosure_summary\")\r\n",
					")\r\n",
					"\r\n",
					"dfSummaryRisk = completion.transform(dfPrompt_risk_disclosure).cache()\r\n",
					"# display(dfSummaryRisk.select(\r\n",
					"#   col(\"risk_disclosure_prompt\"), col(\"error\"), col(\"risk_disclosure_summary.choices.text\").getItem(0).alias(\"text\")))\r\n",
					"# dfSummaryRisk.printSchema()\r\n",
					"\r\n",
					"dfSummaryRisk = dfSummaryRisk.select(col(\"risk_disclosure_summary.choices.text\").getItem(0).alias(\"risk_disclosure_summary\"))\r\n",
					"\r\n",
					"#Summary3\r\n",
					"dfPrompt_controls_procedures = df.select( col(\"controls_procedures\")\r\n",
					"                                    , concat(lit(\"summarize the text below.\\n\"),lit(\"text:\"),col(\"controls_procedures\"),lit(\"\\n summary:\")).alias(\"controls_procedures_prompt\"))\r\n",
					"completion = (\r\n",
					"    OpenAICompletion()\r\n",
					"    .setSubscriptionKey(aoaiApiKey)\r\n",
					"    .setDeploymentName(aoaiDeploymentName)\r\n",
					"    .setUrl(aoaiEndpoint)\r\n",
					"    .setMaxTokens(100)\r\n",
					"    .setPromptCol(\"controls_procedures_prompt\")\r\n",
					"    .setErrorCol(\"error\")\r\n",
					"    .setOutputCol(\"controls_procedures_summary\")\r\n",
					")\r\n",
					"\r\n",
					"dfSummaryCP = completion.transform(dfPrompt_controls_procedures).cache()\r\n",
					"# display(dfSummaryCP.select(\r\n",
					"#   col(\"controls_procedures_prompt\"), col(\"error\"), col(\"controls_procedures_summary.choices.text\").getItem(0).alias(\"text\")))\r\n",
					"# dfSummaryCP.printSchema()\r\n",
					"\r\n",
					"dfSummaryCP = dfSummaryCP.select(col(\"controls_procedures_summary.choices.text\").getItem(0).alias(\"controls_procedures_summary\"))"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from functools import reduce\r\n",
					"from pyspark.sql import DataFrame\r\n",
					"\r\n",
					"#Merge all the dataframes\r\n",
					"dfs = [df,dfSummaryMgmtAnalysis,dfSummaryRisk,dfSummaryCP]\r\n",
					"dfFinal = reduce(DataFrame.crossJoin, dfs)\r\n",
					"display(dfFinal)\r\n",
					""
				],
				"execution_count": 8
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Write summarized json to curated zone of data lake"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"l1TransformCount = dfFinal.count()\r\n",
					"writeFile(dfFinal,OutputL1CurateFileSystem, OutputL1CuratedFolder + \"/\" + OutputL1CuratedFile)"
				],
				"execution_count": 9
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Return Values"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import json\r\n",
					"mssparkutils.notebook.exit(json.dumps({\r\n",
					"  \"IngestCount\": ingestCount,\r\n",
					"  \"L1TransformCount\": l1TransformCount\r\n",
					"}))\r\n",
					""
				]
			}
		]
	}
}